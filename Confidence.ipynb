{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TclLbcx3-a6k"
      },
      "source": [
        "## Libraries anf functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heIW5cG_75EC"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "from sklearn.cluster import KMeans\n",
        "import seaborn as sns\n",
        "from scipy.stats import wilcoxon\n",
        "import pickle\n",
        "import plotly.express as px\n",
        "from csv import DictWriter\n",
        "from sklearn.mixture import GaussianMixture\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "import math\n",
        "import imblearn\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import gc\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler, TensorDataset\n",
        "from sklearn.preprocessing import MinMaxScaler , StandardScaler\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
        "from numpy import asarray,savez_compressed\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "!pip install -q SentencePiece transformers\n",
        "from transformers import AdamW, get_cosine_schedule_with_warmup, get_linear_schedule_with_warmup, T5EncoderModel, T5Tokenizer\n",
        "import torch.nn as nn\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import requests\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn import metrics\n",
        "#from torch.utils import data\n",
        "import re\n",
        "import os\n",
        "!pip install Biopython"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evcouplings"
      ],
      "metadata": {
        "id": "ST1ZlTrfS1Ed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# conflict between python 3.10 and collections. I have to substitute from collections import Iterable with from collections.abc import Iterable on:\n",
        "# /usr/local/lib/python3.10/dist-packages/evcouplings/align/protocol.py, /usr/local/lib/python3.10/dist-packages/evcouplings/couplings/mapping.py and /usr/local/lib/python3.10/dist-packages/evcouplings/couplings/model.py\n",
        "#from collections import OrderedDict\n",
        "#from evcouplings.align import Alignment, map_matrix, read_fasta"
      ],
      "metadata": {
        "id": "exZkeO1R54Hh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def intersection(lst1, lst2):\n",
        "    return list(set(lst1) & set(lst2))\n",
        "\n",
        "def msa_protocol(name_msa_file):\n",
        "  ### name_msa_file: path to msa fime of gene\n",
        "  ### return: alignment of gene\n",
        "\n",
        "  with open(name_msa_file, \"r\") as infile:\n",
        "    #seqs = OrderedDict()\n",
        "    next(infile)\n",
        "\n",
        "    #for i, (seq_id, seq) in enumerate(read_fasta(infile)):\n",
        "    proper_infile = read_a3m(infile, inserts = \"delete\") # convert from a3m to a2m\n",
        "    #seq = seq.replace(\".\", \"\")\n",
        "    # seqs[seq_id] = seq\n",
        "    #n_items = take(n, seqs.items())\n",
        "\n",
        "    #aln = Alignment.from_file(proper_infile, format=\"fasta\")\n",
        "    aln = Alignment.from_dict(proper_infile)\n",
        "\n",
        "  # Sequence length and number of sequences\n",
        "  print(f\"alignment is of length {aln.L} and has {aln.N} sequences\")\n",
        "\n",
        "  # Protocol Hopf\n",
        "  # calculate the percent identity of every sequence in the alignment to the first sequence\n",
        "  ident_perc = aln.identities_to(aln.matrix[0])\n",
        "  ident_perc_list = ident_perc.tolist()\n",
        "\n",
        "  # keep identifiers with > 50 percentage identity and colunns with at least 70% occupancy\n",
        "  index_keep = []\n",
        "  for i, iden in enumerate(ident_perc_list):\n",
        "    if iden > 0.5: # 0.5= sequences with at least 50% of identity to the frst sequence are kept\n",
        "      index_keep.append(i)\n",
        "\n",
        "  #use the \"count\" method of the class  -  Percentage of gaps\n",
        "  maximum1 = aln.count(axis=\"seq\",char=\"-\")#.argmax()\n",
        "\n",
        "  filtered_ind = [i for i in range(len(maximum1)) if maximum1[i] <= 0.3] # 0.3 30% of gaps\n",
        "  sequences_to_keep = intersection(index_keep, filtered_ind) # keep indeces that satisfy both conditions\n",
        "\n",
        "  selection_index = sequences_to_keep\n",
        "  aln_subsection = aln.select(sequences=selection_index)\n",
        "  print(f\"the new alignment has {aln_subsection.N} sequences\")\n",
        "\n",
        "  # if remaining sequences in MSA < 15 redo the process with less strict filtering\n",
        "  if aln_subsection.N <15:\n",
        "    index_keep = []\n",
        "    for i, iden in enumerate(ident_perc_list):\n",
        "      #if iden > 0.05: # 0.3= sequences with at least 5% of identity to the frst sequence are kept\n",
        "      if iden > 0.27: # 0.3= sequences with at least 10% of identity to the frst sequence are kept\n",
        "        index_keep.append(i)\n",
        "    filtered_ind = [i for i in range(len(maximum1)) if maximum1[i] <= 0.7] # max 60% of gaps\n",
        "    sequences_to_keep = intersection(index_keep, filtered_ind) # keep indeces that satisfy both conditions\n",
        "    selection_index = sequences_to_keep\n",
        "    aln_subsection = aln.select(sequences=selection_index)\n",
        "\n",
        "  if aln_subsection.N <15:\n",
        "    index_keep = []\n",
        "    for i, iden in enumerate(ident_perc_list):\n",
        "      #if iden > 0.05: # 0.3= sequences with at least 5% of identity to the frst sequence are kept\n",
        "      if iden > 0.2: # 0.3= sequences with at least 20% of identity to the frst sequence are kept\n",
        "        index_keep.append(i)\n",
        "    filtered_ind = [i for i in range(len(maximum1)) if maximum1[i] <= 0.7] # max 60% of gaps\n",
        "    sequences_to_keep = intersection(index_keep, filtered_ind) # keep indeces that satisfy both conditions\n",
        "    selection_index = sequences_to_keep\n",
        "    aln_subsection = aln.select(sequences=selection_index)\n",
        "  #if aln_subsection.N >5000:\n",
        "  #  index_keep = []\n",
        "  #  for i, iden in enumerate(ident_perc_list):\n",
        "  #    if iden > 0.6: # 0.4= sequences with at least 30% of identity to the frst sequence are kept\n",
        "  #      index_keep.append(i)\n",
        "  #  filtered_ind = [i for i in range(len(maximum1)) if maximum1[i] <= 0.2] # 0.6 60% of gaps\n",
        "  #  sequences_to_keep = intersection(index_keep, filtered_ind) # keep indeces that satisfy both conditions\n",
        "  #  selection_index = sequences_to_keep\n",
        "  #  aln_subsection = aln.select(sequences=selection_index)\n",
        "\n",
        "\n",
        "  #use the \"count\" method of the class  -  Percentage of gaps\n",
        "  #maximum1 = aln.count(axis=\"seq\",char=\"-\")#.argmax()\n",
        "  #filtered_ind = [i for i in range(len(maximum1)) if maximum1[i] <= 0.3] # 0.6 60% of gaps\n",
        "  print(f\"the new alignment has {aln_subsection.N} sequences\")\n",
        "\n",
        "  return aln_subsection\n",
        "\n",
        "def read_a3m(fileobj, inserts=\"first\"):\n",
        "    \"\"\"\n",
        "    Read an alignment in compressed a3m format and expand\n",
        "    into a2m format.\n",
        "    .. note::\n",
        "        this function is currently not able to keep inserts in all the sequences\n",
        "    ..todo::\n",
        "        implement this\n",
        "    Parameters\n",
        "    ----------\n",
        "    fileobj : file-like object\n",
        "        A3M alignment file\n",
        "    inserts : {\"first\", \"delete\"}\n",
        "        Keep inserts in first sequence, or delete\n",
        "        any insert column and keep only match state\n",
        "        columns.\n",
        "    Returns\n",
        "    -------\n",
        "    OrderedDict\n",
        "        Sequences in alignment (key: ID, value: sequence),\n",
        "        in order they appeared in input file\n",
        "    Raises\n",
        "    ------\n",
        "    ValueError\n",
        "        Upon invalid choice of insert strategy\n",
        "    \"\"\"\n",
        "    seqs = OrderedDict()\n",
        "\n",
        "    for i, (seq_id, seq) in enumerate(read_fasta(fileobj)):\n",
        "        # remove any insert gaps that may still be in alignment\n",
        "        # (just to be sure)\n",
        "        seq = seq.replace(\".\", \"\")\n",
        "\n",
        "        if inserts == \"first\":\n",
        "            # define \"spacing\" of uppercase columns in\n",
        "            # final alignment based on target sequence;\n",
        "            # remaining columns will be filled with insert\n",
        "            # gaps in the other sequences\n",
        "            if i == 0:\n",
        "                uppercase_cols = [\n",
        "                    j for (j, c) in enumerate(seq)\n",
        "                    if (c == c.upper() or c == \"-\")\n",
        "                ]\n",
        "                gap_template = np.array([\".\"] * len(seq))\n",
        "                filled_seq = seq\n",
        "            else:\n",
        "                uppercase_chars = [\n",
        "                    c for c in seq if c == c.upper() or c == \"-\"\n",
        "                ]\n",
        "                filled = np.copy(gap_template)\n",
        "                filled[uppercase_cols] = uppercase_chars\n",
        "                filled_seq = \"\".join(filled)\n",
        "\n",
        "        elif inserts == \"delete\":\n",
        "            # remove all lowercase letters and insert gaps .;\n",
        "            # since each sequence must have same number of\n",
        "            # uppercase letters or match gaps -, this gives\n",
        "            # the final sequence in alignment\n",
        "            seq = \"\".join([c for c in seq if c == c.upper() and c != \".\"])\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                \"Invalid option for inserts: {}\".format(inserts)\n",
        "            )\n",
        "\n",
        "        seqs[seq_id] = seq\n",
        "\n",
        "    return seqs\n"
      ],
      "metadata": {
        "id": "zrtaBGxelryQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_labels(val):\n",
        "    if 'benign' in val:\n",
        "        return 'benign'\n",
        "    elif 'pathogenic' in val:\n",
        "        return 'pathogenic'\n",
        "    else:\n",
        "        return 'VUS'\n",
        "\n",
        "def cancer_labels(val):\n",
        "    if 'cancer' in val:\n",
        "        return 'cancer'\n",
        "    else:\n",
        "        return 'non_canceric'"
      ],
      "metadata": {
        "id": "vyZD0qk0jfVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGBSmleo9Ew0"
      },
      "outputs": [],
      "source": [
        "def init_weights(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        #nn.init.normal_(m.weight, std=0.01)\n",
        "        nn.init.xavier_normal_(m.weight)\n",
        "\n",
        "    if type(m) == nn.LSTM:\n",
        "      for param in m._flat_weights_names:\n",
        "          if \"weight\" in param:\n",
        "              nn.init.xavier_uniform_(m._parameters[param])\n",
        "\n",
        "def unique(list1):\n",
        "\n",
        "    # initialize a null list\n",
        "    unique_list = []\n",
        "\n",
        "    # traverse for all elements\n",
        "    for x in list1:\n",
        "        # check if exists in unique_list or not\n",
        "        if x not in unique_list:\n",
        "            unique_list.append(x)\n",
        "\n",
        "    print(f'{len(unique_list)} unique transcripts')\n",
        "    return unique_list\n",
        "\n",
        "class ClassifierDataset(Dataset):\n",
        "\n",
        "    def __init__(self, X_data, y_data):\n",
        "        self.X_data = X_data\n",
        "        self.y_data = y_data\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data[index], self.y_data[index]\n",
        "\n",
        "    def __len__ (self):\n",
        "        return len(self.X_data)\n",
        "\n",
        "\n",
        "def get_class_distribution_binary(obj):\n",
        "    count_dict = {\n",
        "        'Neutral': 0,\n",
        "        'Deleterious': 0,\n",
        "    }\n",
        "\n",
        "    for i in obj:\n",
        "        if i == 0:\n",
        "            count_dict['Neutral'] += 1\n",
        "        elif i == 1:\n",
        "            count_dict['Deleterious'] += 1\n",
        "\n",
        "        else:\n",
        "            print(\"Check classes.\")\n",
        "\n",
        "    return count_dict\n",
        "\n",
        "\n",
        "def Average(lst):\n",
        "  return sum(lst) /len(lst)\n",
        "\n",
        "\n",
        "\n",
        "def dataset_with_indices(cls):\n",
        "    \"\"\"\n",
        "    Modifies the given Dataset class to return a tuple data, target, index\n",
        "    instead of just data, target.\n",
        "    \"\"\"\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        data, target = cls.__getitem__(self, index)\n",
        "        return data, target, index\n",
        "\n",
        "    return type(cls.__name__, (cls,), {\n",
        "        '__getitem__': __getitem__,\n",
        "    })\n",
        "\n",
        "\n",
        "DWithInd = dataset_with_indices(torch.utils.data.TensorDataset)\n",
        "\n",
        "\n",
        "\n",
        "class Classifier2L(nn.Module):\n",
        "    def __init__(self, hidden, hidden2, dropout=0):\n",
        "        super(Classifier2L, self).__init__()\n",
        "        self.hidden = hidden\n",
        "        self.hidden2 = hidden2\n",
        "        self.num_feature = 2200 #1600\n",
        "        self.dropout = dropout\n",
        "        self.batchnorm1 = nn.BatchNorm1d(self.hidden)\n",
        "        self.batchnorm2 = nn.BatchNorm1d(self.hidden2)\n",
        "\n",
        "        self.layer_1 = nn.Linear(self.num_feature,  self.hidden)\n",
        "        self.layer_2 = nn.Linear( self.hidden, self.hidden2)\n",
        "        self.layer_3 = nn.Linear( self.hidden2, 1)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer_1(x)\n",
        "        x = self.batchnorm1(x)\n",
        "        x= self.dropout(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.layer_2(x)\n",
        "        x = self.batchnorm2(x)\n",
        "        x = self.relu(x)\n",
        "        x= self.dropout(x)\n",
        "\n",
        "        x = self.layer_3(x)\n",
        "        #x = self.batchnorm2(x)\n",
        "        #x = self.sigmoid(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "    def compute_l1_loss(self, w):\n",
        "        return torch.abs(w).sum()\n",
        "\n",
        "    def compute_l2_loss(self, w):\n",
        "        return torch.square(w).sum()\n",
        "\n",
        "\n",
        "# implementation of a single testing epoch\n",
        "def test_epoch(net, loader, loss_fn):\n",
        "\n",
        "    # set the network in evaluation mode\n",
        "    net.eval()\n",
        "\n",
        "    # keep track of the loss\n",
        "    loss_cum = 0\n",
        "    cnt = 0\n",
        "    num_correct_val = 0\n",
        "    targets = []\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "      for i, data in enumerate(loader):\n",
        "\n",
        "          x, y = data\n",
        "          x = x.to(device)\n",
        "          y = y.to(device)\n",
        "\n",
        "          # feed the batch to the network and compute the outputs\n",
        "          y_pred = net(x.float())\n",
        "          #y_pred_sq = np.squeeze(y_pred) #add when using loss_fn: BCEloss()\n",
        "          pred = torch.round(y_pred.squeeze())  # rounds to the nearest integer\n",
        "\n",
        "          # compare predictions to true label\n",
        "          #correct_tensor = pred.eq(y.float().view_as(pred))\n",
        "          #correct = np.squeeze(correct_tensor.cpu().numpy())\n",
        "\n",
        "          targets.extend(y.cpu().detach().numpy().tolist())\n",
        "          predictions.extend(torch.sigmoid(y_pred).cpu().detach().numpy().tolist())\n",
        "\n",
        "          #num_correct_val += np.sum(correct)\n",
        "          # compare the outputs to the labels with the loss function\n",
        "          #loss = loss_fn(y_pred_sq, y.float())  #ad|d when using loss_fn: BCEloss()\n",
        "          loss = loss_fn(y_pred, y.float())\n",
        "\n",
        "          # Specify L1 and L2 weights\n",
        "          l1_weight = 0\n",
        "          l2_weight = 0\n",
        "\n",
        "          # Compute L1 and L2 loss component\n",
        "          parameters = []\n",
        "          for parameter in net.parameters():\n",
        "              parameters.append(parameter.view(-1))\n",
        "          l1 = l1_weight * net.compute_l1_loss(torch.cat(parameters))\n",
        "          l2 = l2_weight * net.compute_l2_loss(torch.cat(parameters))\n",
        "\n",
        "          # Add L1 and L2 loss components\n",
        "          loss += l1\n",
        "          loss += l2\n",
        "\n",
        "          loss_cum += loss.data.cpu().numpy()\n",
        "          cnt += 1\n",
        "\n",
        "    # compute the average loss\n",
        "    #len_trainx = len(loader) * len(y_pred)\n",
        "    #mytest_acc = num_correct_val\n",
        "    loss_avg = loss_cum / cnt\n",
        "    predictions = np.array(predictions) >= 0.5\n",
        "    mytest_acc  = (metrics.accuracy_score(targets, predictions)) *100\n",
        "    total = cnt *len(y)\n",
        "\n",
        "    return loss_avg, mytest_acc\n",
        "\n",
        "# implementation of a single training epoch\n",
        "def train_epoch_cross(net, loader, loss_fn, optimizer, scheduler):\n",
        "\n",
        "    # set the network in training mode\n",
        "    net.train()\n",
        "\n",
        "    # keep track of the loss\n",
        "    loss_cum = 0\n",
        "    cnt = 0\n",
        "    num_correct = 0\n",
        "    targets = []\n",
        "    predictions = []\n",
        "\n",
        "    for i, data in enumerate(loader):\n",
        "\n",
        "        # sample data\n",
        "        x, y = data\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        # set all gradients equal to zero\n",
        "        net.zero_grad()\n",
        "\n",
        "        # feed the batch to the network and compute the outputs\n",
        "        y_pred = net(x)\n",
        "        #y_pred_sq = np.squeeze(y_pred) # add when using loss_fn: BCEloss()\n",
        "\n",
        "        pred = torch.round(y_pred.squeeze())  # rounds to the nearest integer\n",
        "\n",
        "        # compare predictions to true label\n",
        "        #correct_tensor = pred.eq(y.float().view_as(pred))\n",
        "        #correct = np.squeeze(correct_tensor.cpu().numpy())\n",
        "        #num_correct += np.sum(correct)\n",
        "        targets.extend(y.cpu().detach().numpy().tolist())\n",
        "        predictions.extend(torch.sigmoid(y_pred).cpu().detach().numpy().tolist())\n",
        "\n",
        "        #predictions_round = [round(p) for p in predictions]\n",
        "        #correct_tensor = predictions_round.eq(targets.float().view_as(predictions_round))\n",
        "\n",
        "        #loss = loss_fn(y_pred_sq, y.float())  #add when using loss_fn: BCEloss()\n",
        "        loss = loss_fn(y_pred, y.float())\n",
        "\n",
        "        # Specify L1 and L2 weights\n",
        "        l1_weight = 0\n",
        "        l2_weight = 0\n",
        "\n",
        "        # Compute L1 and L2 loss component\n",
        "        parameters = []\n",
        "        for parameter in net.parameters():\n",
        "            parameters.append(parameter.view(-1))\n",
        "        l1 = l1_weight * net.compute_l1_loss(torch.cat(parameters))\n",
        "        l2 = l2_weight * net.compute_l2_loss(torch.cat(parameters))\n",
        "\n",
        "        # Add L1 and L2 loss components\n",
        "        loss += l1\n",
        "        loss += l2\n",
        "\n",
        "        loss_cum += loss.data.cpu().numpy()\n",
        "        cnt += 1\n",
        "\n",
        "        # backpropagate the gradients w.r.t. computed loss\n",
        "        loss.backward()\n",
        "\n",
        "        # apply one step in the optimization\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        #break #for training one batch\n",
        "\n",
        "    # compute the average loss\n",
        "    #mytrain_acc = num_correct\n",
        "    loss_avg = loss_cum / cnt\n",
        "\n",
        "    #predictions = np.array(predictions) >= 0.5\n",
        "    predictions = [1 if p[0] > 0.5 else 0 for p in predictions]\n",
        "    mytrain_acc  = metrics.accuracy_score(targets, predictions)   *100\n",
        "    #mytrain_acc = (num_correct/ (len(y)*cnt)) *100\n",
        "    return loss_avg, mytrain_acc\n",
        "\n",
        "def loss_fn(outputs, targets):\n",
        "  return nn.BCEWithLogitsLoss()(outputs, targets.view(-1, 1))\n",
        "\n",
        "\n",
        "def train_net_cross(net, train_loader, val_loader, loss_fn, optimizer, epochs , scheduler):\n",
        "\n",
        "    # transfer the network to the GPU\n",
        "    net = net.to(device)\n",
        "\n",
        "    train_loss = np.zeros((epochs))\n",
        "    test_loss = np.zeros((epochs))\n",
        "    train_acc = np.zeros((epochs))\n",
        "    train_acc_alt = np.zeros((epochs))\n",
        "\n",
        "    test_acc = np.zeros((epochs))\n",
        "    test_acc_alt = np.zeros((epochs))\n",
        "\n",
        "    print(\"Begin training.\")\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "\n",
        "        # training\n",
        "        train_loss[epoch], train_acc[epoch] = train_epoch_cross(net, train_loader, loss_fn, optimizer, scheduler)\n",
        "        #predictions, outputs = eval(net, train_loader)\n",
        "        #train_acc_alt[epoch] = metrics.accuracy_score(outputs, predictions)\n",
        "\n",
        "        # validation\n",
        "        test_loss[epoch], test_acc[epoch] = test_epoch(net, val_loader, loss_fn)\n",
        "        #predictions, outputs = eval(net, val_loader)\n",
        "        #test_acc_alt[epoch] = metrics.accuracy_score(outputs, predictions)\n",
        "\n",
        "        print('Epoch %5d - Train loss: %.6f - Train accuracy: %.6f - Test loss: %.6f - Test accuracy: %.6f'\n",
        "             % (epoch, train_loss[epoch], train_acc[epoch], test_loss[epoch], test_acc[epoch]))\n",
        "\n",
        "        #print('Epoch %5d - Train loss: %.6f - Train accuracy: %.6f'\n",
        "        #    % (epoch, train_loss[epoch], train_acc[epoch]))# for training one batch\n",
        "\n",
        "    return (train_loss, test_loss), (train_acc , test_acc)\n",
        "    #return train_loss, train_acc # for training one batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toKOCmDZ2oax"
      },
      "source": [
        "## Load protT5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q53cJBuw2q9H"
      },
      "outputs": [],
      "source": [
        "# Advanced\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\", do_lower_case=False )\n",
        "model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_uniref50\")\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "model = model.eval()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TP53 / BRAF confidence score"
      ],
      "metadata": {
        "id": "l4YeJ6V9jRxw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## input TP53/BRAF Clinvar expert panel and multiple submitters annotations, check if mutation iscorrect and chech if D2D prediction is correct - not used anymore"
      ],
      "metadata": {
        "id": "4pSBhzp97LEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ar_clinvar = pd.read_csv('PTEN_expert_panel_multiple_submitters', delimiter = '\\t', usecols=['Name', 'Gene(s)', 'Condition(s)' ,'Protein change', 'Clinical significance (Last reviewed)'])\n",
        "ar_clinvar['label'] = ar_clinvar['Clinical significance (Last reviewed)'].apply(clean_labels)\n",
        "ar_clinvar['condition'] = ar_clinvar['Condition(s)'].apply(cancer_labels)\n",
        "\n",
        "ar_predictions = pd.read_csv('PTEN_d2d_results.csv', sep=',')\n",
        "\n",
        "# for converting d2d_results to d2d_performance_vs_clinvar format\n",
        "temp = ar_predictions.mutation.str.split(pat='_',expand=True)[0]\n",
        "ar_predictions['uniprot id'] = temp\n",
        "temp = ar_predictions.mutation.str.split(pat='_',expand=True)[1]\n",
        "ar_predictions= ar_predictions.drop('mutation', axis=1)\n",
        "ar_predictions['mutation']= temp\n",
        "ar_predictions['AA_orig'] = ar_predictions['mutation'].str[:1]\n",
        "ar_predictions['AA_targ'] = ar_predictions['mutation'].str[-1:]\n",
        "ar_predictions['position'] = ar_predictions['mutation'].str[1:-1]\n",
        "# drop original column\n",
        "ar_predictions = ar_predictions.drop('mutation', axis=1)\n",
        "ar_predictions = ar_predictions.rename(columns={\"prediction\": \"D2D_prediction\"})\n",
        "\n",
        "correct, incorrect, vus_nb, count_mutations, incorrect_mutation, correct_mutation  = d2d_performance_vs_clinvar_correct(ar_predictions,ar_clinvar, False)\n",
        "\n",
        "print(f'Correct labels for BRAF: {correct} out of {count_mutations-vus_nb} with known significance. Accuracy: {round(correct / (count_mutations-vus_nb),3)}')\n",
        "print('--------------------------')\n",
        "print('Inorrect labels for BRAF: ', incorrect)\n",
        "print('--------------------------')\n",
        "print(f'VUS labels for BRAF: {vus_nb}, VUS percentage in gene annotations {round(vus_nb/count_mutations,3)}')"
      ],
      "metadata": {
        "id": "YuqtSd8O7ZXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tp53_clinvar = pd.read_csv('TP53_expert_panel_multiple_submitters', delimiter='\\t', usecols=['Name', 'Gene(s)', 'Condition(s)' ,'Protein change', 'Clinical significance (Last reviewed)'])\n",
        "tp53_clinvar['label'] = tp53_clinvar['Clinical significance (Last reviewed)'].apply(clean_labels)\n",
        "tp53_clinvar['condition'] = tp53_clinvar['Condition(s)'].apply(cancer_labels)\n",
        "\n",
        "tp53_predictions = pd.read_csv('P04637_all_results2.csv')"
      ],
      "metadata": {
        "id": "a9npvrGKgze5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def d2d_performance_vs_clinvar_delete(d2d_predictions, clinvar_file, cancer_flag=False):\n",
        "  if cancer_flag == True:\n",
        "    clinvar_file = clinvar_file[clinvar_file['condition']=='cancer']\n",
        "  d2d_predictions['conc_mutation'] = d2d_predictions['AA_orig'] + d2d_predictions['position'].astype(str) + d2d_predictions['AA_targ']\n",
        "  correct, incorrect, vus_nb, count_mutations = 0,0,0,0\n",
        "  incorrect_mutation, correct_mutation = [], []\n",
        "  for i, mut in clinvar_file.iterrows():\n",
        "    mutations = mut['Protein change'].split(', ')\n",
        "    for mutation in mutations:\n",
        "      temp = d2d_predictions[d2d_predictions['conc_mutation'] == mutation]\n",
        "      if len(temp) >0:\n",
        "        count_mutations+=1\n",
        "        if (mut['label'] == 'benign' and float(temp['D2D_prediction']) <0.5) or (mut['label'] == 'pathogenic' and float(temp['D2D_prediction']) >=0.5) :\n",
        "          correct+=1\n",
        "          correct_mutation.append([mut['label'],temp['conc_mutation'].values[0]])\n",
        "        elif (mut['label'] == 'pathogenic' and float(temp['D2D_prediction']) <0.5) or (mut['label'] == 'benign' and float(temp['D2D_prediction']) >=0.5):\n",
        "          incorrect+=1\n",
        "          incorrect_mutation.append([mut['label'],temp['conc_mutation'].values[0]])\n",
        "        else:\n",
        "          vus_nb+=1\n",
        "  return correct, incorrect, vus_nb, count_mutations, incorrect_mutation, correct_mutation"
      ],
      "metadata": {
        "id": "6bxzg0Ml7ZbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def AAconvert(AminoAcid):\n",
        "\n",
        "  aa = {\n",
        "      'Ala' : 'A',\n",
        "      'Arg' : 'R',\n",
        "      'Asn' : 'N',\n",
        "      'Asp' : 'D',\n",
        "      'Cys' : 'C',\n",
        "      'Glu' : 'E',\n",
        "      'Gln' : 'Q',\n",
        "      'Gly' : 'G',\n",
        "      'His' : 'H',\n",
        "      'Ile' : 'I',\n",
        "      'Leu' : 'L',\n",
        "      'Lys' : 'K',\n",
        "      'Met' : 'M',\n",
        "      'Phe' : 'F',\n",
        "      'Pro' : 'P',\n",
        "      'Ser' : 'S',\n",
        "      'Thr' : 'T',\n",
        "      'Trp' : 'W',\n",
        "      'Tyr' : 'Y',\n",
        "      'Val' : 'V',\n",
        "      'Ter' : '*'\n",
        "\n",
        "  }\n",
        "  return aa[AminoAcid]\n",
        "\n",
        "def d2d_performance_vs_clinvar_correct(d2d_predictions, clinvar_file, cancer_flag=False):\n",
        "  if cancer_flag == True:\n",
        "    clinvar_file = clinvar_file[clinvar_file['condition']=='cancer']\n",
        "  d2d_predictions['conc_mutation'] = d2d_predictions['AA_orig'] + d2d_predictions['position'].astype(str) + d2d_predictions['AA_targ']\n",
        "  correct, incorrect, vus_nb, count_mutations = 0,0,0,0\n",
        "  incorrect_mutation, correct_mutation = [], []\n",
        "  for i, mut in clinvar_file.iterrows():\n",
        "    #print(mut)\n",
        "    mutations = mut['Name'].split('(p.')[1][:-1]\n",
        "    mutation= AAconvert(mutations[:3])+ mutations[3:-3]+ AAconvert(mutations[-3:])\n",
        "\n",
        "    temp = d2d_predictions[d2d_predictions['conc_mutation'] == mutation]\n",
        "    if len(temp) >0:\n",
        "      count_mutations+=1\n",
        "      if (mut['label'] == 'benign' and float(temp['D2D_prediction']) <0.5) or (mut['label'] == 'pathogenic' and float(temp['D2D_prediction']) >=0.5) or  (mut['label'] == 'likely benign' and float(temp['D2D_prediction']) <0.5) or (mut['label'] == 'likely pathogenic' and float(temp['D2D_prediction']) >=0.5) :\n",
        "        correct+=1\n",
        "        correct_mutation.append([mut['label'],temp['conc_mutation'].values[0]])\n",
        "      elif (mut['label'] == 'pathogenic' and float(temp['D2D_prediction']) <0.5) or (mut['label'] == 'benign' and float(temp['D2D_prediction']) >=0.5) or (mut['label'] == 'likely pathogenic' and float(temp['D2D_prediction']) <0.5) or (mut['label'] == 'likely benign' and float(temp['D2D_prediction']) >=0.5):\n",
        "        incorrect+=1\n",
        "        incorrect_mutation.append([mut['label'],temp['conc_mutation'].values[0]])\n",
        "      else:\n",
        "        vus_nb+=1\n",
        "  return correct, incorrect, vus_nb, count_mutations, incorrect_mutation, correct_mutation"
      ],
      "metadata": {
        "id": "frfOoDwvupy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct, incorrect, vus_nb, count_mutations, incorrect_mutation, correct_mutation = d2d_performance_vs_clinvar_correct(tp53_predictions,tp53_clinvar, False)\n",
        "\n",
        "print(f'Correct labels for TP53: {correct} out of {count_mutations-vus_nb} with known significance. Accuracy: {round(correct / (count_mutations-vus_nb),3)}')\n",
        "print('--------------------------')\n",
        "print('Inorrect labels for TP53: ', incorrect)\n",
        "print('--------------------------')\n",
        "print(f'VUS labels for TP53: {vus_nb}, VUS percentage in gene annotations {round(vus_nb/count_mutations,3)}')"
      ],
      "metadata": {
        "id": "HQ-mmjmsu8w2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct, incorrect, vus_nb, count_mutations, incorrect_mutation, correct_mutation = d2d_performance_vs_clinvar(tp53_predictions,tp53_clinvar, False)\n",
        "\n",
        "print(f'Correct labels for TP53: {correct} out of {count_mutations-vus_nb} with known significance. Accuracy: {round(correct / (count_mutations-vus_nb),3)}')\n",
        "print('--------------------------')\n",
        "print('Inorrect labels for TP53: ', incorrect)\n",
        "print('--------------------------')\n",
        "print(f'VUS labels for TP53: {vus_nb}, VUS percentage in gene annotations {round(vus_nb/count_mutations,3)}')"
      ],
      "metadata": {
        "id": "I2Pdp1W4UHFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "braf_clinvar = pd.read_csv('BRAF_expert_panel_multiple_submitters.csv', usecols=['Gene(s)', 'Condition(s)' ,'Protein change', 'Clinical significance (Last reviewed)'])\n",
        "braf_clinvar['label'] = braf_clinvar['Clinical significance (Last reviewed)'].apply(clean_labels)\n",
        "braf_clinvar['condition'] = braf_clinvar['Condition(s)'].apply(cancer_labels)\n",
        "\n",
        "braf_predictions = pd.read_csv('P15056_all_results.csv', sep=',')\n",
        "\n",
        "correct, incorrect, vus_nb, count_mutations, incorrect_mutation, correct_mutation = d2d_performance_vs_clinvar(braf_predictions,braf_clinvar, False)\n",
        "\n",
        "print(f'Correct labels for BRAF: {correct} out of {count_mutations-vus_nb} with known significance. Accuracy: {round(correct / (count_mutations-vus_nb),3)}')\n",
        "print('--------------------------')\n",
        "print('Incorrect labels for BRAF: ', incorrect)\n",
        "print('--------------------------')\n",
        "print(f'VUS labels for BRAF: {vus_nb}, VUS percentage in gene annotations {round(vus_nb/count_mutations,3)}')"
      ],
      "metadata": {
        "id": "JLIJVJs5QIV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = pd.read_csv('TP53_formatted.csv', usecols=['score'])\n",
        "predictions = predictions['score'].tolist()"
      ],
      "metadata": {
        "id": "uWh-jpp-P8h9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "tp53 = pd.read_csv('TP53.csv')\n",
        "mutation = tp53['mutation'].tolist()\n",
        "prob_benign = tp53['prob_benign'].tolist()\n",
        "prob_pathogenic  = tp53['prob_pathogenic'].tolist()\n",
        "WT_thres = tp53['WT_thres'].tolist()\n",
        "MUT_thres = tp53['MUT_thres'].tolist()"
      ],
      "metadata": {
        "id": "zcex9fe5v6d3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tp = pd.DataFrame(list(zip(mutation,prob_benign,prob_pathogenic, WT_thres,MUT_thres, predictions)), columns =['mutation',\t'prob_benign'\t,'prob_pathogenic',\t'WT_thres','MUT_thres', 'prediction'])\n",
        "print(tp.head())"
      ],
      "metadata": {
        "id": "MitK9LJC0ei_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tp.to_csv('tp53.csv', index=False)"
      ],
      "metadata": {
        "id": "l4cTli1t07xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "benign = tp[tp['prediction']<0.5]\n",
        "x_b = benign['WT_thres'].tolist()\n",
        "y_b = benign['MUT_thres'].tolist()"
      ],
      "metadata": {
        "id": "xsF8ofxuBGkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pathogenic = tp[tp['prediction']>=0.5]\n",
        "x_p = pathogenic['WT_thres'].tolist()\n",
        "y_p = pathogenic['MUT_thres'].tolist()"
      ],
      "metadata": {
        "id": "H7aZr-x2BHJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(min(x_b),max(x_b) ,min(y_b), max(y_b))\n",
        "print(min(x_p),max(x_p) ,min(y_p), max(y_p))"
      ],
      "metadata": {
        "id": "GsgJdNx_BHLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## confidence - log-likelihood GMM"
      ],
      "metadata": {
        "id": "PK_DKEvc7i4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.neighbors import KernelDensity\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as st\n",
        "import plotly.express as px\n",
        "import statistics\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "path = '/content/drive/MyDrive/my_colab/3rdYear/GMM/confidence/'\n",
        "\n",
        "# Define a function to split the string and create new columns\n",
        "def split_string(row):\n",
        "    first = row[0]\n",
        "    last = row[-1]\n",
        "    rest = row[1:-1]\n",
        "    return first, last, rest\n",
        "\n",
        "\n",
        "def clean_labels(val):\n",
        "    if 'Likely benign' in val:\n",
        "        return 'likely benign'\n",
        "    elif 'Benign' in val:\n",
        "        return 'benign'\n",
        "    elif 'Likely pathogenic' in val:\n",
        "        return 'likely pathogenic'\n",
        "    elif 'Pathogenic' in val:\n",
        "        return 'pathogenic'\n",
        "    else:\n",
        "        return 'VUS'\n",
        "\n",
        "def cancer_labels(val):\n",
        "    if 'cancer' in val:\n",
        "        return 'cancer'\n",
        "    else:\n",
        "        return 'non_canceric'\n",
        "\n",
        "def AAconvert(AminoAcid):\n",
        "\n",
        "  aa = {\n",
        "      'Ala' : 'A',\n",
        "      'Arg' : 'R',\n",
        "      'Asn' : 'N',\n",
        "      'Asp' : 'D',\n",
        "      'Cys' : 'C',\n",
        "      'Glu' : 'E',\n",
        "      'Gln' : 'Q',\n",
        "      'Gly' : 'G',\n",
        "      'His' : 'H',\n",
        "      'Ile' : 'I',\n",
        "      'Leu' : 'L',\n",
        "      'Lys' : 'K',\n",
        "      'Met' : 'M',\n",
        "      'Phe' : 'F',\n",
        "      'Pro' : 'P',\n",
        "      'Ser' : 'S',\n",
        "      'Thr' : 'T',\n",
        "      'Trp' : 'W',\n",
        "      'Tyr' : 'Y',\n",
        "      'Val' : 'V',\n",
        "      'Ter' : '*'\n",
        "\n",
        "  }\n",
        "  return aa[AminoAcid]\n",
        "\n",
        "\n",
        "def d2d_performance_vs_clinvar_labels_correct(d2d_predictions, clinvar_file, cancer_flag=False):\n",
        "  if cancer_flag == True:\n",
        "    clinvar_file = clinvar_file[clinvar_file['condition']=='cancer']\n",
        "  d2d_predictions['conc_mutation'] = d2d_predictions['AA_orig'] + d2d_predictions['position'].astype(str) + d2d_predictions['AA_targ']\n",
        "  #d2d_predictions['conc_mutation'] = d2d_predictions['AA_orig'] + d2d_predictions['position'] + d2d_predictions['AA_targ']\n",
        "  correct, incorrect, vus_nb, count_mutations,another_reference = 0,0,0,0,0\n",
        "  incorrect_mutation, correct_mutation, correct_label = [], [], []\n",
        "  clinvar_file = clinvar_file[clinvar_file['Protein change'].notna()]\n",
        "  predictions_clinvar_labels = pd.DataFrame(columns =  [\"uniprot id\", \"WT_sequence\",\"mut_sequence\", \"AA_orig\", \"position\", \"AA_targ\", \"D2D_prediction\", \"conc_mutation\",\"lab_clinvar\", \"overall_confidence\"])\n",
        "\n",
        "  for i, mut in clinvar_file.iterrows():\n",
        "    mutations = mut['Name'].split('(p.')[1][:-1]\n",
        "    mutation= AAconvert(mutations[:3])+ mutations[3:-3]+ AAconvert(mutations[-3:])\n",
        "\n",
        "    temp = d2d_predictions[d2d_predictions['conc_mutation'] == mutation]\n",
        "\n",
        "    if len(temp) >0:\n",
        "      count_mutations+=1\n",
        "      if (mut['label'] == 'benign' and float(temp['D2D_prediction']) <0.5) or (mut['label'] == 'likely benign' and float(temp['D2D_prediction']) <0.5)  or (mut['label'] == 'pathogenic' and float(temp['D2D_prediction']) >=0.5) or (mut['label'] == 'likely pathogenic' and float(temp['D2D_prediction']) >=0.5):\n",
        "        correct+=1\n",
        "        correct_mutation.append([mut['label'],temp['conc_mutation'].values[0]])\n",
        "        temp['lab_clinvar'] = mut['label']\n",
        "        temp['condition'] = str(mut['condition'])\n",
        "        temp['correct_label'] = [1]\n",
        "        predictions_clinvar_labels = predictions_clinvar_labels.append(temp)\n",
        "      elif (mut['label'] == 'pathogenic' and float(temp['D2D_prediction']) <0.5) or (mut['label'] == 'likely pathogenic' and float(temp['D2D_prediction']) <0.5) or  (mut['label'] == 'benign' and float(temp['D2D_prediction']) >=0.5) or (mut['label'] == 'likely benign' and float(temp['D2D_prediction']) >=0.5):\n",
        "        incorrect+=1\n",
        "        incorrect_mutation.append([mut['label'],temp['conc_mutation'].values[0]])\n",
        "        temp['condition'] = str(mut['condition'])\n",
        "        temp['lab_clinvar'] = mut['label']\n",
        "        temp['correct_label'] = [0]\n",
        "        predictions_clinvar_labels = predictions_clinvar_labels.append(temp)\n",
        "      elif mut['label'] == 'VUS' and float(temp['D2D_prediction'] < 0.5):\n",
        "        temp['lab_clinvar'] = ['VUS, D2D benign']\n",
        "        temp['correct_label'] = ['VUS']\n",
        "        temp['condition'] = str(mut['condition'])\n",
        "        vus_nb+=1\n",
        "        temp['condition'] = str(mut['condition'])\n",
        "        predictions_clinvar_labels = predictions_clinvar_labels.append(temp)\n",
        "      elif mut['label'] == 'VUS' and float(temp['D2D_prediction'] >= 0.5):\n",
        "        temp['lab_clinvar'] = ['VUS, D2D deleterious']\n",
        "        temp['correct_label'] = ['VUS']\n",
        "        temp['condition'] = str(mut['condition'])\n",
        "        vus_nb+=1\n",
        "        predictions_clinvar_labels = predictions_clinvar_labels.append(temp)\n",
        "    else:\n",
        "      pass # another reference genome\n",
        "\n",
        "  return correct, incorrect, vus_nb, count_mutations, incorrect_mutation, correct_mutation, predictions_clinvar_labels\n",
        "\n",
        "def predictions_clinvarlabels_preprocessing(gene):\n",
        "  clinvar = pd.read_csv(path+gene +'_expert_multiple_single_submitters.txt', delimiter='\\t', usecols=['Name', 'Gene(s)', 'Condition(s)' ,'Protein change', 'Clinical significance (Last reviewed)'])\n",
        "  clinvar['label'] = clinvar['Clinical significance (Last reviewed)'].apply(clean_labels)\n",
        "  clinvar['condition'] = clinvar['Condition(s)'].apply(cancer_labels)\n",
        "\n",
        "  predictions = pd.read_csv(path+gene+ '_d2d_results.csv')\n",
        "\n",
        "  # for converting d2d_results to d2d_performance_vs_clinvar format\n",
        "  temp = predictions.mutation.str.split(pat='_',expand=True)[0]\n",
        "  predictions['uniprot id'] = temp\n",
        "  temp = predictions.mutation.str.split(pat='_',expand=True)[1]\n",
        "  predictions= predictions.drop('mutation', axis=1)\n",
        "  predictions['mutation']= temp\n",
        "  predictions['AA_orig'] = predictions['mutation'].str[:1]\n",
        "  predictions['AA_targ'] = predictions['mutation'].str[-1:]\n",
        "  predictions['position'] = predictions['mutation'].str[1:-1]\n",
        "  # drop original column\n",
        "  predictions = predictions.drop('mutation', axis=1)\n",
        "  predictions = predictions.rename(columns={\"prediction\": \"D2D_prediction\"})\n",
        "\n",
        "  return predictions, clinvar\n",
        "\n",
        "def normalise_confidence(gene_confidence):\n",
        "\n",
        "  # min max\n",
        "  max_log = max(gene_confidence['Log_prob'].tolist())\n",
        "  min_log = min(gene_confidence['Log_prob'].tolist())\n",
        "  gene_confidence['log_normalized'] = (gene_confidence['Log_prob'] - min_log )/(max_log - min_log)\n",
        "  condition1 = gene_confidence['D2D_prediction'] >= 0.5 # for the 5 initial genes TP53, PTEN, AR, BRAF and ChEK2: D2D_prediction\n",
        "  condition2 = (gene_confidence['log_normalized'] >= 0.5) & (gene_confidence['D2D_prediction'] < 0.5)\n",
        "  condition3 = (gene_confidence['log_normalized'] < 0.5) & (gene_confidence['D2D_prediction'] < 0.5)\n",
        "\n",
        "  # using log-GMM\n",
        "  gene_confidence.loc[condition1, 'overall_confidence'] = gene_confidence.loc[condition1, 'log_normalized']   # Set values in 'B' as half of values in 'C' when the condition is met\n",
        "  gene_confidence.loc[condition2, 'overall_confidence'] = abs(1- gene_confidence.loc[condition2, 'log_normalized'] ) # *1.2#Set values in 'B' as half of values in 'D' when the condition is not met\n",
        "  gene_confidence.loc[condition3, 'overall_confidence'] = 1- gene_confidence.loc[condition3, 'log_normalized']*1.3\n",
        "\n",
        "  return gene_confidence"
      ],
      "metadata": {
        "id": "qTPM-dgK_hQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Overall Clinvar (690 mutations) performance VERSUS Weighted quality performance"
      ],
      "metadata": {
        "id": "8i2m2I4m_hQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tp53_confidenceAB =pd.read_csv(path+'TP53_confidenceAB.csv')\n",
        "braf_confidenceAB =pd.read_csv(path+'BRAF_confidenceAB.csv')\n",
        "pten_confidenceAB =pd.read_csv(path+'PTEN_confidenceAB.csv')\n",
        "chek2_confidenceAB =pd.read_csv(path+'CHEK2_confidenceAB.csv')\n",
        "ar_confidenceAB =pd.read_csv(path+'AR_confidenceAB.csv')\n",
        "# predictions preprocessing\n",
        "tp53_predictions, tp53_clinvar= predictions_clinvarlabels_preprocessing('TP53')\n",
        "tp53_predictions['Log_prob'] = tp53_confidenceAB['Log_prob']\n",
        "tp53_predictions['prob_benign'] = tp53_confidenceAB['prob_benign']\n",
        "tp53_predictions['prob_pathogenic'] = tp53_confidenceAB['prob_pathogenic']\n",
        "tp53_predictions = normalise_confidence(tp53_predictions)\n",
        "\n",
        "braf_predictions, braf_clinvar= predictions_clinvarlabels_preprocessing('BRAF')\n",
        "braf_predictions['Log_prob'] = braf_confidenceAB['Log_prob']\n",
        "braf_predictions['prob_benign'] = braf_confidenceAB['prob_benign']\n",
        "braf_predictions['prob_pathogenic'] = braf_confidenceAB['prob_pathogenic']\n",
        "braf_predictions = normalise_confidence(braf_predictions)\n",
        "\n",
        "pten_predictions, pten_clinvar= predictions_clinvarlabels_preprocessing('PTEN')\n",
        "pten_predictions['Log_prob'] = pten_confidenceAB['Log_prob']\n",
        "pten_predictions['prob_benign'] = pten_confidenceAB['prob_benign']\n",
        "pten_predictions['prob_pathogenic'] = pten_confidenceAB['prob_pathogenic']\n",
        "pten_predictions = normalise_confidence(pten_predictions)\n",
        "\n",
        "chek2_predictions, chek2_clinvar= predictions_clinvarlabels_preprocessing('CHEK2')\n",
        "chek2_predictions['Log_prob'] = chek2_confidenceAB['Log_prob']\n",
        "chek2_predictions['prob_benign'] = chek2_confidenceAB['prob_benign']\n",
        "chek2_predictions['prob_pathogenic'] = chek2_confidenceAB['prob_pathogenic']\n",
        "chek2_predictions = normalise_confidence(chek2_predictions)\n",
        "\n",
        "ar_predictions, ar_clinvar= predictions_clinvarlabels_preprocessing('AR')\n",
        "ar_predictions['Log_prob'] = ar_confidenceAB['Log_prob']\n",
        "ar_predictions['prob_benign'] = ar_confidenceAB['prob_benign']\n",
        "ar_predictions['prob_pathogenic'] = ar_confidenceAB['prob_pathogenic']\n",
        "ar_predictions = normalise_confidence(ar_predictions)\n",
        "\n",
        "# Assign a weight to each prediction based on its confidence level\n",
        "# call function to calculate overall performance\n",
        "correct_tp53, incorrect_tp53, vus_nb_tp53, count_mutations_tp53, incorrect_mutation_tp53, correct_mutation_tp53, predictions_clinvar_labels_tp53 = d2d_performance_vs_clinvar_labels_correct(tp53_predictions, tp53_clinvar, False)\n",
        "correct_braf, incorrect_braf, vus_nb_braf, count_mutations_braf, incorrect_mutation_braf, correct_mutation_braf, predictions_clinvar_labels_braf = d2d_performance_vs_clinvar_labels_correct(braf_predictions,braf_clinvar, False)\n",
        "correct_pten, incorrect_pten, vus_nb_pten, count_mutations_pten, incorrect_mutation_pten, correct_mutation_pten, predictions_clinvar_labels_pten = d2d_performance_vs_clinvar_labels_correct(pten_predictions,pten_clinvar, False)\n",
        "correct_chek2, incorrect_chek2, vus_nb_chek2, count_mutations_chek2, incorrect_mutation_chek2, correct_mutation_chek2, predictions_clinvar_labels_chek2 = d2d_performance_vs_clinvar_labels_correct(chek2_predictions,chek2_clinvar, False)\n",
        "correct_ar, incorrect_ar, vus_nb_ar, count_mutations_ar, incorrect_mutation_ar, correct_mutation_ar, predictions_clinvar_labels_ar = d2d_performance_vs_clinvar_labels_correct(ar_predictions,ar_clinvar, False)"
      ],
      "metadata": {
        "id": "W94lsC6Q_hQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# concatenate TP53, PTEN, AR, BRAF, CHEK2 predictions in one df\n",
        "all_predictions_labels = pd.concat([predictions_clinvar_labels_tp53, predictions_clinvar_labels_braf,predictions_clinvar_labels_pten, predictions_clinvar_labels_chek2, predictions_clinvar_labels_ar ], ignore_index=True)\n",
        "#all_norma = normalise_confidence(all_predictions_labels)"
      ],
      "metadata": {
        "id": "RQxH-64Y_hQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(max(all_predictions_labels['Log_prob']), max(all_predictions_labels['overall_confidence']))\n",
        "print(min(all_predictions_labels['Log_prob']), min(all_predictions_labels['overall_confidence']))"
      ],
      "metadata": {
        "id": "fQ1KtktbGBxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labelled = all_predictions_labels[all_predictions_labels['correct_label'] != 'VUS']\n",
        "\n",
        "weighted_sum = (labelled['overall_confidence'] * labelled['correct_label']).sum()\n",
        "total_weight = labelled['overall_confidence'].sum()\n",
        "weighted_average = weighted_sum / total_weight\n",
        "print(weighted_average)"
      ],
      "metadata": {
        "id": "G413OBLe_hQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DMS"
      ],
      "metadata": {
        "id": "jS-BjE7ukqFB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TP53"
      ],
      "metadata": {
        "id": "h4h6YSjtkuJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tp53_confidenceAB =pd.read_csv(path+'TP53_confidenceAB.csv')\n",
        "dms_mutations = pd.read_csv('/content/drive/MyDrive/my_colab/3rdYear/datasets/DMS_mutations.csv')\n",
        "\n",
        "dms_mutations_tp53 = dms_mutations[dms_mutations['uniprot id'] == 'P04637-1']\n",
        "dms_mutations_tp53['position'] = dms_mutations_tp53['position'].astype(str) # comment when KDE is used\n",
        "\n",
        "tp53_predictions = pd.read_csv('/content/drive/MyDrive/TP53_d2d_results2.csv')\n",
        "tp53_predictions = tp53_predictions.rename(columns={\"prediction\": \"D2D_prediction\"})\n",
        "tp53_predictions['Log_prob'] = tp53_confidenceAB['Log_prob']\n",
        "# when using KDE\n",
        "tp53_predictions['AA_orig'] = tp53_predictions['mutation'].str[:1]\n",
        "tp53_predictions['AA_targ'] = tp53_predictions['mutation'].str[-1:]\n",
        "tp53_predictions['position'] = tp53_predictions['mutation'].str[1:-1]\n",
        "\n",
        "tp53_predictions['Log_prob'] = tp53_confidenceAB['Log_prob']\n",
        "tp53_predictions['prob_benign'] = tp53_confidenceAB['prob_benign']\n",
        "tp53_predictions['prob_pathogenic'] = tp53_confidenceAB['prob_pathogenic']\n",
        "\n",
        "# for converting d2d_results to d2d_performance_vs_clinvar format\n",
        "temp = tp53_predictions.mutation.str.split(pat='_',expand=True)[0]\n",
        "tp53_predictions['uniprot id'] = temp\n",
        "\n",
        "temp = tp53_predictions.mutation.str.split(pat='_',expand=True)[1]\n",
        "tp53_predictions= tp53_predictions.drop('mutation', axis=1)\n",
        "tp53_predictions['mutation']= temp\n",
        "\n",
        "tp53_predictions['AA_orig'] = tp53_predictions['mutation'].str[:1]\n",
        "tp53_predictions['AA_targ'] = tp53_predictions['mutation'].str[-1:]\n",
        "tp53_predictions['position'] = tp53_predictions['mutation'].str[1:-1]\n",
        "\n",
        "tp53_predictions= normalise_confidence(tp53_predictions)\n",
        "# Merge df1 and df2 based on columns \"AA_orig\", \"AA_targ\", \"position\"\n",
        "merged_df = pd.merge(tp53_predictions, dms_mutations_tp53,  on=[\"AA_orig\", \"AA_targ\", \"position\"])\n",
        "# Select the values from df1's \"contin_label\" and df2's \"prediction\"\n",
        "selected_values = merged_df[[\"contin_label\", \"D2D_prediction\",  \"overall_confidence\", \"log_normalized\"]]"
      ],
      "metadata": {
        "id": "B8vB1U3Xkrvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot correlation\n",
        "correlation, p_value = stats.pearsonr(selected_values['contin_label'], selected_values['D2D_prediction'])\n",
        "\n",
        "sns.set_theme()\n",
        "plt.rcParams[\"figure.figsize\"] = (11,8)\n",
        "plt.figure(facecolor='white')\n",
        "plt.rcParams['axes.facecolor'] = 'white'\n",
        "\n",
        "#plt.scatter(selected_values['contin_label'], selected_values['prediction'], alpha=0.6, c = selected_values['contin_label'], cmap=\"viridis\")\n",
        "plt.scatter(selected_values['contin_label'], selected_values['D2D_prediction'], alpha=0.4, c = selected_values['overall_confidence'], cmap=\"viridis\")\n",
        "plt.xlabel('enrichment ratio (ER) score', fontweight='bold', color = 'grey' )\n",
        "plt.ylabel('D2Deep predictions', fontweight='bold', color = 'grey')\n",
        "\n",
        "#find line of best fit\n",
        "#a, b = np.polyfit(selected_values['contin_label'], selected_values['D2D_prediction'],1)\n",
        "#plt.plot(selected_values['contin_label'], a*selected_values['contin_label']+b, color = '#636e6c')\n",
        "\n",
        "plt.xticks(color = 'grey',fontweight='bold')\n",
        "plt.yticks(color = 'grey',fontweight='bold')\n",
        "#plt.text(0.6, 0.1, 'y = ' + '{:.2f}'.format(b) + '+' + ' {:.2f}'.format(a) + 'x', size=20, color='gray',  fontweight='bold')\n",
        "plt.title(\"D2D predictions versus enrichment ratio (ER) score for TP53\",fontsize = 15, fontweight='bold', color = 'grey')\n",
        "# plt.colorbar(label=\"Continuous predictions\", orientation=\"horizontal\")\n",
        "\n",
        "colorbar = plt.colorbar(orientation=\"horizontal\")\n",
        "# Set the color of the colorbar label\n",
        "colorbar.set_label('Confidence score', color='grey')\n",
        "colorbar.ax.tick_params(colors='grey')\n",
        "plt.grid(color = 'green', linestyle = '--', axis = 'y', linewidth = 0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xciNFEgwDKdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(correlation,p_value)"
      ],
      "metadata": {
        "id": "ry_saGujlJyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "quantify"
      ],
      "metadata": {
        "id": "cl2pg57ecLDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Neutral -0.3 < DMS ER < 0.2\n",
        "# Benign DMS ER > 0.2\n",
        "# Pathogneic DMS ER -< 0.3\n",
        "benign_DMS_benign_pred = selected_values[(selected_values['contin_label'] >=0.2) & (selected_values['D2D_prediction'] <0.5 )]\n",
        "benign_DMS_pathogenic_pred = selected_values[(selected_values['contin_label'] >=0.2) & (selected_values['D2D_prediction'] >=0.5 )]\n",
        "pathogenic_DMS_pathogenic_pred = selected_values[(selected_values['contin_label']<-0.3) & (selected_values['D2D_prediction'] >= 0.5 )]\n",
        "pathogenic_DMS_benign_pred = selected_values[(selected_values['contin_label']<-0.3) & (selected_values['D2D_prediction'] < 0.5 )]\n",
        "\n",
        "benign_DMS_benign_pred=benign_DMS_benign_pred.sample(frac=1).reset_index(drop=True)\n",
        "benign_DMS_benign_pred = benign_DMS_benign_pred.iloc[:round(len(benign_DMS_benign_pred))]  # Replace with the desired subset from the four lists\n",
        "\n",
        "benign_DMS_pathogenic_pred= benign_DMS_pathogenic_pred.sample(frac=1).reset_index(drop=True)\n",
        "benign_DMS_pathogenic_pred = benign_DMS_pathogenic_pred.iloc[:round(len(benign_DMS_pathogenic_pred))]\n",
        "\n",
        "pathogenic_DMS_pathogenic_pred= pathogenic_DMS_pathogenic_pred.sample(frac=1).reset_index(drop=True)\n",
        "pathogenic_DMS_pathogenic_pred = pathogenic_DMS_pathogenic_pred.iloc[:round(len(pathogenic_DMS_pathogenic_pred))]\n",
        "\n",
        "pathogenic_DMS_benign_pred= pathogenic_DMS_benign_pred.sample(frac=1).reset_index(drop=True)\n",
        "pathogenic_DMS_benign_pred = pathogenic_DMS_benign_pred.iloc[:round(len(pathogenic_DMS_benign_pred))]\n",
        "\n",
        "subset=[benign_DMS_benign_pred['overall_confidence'].tolist(), benign_DMS_pathogenic_pred['overall_confidence'].tolist(), pathogenic_DMS_pathogenic_pred['overall_confidence'].tolist(),  pathogenic_DMS_benign_pred['overall_confidence'].tolist()]\n",
        "\n",
        "xs = []\n",
        "for i, mut in enumerate(subset):\n",
        "    xs.append(np.random.normal(i+1 , 0.03, len(mut)))  # adds jitter to the data points - can be adjusted\n",
        "\n",
        "plt.boxplot(subset, showfliers=False)\n",
        "palette = ['g', '#BDEFC6', 'r', '#FBDDDD']\n",
        "for x, val, c in zip(xs, subset, palette):\n",
        "    plt.scatter(x, val, alpha=0.4, color=c)\n",
        "\n",
        "plt.ylabel('Confidence scores')\n",
        "#plt.xticks([1,2,3,4], ['Benign predictions for experimentally benign', 'Pathogenic predictions for experimentally benign', 'pathogenic','pathogenic' ])\n",
        "plt.grid(color = 'gray', linestyle = '--', axis = 'y', linewidth = 0.5)\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F6pdLOMF3QVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "wilcoxon rank sum test"
      ],
      "metadata": {
        "id": "5ySOmENK2-_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import ranksums\n",
        "\n",
        "correct = benign_DMS_benign_pred['overall_confidence'].tolist() + pathogenic_DMS_pathogenic_pred['overall_confidence'].tolist()\n",
        "incorrect = benign_DMS_pathogenic_pred['overall_confidence'].tolist()+ pathogenic_DMS_benign_pred['overall_confidence'].tolist()\n",
        "\n",
        "print(ranksums(correct, incorrect))"
      ],
      "metadata": {
        "id": "yJJd1tzz12tE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5 genes"
      ],
      "metadata": {
        "id": "Nk-XZIlJHx-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tp53_confidenceAB =pd.read_csv(path+'TP53_confidenceAB.csv')\n",
        "braf_confidenceAB =pd.read_csv(path+'BRAF_confidenceAB.csv')\n",
        "pten_confidenceAB =pd.read_csv(path+'PTEN_confidenceAB.csv')\n",
        "chek2_confidenceAB =pd.read_csv(path+'CHEK2_confidenceAB.csv')\n",
        "ar_confidenceAB =pd.read_csv(path+'AR_confidenceAB.csv')\n",
        "# predictions preprocessing\n",
        "tp53_predictions, tp53_clinvar= predictions_clinvarlabels_preprocessing('TP53')\n",
        "tp53_predictions['Log_prob'] = tp53_confidenceAB['Log_prob']\n",
        "tp53_predictions['prob_benign'] = tp53_confidenceAB['prob_benign']\n",
        "tp53_predictions['prob_pathogenic'] = tp53_confidenceAB['prob_pathogenic']\n",
        "tp53_predictions = normalise_confidence(tp53_predictions)\n",
        "\n",
        "braf_predictions, braf_clinvar= predictions_clinvarlabels_preprocessing('BRAF')\n",
        "braf_predictions['Log_prob'] = braf_confidenceAB['Log_prob']\n",
        "braf_predictions['prob_benign'] = braf_confidenceAB['prob_benign']\n",
        "braf_predictions['prob_pathogenic'] = braf_confidenceAB['prob_pathogenic']\n",
        "braf_predictions = normalise_confidence(braf_predictions)\n",
        "\n",
        "pten_predictions, pten_clinvar= predictions_clinvarlabels_preprocessing('PTEN')\n",
        "pten_predictions['Log_prob'] = pten_confidenceAB['Log_prob']\n",
        "pten_predictions['prob_benign'] = pten_confidenceAB['prob_benign']\n",
        "pten_predictions['prob_pathogenic'] = pten_confidenceAB['prob_pathogenic']\n",
        "pten_predictions = normalise_confidence(pten_predictions)\n",
        "\n",
        "chek2_predictions, chek2_clinvar= predictions_clinvarlabels_preprocessing('CHEK2')\n",
        "chek2_predictions['Log_prob'] = chek2_confidenceAB['Log_prob']\n",
        "chek2_predictions['prob_benign'] = chek2_confidenceAB['prob_benign']\n",
        "chek2_predictions['prob_pathogenic'] = chek2_confidenceAB['prob_pathogenic']\n",
        "chek2_predictions = normalise_confidence(chek2_predictions)\n",
        "\n",
        "ar_predictions, ar_clinvar= predictions_clinvarlabels_preprocessing('AR')\n",
        "ar_predictions['Log_prob'] = ar_confidenceAB['Log_prob']\n",
        "ar_predictions['prob_benign'] = ar_confidenceAB['prob_benign']\n",
        "ar_predictions['prob_pathogenic'] = ar_confidenceAB['prob_pathogenic']\n",
        "ar_predictions = normalise_confidence(ar_predictions)\n",
        "\n",
        "# Assign a weight to each prediction based on its confidence level\n",
        "# call function to calculate overall performance\n",
        "correct_tp53, incorrect_tp53, vus_nb_tp53, count_mutations_tp53, incorrect_mutation_tp53, correct_mutation_tp53, predictions_clinvar_labels_tp53 = d2d_performance_vs_clinvar_labels_correct(tp53_predictions, tp53_clinvar, False)\n",
        "correct_braf, incorrect_braf, vus_nb_braf, count_mutations_braf, incorrect_mutation_braf, correct_mutation_braf, predictions_clinvar_labels_braf = d2d_performance_vs_clinvar_labels_correct(braf_predictions,braf_clinvar, False)\n",
        "correct_pten, incorrect_pten, vus_nb_pten, count_mutations_pten, incorrect_mutation_pten, correct_mutation_pten, predictions_clinvar_labels_pten = d2d_performance_vs_clinvar_labels_correct(pten_predictions,pten_clinvar, False)\n",
        "correct_chek2, incorrect_chek2, vus_nb_chek2, count_mutations_chek2, incorrect_mutation_chek2, correct_mutation_chek2, predictions_clinvar_labels_chek2 = d2d_performance_vs_clinvar_labels_correct(chek2_predictions,chek2_clinvar, False)\n",
        "correct_ar, incorrect_ar, vus_nb_ar, count_mutations_ar, incorrect_mutation_ar, correct_mutation_ar, predictions_clinvar_labels_ar = d2d_performance_vs_clinvar_labels_correct(ar_predictions,ar_clinvar, False)"
      ],
      "metadata": {
        "id": "JR7IQc5P_4if"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tp53_predictions.to_csv(path+'TP53_d2d_results_confidence.csv')\n",
        "#braf_predictions.to_csv(path+'BRAF_d2d_results_confidence.csv')\n",
        "#pten_predictions.to_csv(path+'PTEN_d2d_results_confidence.csv')\n",
        "#chek2_predictions.to_csv(path+'CHEK2_d2d_results_confidence.csv')\n",
        "#ar_predictions.to_csv(path+'AR_d2d_results_confidence.csv')"
      ],
      "metadata": {
        "id": "aSLpxZerSsvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# concatenate TP53, PTEN, AR, BRAF, CHEK2 predictions in one df\n",
        "all_predictions_labels = pd.concat([predictions_clinvar_labels_tp53, predictions_clinvar_labels_braf,predictions_clinvar_labels_pten, predictions_clinvar_labels_chek2, predictions_clinvar_labels_ar ], ignore_index=True)"
      ],
      "metadata": {
        "id": "yb4VB5dH_-4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labelled = all_predictions_labels[all_predictions_labels['correct_label'] != 'VUS']\n",
        "\n",
        "weighted_sum = (labelled['overall_confidence'] * labelled['correct_label']).sum()\n",
        "total_weight = labelled['overall_confidence'].sum()\n",
        "weighted_average = weighted_sum / total_weight\n",
        "print(weighted_average)"
      ],
      "metadata": {
        "id": "OvVlOnAyKwMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TP53"
      ],
      "metadata": {
        "id": "nl_88xl5TUT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tp53 = all_predictions_labels[all_predictions_labels['uniprot id'] == 'P04637']\n",
        "tp53_labelled = labelled[labelled['uniprot id'] == 'P04637']\n",
        "\n",
        "correct =tp53_labelled['correct_label'].sum()\n",
        "print(f'Correct labels for TP53: { round(correct)} out of {len(tp53_labelled)} with known significance. Accuracy: {round(correct/ len(tp53_labelled),3)}')\n",
        "print('--------------------------')\n",
        "print('Inorrect labels for TP53: ', len(tp53_labelled[tp53_labelled['correct_label'] == 0]))\n",
        "print('--------------------------')\n",
        "print(f'VUS labels for TP53: {len(tp53) - len(tp53_labelled)}, VUS percentage in gene annotations {round(len(tp53) - len(tp53_labelled)/len(tp53),3)}')"
      ],
      "metadata": {
        "id": "bKL6NhhFTVno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct, incorrect, vus_nb, count_mutations, incorrect_mutation, correct_mutation, predictions_clinvar_labels = d2d_performance_vs_clinvar_labels_correct(tp53_predictions, tp53_clinvar, False)\n",
        "predictions_clinvar_labels['pos'] = pd.to_numeric(predictions_clinvar_labels['position'],errors='coerce')\n",
        "test= predictions_clinvar_labels.sort_values(by='position', ascending=True)"
      ],
      "metadata": {
        "id": "z1HWE-eb0hrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.scatter(test, x='pos', y='D2D_prediction',\n",
        "                 color =  test['lab_clinvar'],\n",
        "                 symbol = test['lab_clinvar'],\n",
        "                 symbol_sequence= ['circle-open', 'circle', 'circle-open','circle','circle', 'circle'],\n",
        "                 color_discrete_sequence = ['#82AAE3' ,'#82AAE3' ,'#ffa7b1', '#ffa7b1', 'blue'  ,'#ed5564'], opacity = 0.85, width =850, height =400,  hover_data=['conc_mutation', 'D2D_prediction' ])\n",
        "                 #color_discrete_sequence = ['#a4c639' ,'#a4c639' ,'#ffa7b1', '#ffa7b1', '#23712E'  ,'#D82626'], opacity = 0.85, width =850, height =400,  hover_data=['conc_mutation', 'D2D_prediction' ])\n",
        "\n",
        "\n",
        "# Change the bar mode\n",
        "\n",
        "fig.update_layout(barmode='group', title=\"TP53 Gene \",\n",
        "    xaxis_title=\"Position\",\n",
        "    yaxis_title=\"D2D prediction\",\n",
        "    font_family=\"Arial\",\n",
        "    legend_title=\"Groundtruth\",\n",
        "    title_font_family=\"Arial\")\n",
        "\n",
        "fig.update_layout({\n",
        "'plot_bgcolor': 'rgba(255, 255, 255, 255)' ,\n",
        "'paper_bgcolor': 'rgba(255, 255, 255, 255)',\n",
        "})\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "cCJ3xbkF0hzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "weighted performance"
      ],
      "metadata": {
        "id": "embsN8geQmKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weighted_sum = (tp53_labelled['overall_confidence'] * tp53_labelled['correct_label']).sum()\n",
        "total_weight = tp53_labelled['overall_confidence'].sum()\n",
        "weighted_average = weighted_sum / total_weight\n",
        "print(weighted_average)"
      ],
      "metadata": {
        "id": "B0eLgbC8QqWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "high_confidence_predictions = tp53[tp53['overall_confidence'] >=0.65]\n",
        "high_positions =  high_confidence_predictions['position'].tolist()\n",
        "high_positions = [int(x) for x in high_positions]\n",
        "\n",
        "low_confidence_predictions = tp53[tp53['overall_confidence'] < 0.5]\n",
        "low_positions =  low_confidence_predictions['position'].tolist()\n",
        "low_positions = [int(x) for x in low_positions]\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (10,3)\n",
        "plt.scatter(high_positions, high_confidence_predictions['overall_confidence'], label = 'high overall_confidence', c='b', alpha=0.7)\n",
        "plt.show()\n",
        "plt.rcParams[\"figure.figsize\"] = (10,3)\n",
        "plt.scatter(low_positions, low_confidence_predictions['overall_confidence'], label = 'low overall_confidence', c='b', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jikA8cMm0Tw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "high_confidence_predictions['pos'] = pd.to_numeric(high_confidence_predictions['position'],errors='coerce')\n",
        "test_high = high_confidence_predictions.sort_values(by='position', ascending=True)"
      ],
      "metadata": {
        "id": "w91wzWWOpv2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.scatter(test_high, x='pos', y='D2D_prediction',\n",
        "                 color =  test_high['lab_clinvar'],\n",
        "                 symbol = test_high['lab_clinvar'],\n",
        "                 symbol_sequence= ['circle', 'circle-open', 'circle-open','circle','circle', 'circle'],\n",
        "                 #color_discrete_sequence = ['#a4c639' ,'#a4c639' ,'#ffa7b1', '#D82626', '#ffa7b1'  ,'#23712E'], opacity = 0.85, width =850, height =400,  hover_data=['conc_mutation', 'D2D_prediction' ])\n",
        "                 color_discrete_sequence = ['#82AAE3' ,'#82AAE3' ,'#ffa7b1', '#ed5564', '#ffa7b1','blue' ], opacity = 0.85, width =850, height =400,  hover_data=['conc_mutation', 'D2D_prediction' ])\n",
        "\n",
        "\n",
        "# Change the bar mode\n",
        "\n",
        "fig.update_layout(barmode='group', title=\"TP53 Gene \",\n",
        "    xaxis_title=\"Position\",\n",
        "    yaxis_title=\"D2D prediction\",\n",
        "    font_family=\"Arial\",\n",
        "    legend_title=\"Groundtruth\",\n",
        "    title_font_family=\"Arial\")\n",
        "\n",
        "fig.update_layout({\n",
        "'plot_bgcolor': 'rgba(255, 255, 255, 255)' ,\n",
        "'paper_bgcolor': 'rgba(255, 255, 255, 255)',\n",
        "})\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "2eOa8nICyiWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Novel mutations"
      ],
      "metadata": {
        "id": "7zfJvTjZy_sF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tp53_predictions_norm = tp53_predictions\n",
        "#tp53_predictions_norm = normal|ise_confidence(tp53_predictions)"
      ],
      "metadata": {
        "id": "Wa305zqIF_vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# p.A138V https://molmed.biomedcentral.com/articles/10.1186/s10020-020-00183-1\n",
        "tp53_predictions_norm[tp53_predictions_norm['conc_mutation']== 'A138V']"
      ],
      "metadata": {
        "id": "WDrtDpFzy_sF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(tp53_predictions_norm['overall_confidence'])\n",
        "plt.plot()"
      ],
      "metadata": {
        "id": "Cl2DK3IKGHPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# p.Ala276Ile https://pubmed.ncbi.nlm.nih.gov/29783665/\n",
        "tp53_predictions_norm[tp53_predictions_norm['conc_mutation']=='A276I']"
      ],
      "metadata": {
        "id": "iH5VMUXDy_sG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tp53_predictions_norm[tp53_predictions_norm['conc_mutation']=='E358V']"
      ],
      "metadata": {
        "id": "uLDA-qawy_sG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CPV - TP53\n",
        "print('Prediction:',tp53_predictions_norm[tp53_predictions_norm['conc_mutation']== 'R175H']['D2D_prediction'].values[0], 'Confidence:',  round(tp53_predictions_norm[tp53_predictions_norm['conc_mutation']=='R175H']['overall_confidence'].values[0],3))\n",
        "print('---------------')\n",
        "print('Prediction:', tp53_predictions_norm[tp53_predictions_norm['conc_mutation']=='Y220C']['D2D_prediction'].values[0], 'Confidence:',  round(tp53_predictions_norm[tp53_predictions_norm['conc_mutation']== 'Y220C']['overall_confidence'].values[0],3))\n",
        "print('---------------')\n",
        "print('Prediction:', tp53_predictions_norm[tp53_predictions_norm['conc_mutation']== 'G245S']['D2D_prediction'].values[0], 'Confidence:',  round(tp53_predictions_norm[tp53_predictions_norm['conc_mutation']=='G245S']['overall_confidence'].values[0],3))\n",
        "print('---------------')\n",
        "print('Prediction:', tp53_predictions_norm[tp53_predictions_norm['conc_mutation']=='R248Q']['D2D_prediction'].values[0], 'Confidence:',  round(tp53_predictions_norm[tp53_predictions_norm['conc_mutation']=='R248Q']['overall_confidence'].values[0],3))\n",
        "print('---------------')\n",
        "print('Prediction:', tp53_predictions_norm[tp53_predictions_norm['conc_mutation']=='R248W']['D2D_prediction'].values[0], 'Confidence:',  round(tp53_predictions_norm[tp53_predictions_norm['conc_mutation']=='R248W']['overall_confidence'].values[0],3))\n",
        "print('---------------')\n",
        "print('Prediction:', tp53_predictions_norm[tp53_predictions_norm['conc_mutation']=='R273C']['D2D_prediction'].values[0], 'Confidence:',  round(tp53_predictions_norm[tp53_predictions_norm['conc_mutation']== 'R273C']['overall_confidence'].values[0],3))\n",
        "print('---------------')\n",
        "print('Prediction:', tp53_predictions_norm[tp53_predictions_norm['conc_mutation']=='R273H']['D2D_prediction'].values[0], 'Confidence:',  round(tp53_predictions_norm[tp53_predictions_norm['conc_mutation']== 'R273H']['overall_confidence'].values[0],3))\n",
        "print('---------------')\n",
        "print('Prediction:', tp53_predictions_norm[tp53_predictions_norm['conc_mutation']=='R282W']['D2D_prediction'].values[0], 'Confidence:', round( tp53_predictions_norm[tp53_predictions_norm['conc_mutation']== 'R282W']['overall_confidence'].values[0],3))"
      ],
      "metadata": {
        "id": "pYgBIkujy_sG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Feature analysis"
      ],
      "metadata": {
        "id": "rOKQ8Kzb6wvp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "######Novel mutations -pre-trained"
      ],
      "metadata": {
        "id": "YlDX6Lqv0NpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_positions(lst, n):\n",
        "    positions = []\n",
        "    for i, element in enumerate(lst):\n",
        "        if element > n:\n",
        "            positions.append(i)\n",
        "    return positions"
      ],
      "metadata": {
        "id": "ea0VYya3XMWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "msa_path= '/content/drive/MyDrive/my_colab/3rdYear/datasets/mmseq2/all_msas/'\n",
        "m = nn.MaxPool1d(50) # Max Pooling for reduction of features from 1024 to 50 per AA"
      ],
      "metadata": {
        "id": "OJzvl5e96_eB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uniprot = 'P04637'\n",
        "plt.rcParams[\"figure.figsize\"] = (8,5)\n",
        "\n",
        "mut_gene = tp53_predictions[(tp53_predictions['conc_mutation'] == 'A138V') | (tp53_predictions['conc_mutation'] == 'A276I') | (tp53_predictions['conc_mutation'] == 'E358V' )]\n",
        "\n",
        "## Read in a sequence alignment from a fasta file\n",
        "if os.path.isfile(msa_path + uniprot+ \".a3m\"): # True if file exists\n",
        "  name_msa_file = msa_path + uniprot+ \".a3m\"\n",
        "else:\n",
        "  print('MSA not found in folder !')\n",
        "\n",
        "### MSA of gene\n",
        "aln_subsection = msa_protocol(name_msa_file)\n",
        "\n",
        "### Protrans\n",
        "# calculate the ProTrans for WT protein\n",
        "lines_list = []\n",
        "for line in range(len(aln_subsection)):\n",
        "  temp = aln_subsection.matrix[line, :].tolist()\n",
        "\n",
        "  x = [x.upper() for x in temp]\n",
        "  lines_list.append(x)\n",
        "\n",
        "str1 = \" \"\n",
        "lines_string = [str1.join(first_line) for first_line in lines_list]\n",
        "\n",
        "sequences_WT = [re.sub(r\"[-.]\", \"X\", sequence) for sequence in lines_string]\n",
        "\n",
        "indices_to_excl = []\n",
        "seq_pooled = []\n",
        "\n",
        "BATCH_FILE_SIZE = 15\n",
        "test_features_WT = []\n",
        "for count in range(0, math.floor(len(sequences_WT) / BATCH_FILE_SIZE)):\n",
        "    i = sequences_WT[count*15:(count+1)*15][:]\n",
        "    ids = tokenizer.batch_encode_plus(i, add_special_tokens=True, padding='longest')\n",
        "    input_ids = torch.tensor(ids['input_ids']).to(device)\n",
        "    attention_mask = torch.tensor(ids['attention_mask']).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      embedding = model(input_ids=input_ids,attention_mask=attention_mask)\n",
        "      embedding = embedding.last_hidden_state.cpu().numpy()\n",
        "\n",
        "      for seq_num in range(len(embedding)):\n",
        "        seq_len = (attention_mask[seq_num] == 1).sum()\n",
        "        seq_emd = embedding[seq_num][:seq_len-1]\n",
        "        test_features_WT.append(seq_emd)\n",
        "    del attention_mask\n",
        "    gc.collect()\n",
        "\n",
        "# converting list to array\n",
        "arr_WT = np.array(test_features_WT)\n",
        "seq_temp = torch.tensor(arr_WT)\n",
        "arr_WT = m(seq_temp) # use when you want to reduce dimensions from 1024 to 20\n",
        "print(arr_WT.shape, arr_WT[0].shape)\n",
        "arr_WT =arr_WT.numpy()\n",
        "\n",
        "columns = range(0, arr_WT.shape[1])\n",
        "differences_WT = []\n",
        "densities_WT = []\n",
        "#density_threshold_WT = []\n",
        "for col in columns:\n",
        "    first_col = arr_WT[:, col]\n",
        "    gmm = GaussianMixture(n_components=1).fit(first_col)\n",
        "    densities_temp = gmm.score_samples(first_col)\n",
        "    densities_WT.append(densities_temp)\n",
        "    threshold_temp = np.percentile(densities_temp, 1)\n",
        "    #density_threshold_WT.append(threshold_temp)\n",
        "    #differences_WT.append(abs(densities_temp[0] - threshold_temp) )\n",
        "    differences_WT.append(densities_temp[0] - threshold_temp)\n",
        "print('Columns (input to gmm) shape:', first_col.shape )\n",
        "\n",
        "### Calculate differences of all mutations of gene\n",
        "points, positions_list, colors = [], [], []\n",
        "for k, mut in mut_gene.iterrows():\n",
        "  diction_test = {} # dictionary containing the difference of log-probabilities of mutation from the lof-prob of WT\n",
        "\n",
        "  mut_seq = mut['mut_sequence']# mutated sequence\n",
        "  position = int(mut['position'])-1\n",
        "  AA_orig = mut['AA_orig']\n",
        "  AA_targ = mut['AA_targ']\n",
        "\n",
        "  new_str = [str(x) for x in mut_seq]\n",
        "  new_str[position] = AA_targ\n",
        "\n",
        "  str1 = \" \"\n",
        "  lines_string = str1.join(new_str)\n",
        "  MUT_sequence = re.sub(r\"[-.]\", \"X\", lines_string)\n",
        "\n",
        "  ids = tokenizer.batch_encode_plus([MUT_sequence], add_special_tokens=True, padding='longest')\n",
        "  input_ids = torch.tensor(ids['input_ids']).to(device)\n",
        "  attention_mask = torch.tensor(ids['attention_mask']).to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    embedding = model(input_ids=input_ids,attention_mask=attention_mask)\n",
        "    embedding = embedding.last_hidden_state.cpu().numpy()\n",
        "    #print(embedding.shape)\n",
        "    seq_len = (attention_mask == 1).sum()\n",
        "    seq_emd = embedding[:, :seq_len-1, :]\n",
        "\n",
        "  seq_emd = torch.tensor(seq_emd)\n",
        "  seq_emd = m(seq_emd) # use when you want to reduce dimensions from 1024 to 20\n",
        "  seq_emd =seq_emd.numpy()\n",
        "\n",
        "  arr_WT[0] = seq_emd[0]\n",
        "  del embedding, ids, MUT_sequence, attention_mask\n",
        "  gc.collect()\n",
        "\n",
        "  columns = range(0, arr_WT.shape[1])\n",
        "  differences_MUT = []\n",
        "  densities_MUT = []\n",
        "  #density_threshold_MUT = []\n",
        "  for col in columns:\n",
        "      first_col = arr_WT[:, col]\n",
        "      gmm = GaussianMixture(n_components=1).fit(first_col)\n",
        "      densities_temp = gmm.score_samples(first_col)\n",
        "      densities_MUT.append(densities_temp)\n",
        "      threshold_temp = np.percentile(densities_temp, 1)\n",
        "      differences_MUT.append(densities_temp[0] - threshold_temp)\n",
        "\n",
        "  dif_dif = [differences_WT[i] - differences_MUT[i] for i in range(len(differences_MUT))] # difference of WT and Mutated sequence log probabiities\n",
        "  points.extend([x for x in dif_dif if x>2.5 ])\n",
        "\n",
        "  if position == 137:\n",
        "    positions_list.extend([130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141])\n",
        "    colors.extend([\"yellow\",\"yellow\", \"yellow\", \"yellow\", \"yellow\", \"yellow\",  \"yellow\", \"red\", \"yellow\", \"orange\" , \"yellow\"])\n",
        "    for i in range(len(positions_list)):\n",
        "        plt.scatter(positions_list[i], points[i], color=colors[i])\n",
        "    plt.xlim([0, 392])\n",
        "    plt.plot(dif_dif, c='slategrey', alpha=0.5)\n",
        "\n",
        "  elif position == 275:\n",
        "\n",
        "    positions_list.extend([236, 239, 240, 241, 242, 243, 248, 251, 261, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281,282, 284])\n",
        "    colors.extend([\"orange\", \"yellow\", \"orange\", \"orange\", \"yellow\", \"orange\", \"yellow\", \"orange\",\"yellow\", \"yellow\", \"yellow\", \"red\", \"yellow\", \"yellow\", \"yellow\", \"orange\" , \"red\",\"orange\", \"red\", \"yellow\", \"red\", \"yellow\", \"red\", \"orange\", \"yellow\", \"orange\", \"orange\", \"orange\",\"yellow\", \"orange\"])\n",
        "    for i in range(len(positions_list)):\n",
        "        plt.scatter(positions_list[i], points[i], color=colors[i])\n",
        "    plt.xlim([0, 392])\n",
        "    plt.plot(dif_dif, c='black', alpha=0.5)\n",
        "\n",
        "  elif position == 357:\n",
        "    positions_list.extend([351, 352, 354, 355, 356, 357, 358, 360])\n",
        "    colors.extend([\"grey\", \"grey\", \"grey\", \"grey\", \"yellow\",\"grey\", \"grey\", \"grey\"])\n",
        "    for i in range(len(positions_list)):\n",
        "        plt.scatter(positions_list[i], points[i], color=colors[i])\n",
        "    plt.xlim([0, 392])\n",
        "    plt.plot(dif_dif, c='silver', alpha=0.5)\n",
        "    plt.show()\n",
        "\n",
        "  dif_dif_big= [x if x>2.5 else 0 for x in dif_dif ]\n",
        "  print(find_positions(dif_dif_big,2.5))\n",
        "\n",
        "  gene_name_mutation = uniprot +'_' + AA_orig + str(mut['position']) + AA_targ\n",
        "  diction_test['uniprot_mut'] = gene_name_mutation\n",
        "  diction_test['Log dif'] = dif_dif"
      ],
      "metadata": {
        "id": "cEOq1x1MHrAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uniprot = 'P04637'\n",
        "plt.rcParams[\"figure.figsize\"] = (8,5)\n",
        "\n",
        "mut_gene = tp53_predictions[(tp53_predictions['conc_mutation'] == 'A138V') | (tp53_predictions['conc_mutation'] == 'A276I') | (tp53_predictions['conc_mutation'] == 'E358V' )]\n",
        "\n",
        "## Read in a sequence alignment from a fasta file\n",
        "if os.path.isfile(msa_path + uniprot+ \".a3m\"): # True if file exists\n",
        "  name_msa_file = msa_path + uniprot+ \".a3m\"\n",
        "else:\n",
        "  print('MSA not found in folder !')\n",
        "\n",
        "### MSA of gene\n",
        "aln_subsection = msa_protocol(name_msa_file)\n",
        "\n",
        "### Protrans\n",
        "# calculate the ProTrans for WT protein\n",
        "lines_list = []\n",
        "for line in range(len(aln_subsection)):\n",
        "  temp = aln_subsection.matrix[line, :].tolist()\n",
        "\n",
        "  x = [x.upper() for x in temp]\n",
        "  lines_list.append(x)\n",
        "\n",
        "str1 = \" \"\n",
        "lines_string = [str1.join(first_line) for first_line in lines_list]\n",
        "\n",
        "sequences_WT = [re.sub(r\"[-.]\", \"X\", sequence) for sequence in lines_string]\n",
        "\n",
        "indices_to_excl = []\n",
        "seq_pooled = []\n",
        "\n",
        "BATCH_FILE_SIZE = 15\n",
        "test_features_WT = []\n",
        "for count in range(0, math.floor(len(sequences_WT) / BATCH_FILE_SIZE)):\n",
        "    i = sequences_WT[count*15:(count+1)*15][:]\n",
        "    ids = tokenizer.batch_encode_plus(i, add_special_tokens=True, padding='longest')\n",
        "    input_ids = torch.tensor(ids['input_ids']).to(device)\n",
        "    attention_mask = torch.tensor(ids['attention_mask']).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      embedding = model(input_ids=input_ids,attention_mask=attention_mask)\n",
        "      embedding = embedding.last_hidden_state.cpu().numpy()\n",
        "\n",
        "      for seq_num in range(len(embedding)):\n",
        "        seq_len = (attention_mask[seq_num] == 1).sum()\n",
        "        seq_emd = embedding[seq_num][:seq_len-1]\n",
        "        test_features_WT.append(seq_emd)\n",
        "    del attention_mask\n",
        "    gc.collect()\n",
        "\n",
        "# converting list to array\n",
        "arr_WT = np.array(test_features_WT)\n",
        "seq_temp = torch.tensor(arr_WT)\n",
        "arr_WT = m(seq_temp) # use when you want to reduce dimensions from 1024 to 20\n",
        "print(arr_WT.shape, arr_WT[0].shape)\n",
        "arr_WT =arr_WT.numpy()\n",
        "\n",
        "columns = range(0, arr_WT.shape[1])\n",
        "differences_WT = []\n",
        "densities_WT = []\n",
        "#density_threshold_WT = []\n",
        "for col in columns:\n",
        "    first_col = arr_WT[:, col]\n",
        "    gmm = GaussianMixture(n_components=1).fit(first_col)\n",
        "    densities_temp = gmm.score_samples(first_col)\n",
        "    densities_WT.append(densities_temp)\n",
        "    threshold_temp = np.percentile(densities_temp, 1)\n",
        "    #density_threshold_WT.append(threshold_temp)\n",
        "    #differences_WT.append(abs(densities_temp[0] - threshold_temp) )\n",
        "    differences_WT.append(densities_temp[0] - threshold_temp)\n",
        "print('Columns (input to gmm) shape:', first_col.shape )\n",
        "\n",
        "### Calculate differences of all mutations of gene\n",
        "points, positions_list, colors = [], [], []\n",
        "for k, mut in mut_gene.iterrows():\n",
        "  diction_test = {} # dictionary containing the difference of log-probabilities of mutation from the lof-prob of WT\n",
        "\n",
        "  mut_seq = mut['mut_sequence']# mutated sequence\n",
        "  position = int(mut['position'])-1\n",
        "  AA_orig = mut['AA_orig']\n",
        "  AA_targ = mut['AA_targ']\n",
        "\n",
        "  new_str = [str(x) for x in mut_seq]\n",
        "  new_str[position] = AA_targ\n",
        "\n",
        "  str1 = \" \"\n",
        "  lines_string = str1.join(new_str)\n",
        "  MUT_sequence = re.sub(r\"[-.]\", \"X\", lines_string)\n",
        "\n",
        "  ids = tokenizer.batch_encode_plus([MUT_sequence], add_special_tokens=True, padding='longest')\n",
        "  input_ids = torch.tensor(ids['input_ids']).to(device)\n",
        "  attention_mask = torch.tensor(ids['attention_mask']).to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    embedding = model(input_ids=input_ids,attention_mask=attention_mask)\n",
        "    embedding = embedding.last_hidden_state.cpu().numpy()\n",
        "    #print(embedding.shape)\n",
        "    seq_len = (attention_mask == 1).sum()\n",
        "    seq_emd = embedding[:, :seq_len-1, :]\n",
        "\n",
        "  seq_emd = torch.tensor(seq_emd)\n",
        "  seq_emd = m(seq_emd) # use when you want to reduce dimensions from 1024 to 20\n",
        "  seq_emd =seq_emd.numpy()\n",
        "\n",
        "  arr_WT[0] = seq_emd[0]\n",
        "  del embedding, ids, MUT_sequence, attention_mask\n",
        "  gc.collect()\n",
        "\n",
        "  columns = range(0, arr_WT.shape[1])\n",
        "  differences_MUT = []\n",
        "  densities_MUT = []\n",
        "  #density_threshold_MUT = []\n",
        "  for col in columns:\n",
        "      first_col = arr_WT[:, col]\n",
        "      gmm = GaussianMixture(n_components=1).fit(first_col)\n",
        "      densities_temp = gmm.score_samples(first_col)\n",
        "      densities_MUT.append(densities_temp)\n",
        "      threshold_temp = np.percentile(densities_temp, 1)\n",
        "      differences_MUT.append(densities_temp[0] - threshold_temp)\n",
        "\n",
        "  dif_dif = [differences_WT[i] - differences_MUT[i] for i in range(len(differences_MUT))] # difference of WT and Mutated sequence log probabiities\n",
        "  points.extend([x for x in dif_dif if x>2.5 ])\n",
        "\n",
        "  if position == 137:\n",
        "    positions_list.extend([130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141])\n",
        "    colors.extend([\"yellow\",\"yellow\", \"yellow\", \"yellow\", \"yellow\", \"yellow\",  \"yellow\", \"red\", \"yellow\", \"orange\" , \"yellow\"])\n",
        "    for i in range(len(positions_list)):\n",
        "        plt.scatter(positions_list[i], points[i], color=colors[i])\n",
        "    plt.xlim([0, 392])\n",
        "    plt.ylim([0, 70])\n",
        "    plt.plot(dif_dif, c='slategrey', alpha=0.5)\n",
        "    plt.show()\n",
        "\n",
        "  elif position == 275:\n",
        "\n",
        "    positions_list.extend([236, 239, 240, 241, 242, 243, 248, 251, 261, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281,282, 284])\n",
        "    colors.extend([\"orange\", \"yellow\", \"orange\", \"orange\", \"yellow\", \"orange\", \"yellow\", \"orange\",\"yellow\", \"yellow\", \"yellow\", \"red\", \"yellow\", \"yellow\", \"yellow\", \"orange\" , \"red\",\"orange\", \"red\", \"yellow\", \"red\", \"yellow\", \"red\", \"orange\", \"yellow\", \"orange\", \"orange\", \"orange\",\"yellow\", \"orange\"])\n",
        "    for i in range(len(positions_list)):\n",
        "        plt.scatter(positions_list[i], points[i], color=colors[i])\n",
        "    plt.xlim([0, 392])\n",
        "    plt.ylim([0, 70])\n",
        "    plt.plot(dif_dif, c='black', alpha=0.5)\n",
        "    plt.show()\n",
        "\n",
        "  elif position == 357:\n",
        "    positions_list.extend([351, 352, 354, 355, 356, 357, 358, 360])\n",
        "    colors.extend([\"grey\", \"grey\", \"grey\", \"grey\", \"yellow\",\"grey\", \"grey\", \"grey\"])\n",
        "    for i in range(len(positions_list)):\n",
        "        plt.scatter(positions_list[i], points[i], color=colors[i])\n",
        "    plt.xlim([0, 392])\n",
        "    plt.ylim([0, 70])\n",
        "    plt.plot(dif_dif, c='silver', alpha=0.5)\n",
        "    plt.show()\n",
        "\n",
        "  dif_dif_big= [x if x>2.5 else 0 for x in dif_dif ]\n",
        "  print(find_positions(dif_dif_big,2.5))\n",
        "\n",
        "  gene_name_mutation = uniprot +'_' + AA_orig + str(mut['position']) + AA_targ\n",
        "  diction_test['uniprot_mut'] = gene_name_mutation\n",
        "  diction_test['Log dif'] = dif_dif"
      ],
      "metadata": {
        "id": "6lv3b1t6UW0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "######Novel mutations - GMM"
      ],
      "metadata": {
        "id": "QLPLJE0XaMxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import GMM representations\n",
        "# import difference for each mutation\n",
        "test = pd.read_csv('/content/drive/MyDrive/log_probWT_MUT_P04637_2200AA_57_maxpool.csv', header = None, names = ['mutation', 'log_difference', 'label'])\n",
        "\n",
        "fl_dif = []\n",
        "for x in test['log_difference']:\n",
        "  p = x[1:-1].split(',')\n",
        "  fl_dif.append([float(i) for i in p])\n",
        "\n",
        "test['fl_dif'] = fl_dif\n",
        "\n",
        "# pad to 2200 AA\n",
        "N= 2200\n",
        "fl_dif_pad, positions, proteins_temp =[], [], []\n",
        "for i, mut in test.iterrows():\n",
        "  mut_temp = mut.mutation.split('_')[1]\n",
        "  proteins_temp.append(mut.mutation.split('_')[0])\n",
        "  positions.append(mut_temp[1: -1])\n",
        "  a = mut['fl_dif']\n",
        "  new_a = a + [0] * (N - len(a))\n",
        "  fl_dif_pad.append(new_a)\n",
        "test['fl_dif_pad'] = fl_dif_pad\n",
        "\n",
        "stacked_flat_drgn =[]\n",
        "for i, mut in test.iterrows():\n",
        "  stacked_flat_drgn.append(torch.tensor(mut['fl_dif_pad']))\n",
        "\n",
        "stacked_drgn = torch.stack(stacked_flat_drgn)\n",
        "print(stacked_drgn.shape)"
      ],
      "metadata": {
        "id": "ubK0ysmtbsIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A138V_GMM = test[test['mutation'] == 'P04637_A138V']['fl_dif']"
      ],
      "metadata": {
        "id": "8kSTyTF5cvcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(A173V_GMM.tolist()[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fRBNmd88dABn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A276E_GMM = test[test['mutation'] == 'P04637_A276I']['fl_dif']\n",
        "plt.plot(A276E_GMM.tolist()[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A3C_lY0RaWdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "E358V_GMM = test[test['mutation'] == 'P04637_E358V']['fl_dif']\n",
        "plt.plot(E358V_GMM.tolist()[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_4usGfFpgG_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "######Very confident pathogenic mutations - GMM"
      ],
      "metadata": {
        "id": "85H_A_1hg-_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import heapq\n",
        "\n",
        "conf_05 = tp53[tp53['overall_confidence'] <=0.5]\n",
        "conf_51 = tp53[tp53['overall_confidence'] >0.5 ]\n",
        "\n",
        "conf_05_VUS = conf_05[conf_05['lab_clinvar'].str.contains('VUS')]\n",
        "conf_51_VUS = conf_51[conf_51['lab_clinvar'].str.contains('VUS')]\n",
        "\n",
        "conf_05_VUS_repres, conf_05_VUS_repres_peaks = [], []\n",
        "for i, mut in conf_05_VUS.iterrows():\n",
        "  mutation = mut['uniprot id'] + '_' + mut['AA_orig']+ mut['position']+ mut['AA_targ']\n",
        "  conf_05_VUS_repres.extend(test[test['mutation'] == mutation]['fl_dif'].tolist()[0])\n",
        "  # find the 10 peaks of representation\n",
        "  conf_05_VUS_repres_peaks.extend(heapq.nlargest(10, conf_05_VUS_repres))\n",
        "\n",
        "conf_51_VUS_repres,conf_51_VUS_repres_peaks = [], []\n",
        "for i, mut in conf_51_VUS.iterrows():\n",
        "  mutation = mut['uniprot id'] + '_' + mut['AA_orig']+ mut['position']+ mut['AA_targ']\n",
        "  conf_51_VUS_repres.extend(test[test['mutation'] == mutation]['fl_dif'].tolist()[0])\n",
        "  # find the 10 peaks of representation\n",
        "  conf_51_VUS_repres_peaks.extend(heapq.nlargest(10, conf_51_VUS_repres))\n",
        "\n",
        "filtered_conf_05_VUS_repres = [k for k in conf_05_VUS_repres if k> 10]\n",
        "filtered_conf_51_VUS_repres = [k for k in conf_51_VUS_repres if k> 10]"
      ],
      "metadata": {
        "id": "7zJYjOtnn2RT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Create a figure and axes object\n",
        "fig, ax = plt.subplots()\n",
        "data = [conf_05_VUS_repres_peaks, conf_51_VUS_repres_peaks]\n",
        "boxplot = ax.boxplot(data, labels=['Confidence below 50%', 'Confidence above 50%'], showfliers=False)\n",
        "\n",
        "# Step 3: Customize the appearance of the boxplot\n",
        "boxprops = dict(linestyle='-', linewidth=2, color='darkblue')\n",
        "medianprops = dict(linestyle='-', linewidth=2, color='red')\n",
        "whiskerprops = dict(linestyle='--', linewidth=1.5, color='gray')\n",
        "\n",
        "for box in boxplot['boxes']:\n",
        "    box.set(**boxprops)\n",
        "\n",
        "for median in boxplot['medians']:\n",
        "    median.set(**medianprops)\n",
        "\n",
        "for whisker in boxplot['whiskers']:\n",
        "    whisker.set(**whiskerprops)\n",
        "\n",
        "# Step 4: Optionally, add labels, title, and legends to enhance the plot\n",
        "ax.set_ylabel('D2Deep features\\' peaks values')\n",
        "#ax.set_title('Boxplot of Two Lists A and B')\n",
        "#ax.legend([boxplot[\"boxes\"][0], boxplot[\"boxes\"][1]], ['A', 'B'])\n",
        "\n",
        "# Step 5: Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DdXqmJfAqzjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Novel mutations predicted pathogenic vs confirmed pathogenic ones"
      ],
      "metadata": {
        "id": "_ozzbbsv1MoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "confirmed_benign = tp53_labelled[tp53_labelled['lab_clinvar'].str.contains('benign')]\n",
        "confirmed_pathogenic = tp53_labelled[tp53_labelled['lab_clinvar'].str.contains('pathogenic')]"
      ],
      "metadata": {
        "id": "DvBlq9TU1R7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(confirmed_benign), len(confirmed_pathogenic))"
      ],
      "metadata": {
        "id": "1W_M-3rJhUvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confirmed_benign_repres, confirmed_benign_repres_peaks = [], []\n",
        "for i, mut in confirmed_benign.iterrows():\n",
        "  mutation = mut['uniprot id'] + '_' + mut['AA_orig']+ mut['position']+ mut['AA_targ']\n",
        "  confirmed_benign_repres.extend(test[test['mutation'] == mutation]['fl_dif'].tolist()[0])\n",
        "  # find the 10 peaks of representation\n",
        "  confirmed_benign_repres_peaks.extend(heapq.nlargest(10, confirmed_benign_repres))\n",
        "\n",
        "confirmed_pathogenic_repres, confirmed_pathogenic_repres_peaks = [], []\n",
        "for i, mut in confirmed_pathogenic.iterrows():\n",
        "  mutation = mut['uniprot id'] + '_' + mut['AA_orig']+ mut['position']+ mut['AA_targ']\n",
        "  confirmed_pathogenic_repres.extend(test[test['mutation'] == mutation]['fl_dif'].tolist()[0])\n",
        "  # find the 10 peaks of representation\n",
        "  confirmed_pathogenic_repres_peaks.extend(heapq.nlargest(10, confirmed_pathogenic_repres))"
      ],
      "metadata": {
        "id": "MH8GY-lt2IOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tp53_unlabelled = tp53[tp53['lab_clinvar'].str.contains('VUS')]\n",
        "VUS_benign = tp53_unlabelled[tp53_unlabelled['lab_clinvar'].str.contains('benign')]\n",
        "VUS_pathogenic = tp53_unlabelled[tp53_unlabelled['lab_clinvar'].str.contains('deleterious')]"
      ],
      "metadata": {
        "id": "vBlfXJJX2yyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(VUS_benign), len(VUS_pathogenic) )"
      ],
      "metadata": {
        "id": "51dpzxEthg-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VUS_benign_repres, VUS_benign_repres_peaks = [], []\n",
        "for i, mut in VUS_benign.iterrows():\n",
        "  mutation = mut['uniprot id'] + '_' + mut['AA_orig']+ mut['position']+ mut['AA_targ']\n",
        "  VUS_benign_repres.extend(test[test['mutation'] == mutation]['fl_dif'].tolist()[0])\n",
        "  # find the 10 peaks of representation\n",
        "  VUS_benign_repres_peaks.extend(heapq.nlargest(10, VUS_benign_repres))\n",
        "\n",
        "VUS_pathogenic_repres, VUS_pathogenic_repres_peaks = [], []\n",
        "for i, mut in VUS_pathogenic.iterrows():\n",
        "  mutation = mut['uniprot id'] + '_' + mut['AA_orig']+ mut['position']+ mut['AA_targ']\n",
        "  VUS_pathogenic_repres.extend(test[test['mutation'] == mutation]['fl_dif'].tolist()[0])\n",
        "  # find the 10 peaks of representation\n",
        "  VUS_pathogenic_repres_peaks.extend(heapq.nlargest(10, VUS_pathogenic_repres))"
      ],
      "metadata": {
        "id": "5-GalUwY20ZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VUS_benign_confident = VUS_benign[VUS_benign['overall_confidence'] >=0.5]\n",
        "VUS_pathogenic_confident = VUS_pathogenic[VUS_pathogenic['overall_confidence'] >=0.5]\n",
        "\n",
        "VUS_benign_confident_repres, VUS_benign_confident_repres_peaks = [], []\n",
        "for i, mut in VUS_benign_confident.iterrows():\n",
        "  mutation = mut['uniprot id'] + '_' + mut['AA_orig']+ mut['position']+ mut['AA_targ']\n",
        "  VUS_benign_confident_repres.extend(test[test['mutation'] == mutation]['fl_dif'].tolist()[0])\n",
        "  # find the 10 peaks of representation\n",
        "  VUS_benign_confident_repres_peaks.extend(heapq.nlargest(10, VUS_benign_confident_repres))\n",
        "\n",
        "VUS_pathogenic_confident_repres, VUS_pathogenic_confident_repres_peaks = [], []\n",
        "for i, mut in VUS_pathogenic_confident.iterrows():\n",
        "  mutation = mut['uniprot id'] + '_' + mut['AA_orig']+ mut['position']+ mut['AA_targ']\n",
        "  VUS_pathogenic_confident_repres.extend(test[test['mutation'] == mutation]['fl_dif'].tolist()[0])\n",
        "  # find the 10 peaks of representation\n",
        "  VUS_pathogenic_confident_repres_peaks.extend(heapq.nlargest(10, VUS_pathogenic_confident_repres))"
      ],
      "metadata": {
        "id": "wgPdG14X3rih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(VUS_benign_confident), len(VUS_pathogenic_confident) )"
      ],
      "metadata": {
        "id": "JeO2oYcMhMU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (17,3)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "data = [confirmed_benign_repres_peaks,VUS_benign_repres_peaks, VUS_benign_confident_repres_peaks , confirmed_pathogenic_repres_peaks, VUS_pathogenic_repres_peaks, VUS_pathogenic_confident_repres_peaks, ]\n",
        "boxplot = ax.boxplot(data, labels=['ClinVar benign', 'VUS - Predicted benign', 'VUS - Predicted \\n confidently benign', 'ClinVar pathogenic', 'VUS - Predicted pathogenic', 'VUS - Predicted \\n confidently pathogenic'], showfliers=False)\n",
        "\n",
        "# Step 3: Customize the appearance of the boxplot\n",
        "boxprops = dict(linestyle='-', linewidth=2, color='darkblue')\n",
        "medianprops = dict(linestyle='-', linewidth=2, color='red')\n",
        "whiskerprops = dict(linestyle='--', linewidth=1.5, color='gray')\n",
        "\n",
        "for box in boxplot['boxes']:\n",
        "    box.set(**boxprops)\n",
        "\n",
        "for median in boxplot['medians']:\n",
        "    median.set(**medianprops)\n",
        "\n",
        "for whisker in boxplot['whiskers']:\n",
        "    whisker.set(**whiskerprops)\n",
        "\n",
        "# Step 4: Optionally, add labels, title, and legends to enhance the plot\n",
        "ax.set_ylabel('D2Deep features\\' peaks values')\n",
        "#ax.set_title('Boxplot of Two Lists A and B')\n",
        "#ax.legend([boxplot[\"boxes\"][0], boxplot[\"boxes\"][1]], ['A', 'B'])\n",
        "\n",
        "# Step 5: Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IFq1QkW32M-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "data = [\n",
        "    confirmed_benign_repres_peaks,\n",
        "    VUS_benign_repres_peaks,\n",
        "    VUS_benign_confident_repres_peaks,\n",
        "    confirmed_pathogenic_repres_peaks,\n",
        "    VUS_pathogenic_repres_peaks,\n",
        "    VUS_pathogenic_confident_repres_peaks,\n",
        "]\n",
        "\n",
        "# Set the colors for the first 3 and last 3 boxplots\n",
        "colors = ['green', 'green', 'green', 'red', 'red', 'red']\n",
        "\n",
        "boxplot = ax.boxplot(data, labels=['ClinVar benign', 'VUS - Predicted benign', 'VUS - Predicted \\n confidently benign', 'ClinVar pathogenic', 'VUS - Predicted pathogenic', 'VUS - Predicted \\n confidently pathogenic'], showfliers=False)\n",
        "\n",
        "# Step 3: Customize the appearance of the boxplot\n",
        "boxprops = dict(linestyle='-', linewidth=2.5,  alpha=0.6)\n",
        "medianprops = dict(linestyle='-', linewidth=0.5, color='red')\n",
        "whiskerprops = dict(linestyle='--', linewidth=1, color='lightgray')\n",
        "\n",
        "# Set the edge color for each box based on the colors list\n",
        "for i, box in enumerate(boxplot['boxes']):\n",
        "    boxprops[\"color\"] = colors[i]\n",
        "    box.update(boxprops)\n",
        "\n",
        "for median in boxplot['medians']:\n",
        "    median.set(**medianprops)\n",
        "\n",
        "for whisker in boxplot['whiskers']:\n",
        "    whisker.set(**whiskerprops)\n",
        "\n",
        "# Step 4: Optionally, add labels, title, and legends to enhance the plot\n",
        "ax.set_ylabel(\"D2Deep features' peaks values\")\n",
        "\n",
        "# Step 5: Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_kUHvGW-1R-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "######Very confident pathogenic mutations - pre-trained"
      ],
      "metadata": {
        "id": "pRC2glz20Qfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tp53_predictions, tp53_clinvar= predictions_clinvarlabels_preprocessing('TP53')\n",
        "tp53_predictions['Log_prob'] = tp53_confidenceAB['Log_prob']\n",
        "tp53_predictions['prob_benign'] = tp53_confidenceAB['prob_benign']\n",
        "tp53_predictions['prob_pathogenic'] = tp53_confidenceAB['prob_pathogenic']\n",
        "tp53_predictions = normalise_confidence(tp53_predictions)"
      ],
      "metadata": {
        "id": "h-0UNQDF3yna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mut_gene = tp53_predictions[(tp53_predictions['overall_confidence'] == 1) & (tp53_predictions['D2D_prediction'] == 1) & (tp53_predictions['AA_targ'] != 'Y') & (tp53_predictions['AA_targ'] != 'C') & (tp53_predictions['AA_targ'] != 'F') & (tp53_predictions['AA_targ'] != 'A')] # S241Y, S241C, S241F, S241A : pathogenic in clinvar"
      ],
      "metadata": {
        "id": "Pg6yi5V0-3Mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uniprot = 'P04637'\n",
        "plt.rcParams[\"figure.figsize\"] = (8,5)\n",
        "\n",
        "## Read in a sequence alignment from a fasta file\n",
        "if os.path.isfile(msa_path + uniprot+ \".a3m\"): # True if file exists\n",
        "  name_msa_file = msa_path + uniprot+ \".a3m\"\n",
        "else:\n",
        "  print('MSA not found in folder !')\n",
        "\n",
        "### MSA of gene\n",
        "aln_subsection = msa_protocol(name_msa_file)\n",
        "\n",
        "### Protrans\n",
        "# calculate the ProTrans for WT protein\n",
        "lines_list = []\n",
        "for line in range(len(aln_subsection)):\n",
        "  temp = aln_subsection.matrix[line, :].tolist()\n",
        "\n",
        "  x = [x.upper() for x in temp]\n",
        "  lines_list.append(x)\n",
        "\n",
        "str1 = \" \"\n",
        "lines_string = [str1.join(first_line) for first_line in lines_list]\n",
        "\n",
        "sequences_WT = [re.sub(r\"[-.]\", \"X\", sequence) for sequence in lines_string]\n",
        "\n",
        "indices_to_excl = []\n",
        "seq_pooled = []\n",
        "\n",
        "BATCH_FILE_SIZE = 15\n",
        "test_features_WT = []\n",
        "for count in range(0, math.floor(len(sequences_WT) / BATCH_FILE_SIZE)):\n",
        "    i = sequences_WT[count*15:(count+1)*15][:]\n",
        "    ids = tokenizer.batch_encode_plus(i, add_special_tokens=True, padding='longest')\n",
        "    input_ids = torch.tensor(ids['input_ids']).to(device)\n",
        "    attention_mask = torch.tensor(ids['attention_mask']).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      embedding = model(input_ids=input_ids,attention_mask=attention_mask)\n",
        "      embedding = embedding.last_hidden_state.cpu().numpy()\n",
        "\n",
        "      for seq_num in range(len(embedding)):\n",
        "        seq_len = (attention_mask[seq_num] == 1).sum()\n",
        "        seq_emd = embedding[seq_num][:seq_len-1]\n",
        "        test_features_WT.append(seq_emd)\n",
        "    del attention_mask\n",
        "    gc.collect()\n",
        "\n",
        "# converting list to array\n",
        "arr_WT = np.array(test_features_WT)\n",
        "seq_temp = torch.tensor(arr_WT)\n",
        "arr_WT = m(seq_temp) # use when you want to reduce dimensions from 1024 to 20\n",
        "print(arr_WT.shape, arr_WT[0].shape)\n",
        "arr_WT =arr_WT.numpy()\n",
        "\n",
        "columns = range(0, arr_WT.shape[1])\n",
        "differences_WT = []\n",
        "densities_WT = []\n",
        "#density_threshold_WT = []\n",
        "for col in columns:\n",
        "    first_col = arr_WT[:, col]\n",
        "    gmm = GaussianMixture(n_components=1).fit(first_col)\n",
        "    densities_temp = gmm.score_samples(first_col)\n",
        "    densities_WT.append(densities_temp)\n",
        "    threshold_temp = np.percentile(densities_temp, 1)\n",
        "    #density_threshold_WT.append(threshold_temp)\n",
        "    #differences_WT.append(abs(densities_temp[0] - threshold_temp) )\n",
        "    differences_WT.append(densities_temp[0] - threshold_temp)\n",
        "print('Columns (input to gmm) shape:', first_col.shape )\n",
        "\n",
        "### Calculate differences of all mutations of gene\n",
        "\n",
        "points, positions_list, colors = [], [], []\n",
        "for k, mut in mut_gene.iterrows():\n",
        "  diction_test = {} # dictionary containing the difference of log-probabilities of mutation from the lof-prob of WT\n",
        "\n",
        "  mut_seq = mut['mut_sequence']# mutated sequence\n",
        "  position = int(mut['position'])-1\n",
        "  AA_orig = mut['AA_orig']\n",
        "  AA_targ = mut['AA_targ']\n",
        "\n",
        "  new_str = [str(x) for x in mut_seq]\n",
        "  new_str[position] = AA_targ\n",
        "\n",
        "  str1 = \" \"\n",
        "  lines_string = str1.join(new_str)\n",
        "  MUT_sequence = re.sub(r\"[-.]\", \"X\", lines_string)\n",
        "\n",
        "  ids = tokenizer.batch_encode_plus([MUT_sequence], add_special_tokens=True, padding='longest')\n",
        "  input_ids = torch.tensor(ids['input_ids']).to(device)\n",
        "  attention_mask = torch.tensor(ids['attention_mask']).to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    embedding = model(input_ids=input_ids,attention_mask=attention_mask)\n",
        "    embedding = embedding.last_hidden_state.cpu().numpy()\n",
        "    #print(embedding.shape)\n",
        "    seq_len = (attention_mask == 1).sum()\n",
        "    seq_emd = embedding[:, :seq_len-1, :]\n",
        "\n",
        "  seq_emd = torch.tensor(seq_emd)\n",
        "  seq_emd = m(seq_emd) # use when you want to reduce dimensions from 1024 to 20\n",
        "  seq_emd =seq_emd.numpy()\n",
        "\n",
        "  arr_WT[0] = seq_emd[0]\n",
        "  del embedding, ids, MUT_sequence, attention_mask\n",
        "  gc.collect()\n",
        "\n",
        "  columns = range(0, arr_WT.shape[1])\n",
        "  differences_MUT = []\n",
        "  densities_MUT = []\n",
        "\n",
        "  for col in columns:\n",
        "      first_col = arr_WT[:, col]\n",
        "      gmm = GaussianMixture(n_components=1).fit(first_col)\n",
        "      densities_temp = gmm.score_samples(first_col)\n",
        "      densities_MUT.append(densities_temp)\n",
        "      threshold_temp = np.percentile(densities_temp, 1)\n",
        "      differences_MUT.append(densities_temp[0] - threshold_temp)\n",
        "\n",
        "  dif_dif = [differences_WT[i] - differences_MUT[i] for i in range(len(differences_MUT))] # difference of WT and Mutated sequence log probabiities\n",
        "  plt.plot(dif_dif)\n",
        "  plt.show()\n",
        "\n",
        "  dif_dif_big= [x if x>2 else 0 for x in dif_dif ]\n",
        "  plt.scatter(list(range(0,len(dif_dif))), dif_dif_big)\n",
        "  plt.show()\n",
        "  print(find_positions(dif_dif_big,2))\n",
        "\n",
        "  ### Save dif_dif in a dictionary with keys: genename_mutation\n",
        "  gene_name_mutation = uniprot +'_' + AA_orig + str(mut['position']) + AA_targ\n",
        "\n",
        "  diction_test['uniprot_mut'] = gene_name_mutation\n",
        "  #print(gene_name_mutation, mut['label'])\n",
        "  diction_test['Log dif'] = dif_dif\n",
        "  #diction_test['label'] = mut['label']"
      ],
      "metadata": {
        "id": "WHJEwRhx0kza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uniprot = 'P04637'\n",
        "plt.rcParams[\"figure.figsize\"] = (8,5)\n",
        "\n",
        "## Read in a sequence alignment from a fasta file\n",
        "if os.path.isfile(msa_path + uniprot+ \".a3m\"): # True if file exists\n",
        "  name_msa_file = msa_path + uniprot+ \".a3m\"\n",
        "else:\n",
        "  print('MSA not found in folder !')\n",
        "\n",
        "### MSA of gene\n",
        "aln_subsection = msa_protocol(name_msa_file)\n",
        "\n",
        "### Protrans\n",
        "# calculate the ProTrans for WT protein\n",
        "lines_list = []\n",
        "for line in range(len(aln_subsection)):\n",
        "  temp = aln_subsection.matrix[line, :].tolist()\n",
        "\n",
        "  x = [x.upper() for x in temp]\n",
        "  lines_list.append(x)\n",
        "\n",
        "str1 = \" \"\n",
        "lines_string = [str1.join(first_line) for first_line in lines_list]\n",
        "\n",
        "sequences_WT = [re.sub(r\"[-.]\", \"X\", sequence) for sequence in lines_string]\n",
        "\n",
        "indices_to_excl = []\n",
        "seq_pooled = []\n",
        "\n",
        "BATCH_FILE_SIZE = 15\n",
        "test_features_WT = []\n",
        "for count in range(0, math.floor(len(sequences_WT) / BATCH_FILE_SIZE)):\n",
        "    i = sequences_WT[count*15:(count+1)*15][:]\n",
        "    ids = tokenizer.batch_encode_plus(i, add_special_tokens=True, padding='longest')\n",
        "    input_ids = torch.tensor(ids['input_ids']).to(device)\n",
        "    attention_mask = torch.tensor(ids['attention_mask']).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      embedding = model(input_ids=input_ids,attention_mask=attention_mask)\n",
        "      embedding = embedding.last_hidden_state.cpu().numpy()\n",
        "\n",
        "      for seq_num in range(len(embedding)):\n",
        "        seq_len = (attention_mask[seq_num] == 1).sum()\n",
        "        seq_emd = embedding[seq_num][:seq_len-1]\n",
        "        test_features_WT.append(seq_emd)\n",
        "    del attention_mask\n",
        "    gc.collect()\n",
        "\n",
        "# converting list to array\n",
        "arr_WT = np.array(test_features_WT)\n",
        "seq_temp = torch.tensor(arr_WT)\n",
        "arr_WT = m(seq_temp) # use when you want to reduce dimensions from 1024 to 20\n",
        "print(arr_WT.shape, arr_WT[0].shape)\n",
        "arr_WT =arr_WT.numpy()\n",
        "\n",
        "columns = range(0, arr_WT.shape[1])\n",
        "differences_WT = []\n",
        "densities_WT = []\n",
        "#density_threshold_WT = []\n",
        "for col in columns:\n",
        "    first_col = arr_WT[:, col]\n",
        "    gmm = GaussianMixture(n_components=1).fit(first_col)\n",
        "    densities_temp = gmm.score_samples(first_col)\n",
        "    densities_WT.append(densities_temp)\n",
        "    threshold_temp = np.percentile(densities_temp, 1)\n",
        "    differences_WT.append(densities_temp[0] - threshold_temp)\n",
        "print('Columns (input to gmm) shape:', first_col.shape )\n",
        "\n",
        "### Calculate differences of all mutations of gene\n",
        "\n",
        "points, positions_list, colors = [], [], []\n",
        "for k, mut in mut_gene.iterrows():\n",
        "  diction_test = {} # dictionary containing the difference of log-probabilities of mutation from the lof-prob of WT\n",
        "\n",
        "  mut_seq = mut['mut_sequence']# mutated sequence\n",
        "  position = int(mut['position'])-1\n",
        "  AA_orig = mut['AA_orig']\n",
        "  AA_targ = mut['AA_targ']\n",
        "\n",
        "  new_str = [str(x) for x in mut_seq]\n",
        "  new_str[position] = AA_targ\n",
        "\n",
        "  str1 = \" \"\n",
        "  lines_string = str1.join(new_str)\n",
        "  MUT_sequence = re.sub(r\"[-.]\", \"X\", lines_string)\n",
        "\n",
        "  ids = tokenizer.batch_encode_plus([MUT_sequence], add_special_tokens=True, padding='longest')\n",
        "  input_ids = torch.tensor(ids['input_ids']).to(device)\n",
        "  attention_mask = torch.tensor(ids['attention_mask']).to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    embedding = model(input_ids=input_ids,attention_mask=attention_mask)\n",
        "    embedding = embedding.last_hidden_state.cpu().numpy()\n",
        "    #print(embedding.shape)\n",
        "    seq_len = (attention_mask == 1).sum()\n",
        "    seq_emd = embedding[:, :seq_len-1, :]\n",
        "\n",
        "  seq_emd = torch.tensor(seq_emd)\n",
        "  seq_emd = m(seq_emd) # use when you want to reduce dimensions from 1024 to 20\n",
        "  seq_emd =seq_emd.numpy()\n",
        "\n",
        "  arr_WT[0] = seq_emd[0]\n",
        "  del embedding, ids, MUT_sequence, attention_mask\n",
        "  gc.collect()\n",
        "\n",
        "  columns = range(0, arr_WT.shape[1])\n",
        "  differences_MUT = []\n",
        "  densities_MUT = []\n",
        "  for col in columns:\n",
        "      first_col = arr_WT[:, col]\n",
        "      gmm = GaussianMixture(n_components=1).fit(first_col)\n",
        "      densities_temp = gmm.score_samples(first_col)\n",
        "      densities_MUT.append(densities_temp)\n",
        "      threshold_temp = np.percentile(densities_temp, 1)\n",
        "      differences_MUT.append(densities_temp[0] - threshold_temp)\n",
        "\n",
        "  dif_dif = [differences_WT[i] - differences_MUT[i] for i in range(len(differences_MUT))] # difference of WT and Mutated sequence log probabiities\n",
        "\n",
        "  points.extend([x for x in dif_dif if x>7 ])\n",
        "\n",
        "  if position == 137:\n",
        "    positions_list.extend([133, 134, 135, 136, 138, 139, 140, 142])\n",
        "    colors.extend([\"yellow\", \"yellow\", \"yellow\",  \"yellow\", \"yellow\", \"red\", \"yellow\" , \"yellow\"])\n",
        "\n",
        "    for i in range(len(positions_list)):\n",
        "        plt.scatter(positions_list[i], points[i], color=colors[i])\n",
        "    plt.xlim([0, 392])\n",
        "    plt.plot(dif_dif, c='slategrey', alpha=0.5)\n",
        "\n",
        "\n",
        "  elif position == 275:\n",
        "\n",
        "    positions_list.extend([268, 269, 270, 271, 272, 273, 274, 276, 277, 278, 279, 280])\n",
        "    colors.extend([\"yellow\", \"yellow\", \"orange\", \"red\", \"orange\", \"red\", \"yellow\" , \"red\", \"red\" , \"orange\", \"yellow\" , \"orange\" ])\n",
        "\n",
        "    for i in range(len(positions_list)):\n",
        "        plt.scatter(positions_list[i], points[i], color=colors[i])\n",
        "    plt.xlim([0, 392])\n",
        "    plt.plot(dif_dif, c='black', alpha=0.5)\n",
        "\n",
        "\n",
        "  elif position == 357:\n",
        "\n",
        "    positions_list.extend([352, 355, 356])\n",
        "    colors.extend([\"grey\", \"grey\", \"grey\"])\n",
        "\n",
        "    for i in range(len(positions_list)):\n",
        "        plt.scatter(positions_list[i], points[i], color=colors[i])\n",
        "    plt.xlim([0, 392])\n",
        "    plt.plot(dif_dif, c='silver', alpha=0.5)\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "  ### Save dif_dif in a dictionary with keys: genename_mutation\n",
        "  gene_name_mutation = uniprot +'_' + AA_orig + str(mut['position']) + AA_targ\n",
        "\n",
        "  diction_test['uniprot_mut'] = gene_name_mutation\n",
        "  diction_test['Log dif'] = dif_dif"
      ],
      "metadata": {
        "id": "BX4JrBw-Q1a_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uniprot = 'P04637'\n",
        "plt.rcParams[\"figure.figsize\"] = (8,5)\n",
        "\n",
        "## Read in a sequence alignment from a fasta file\n",
        "if os.path.isfile(msa_path + uniprot+ \".a3m\"): # True if file exists\n",
        "  name_msa_file = msa_path + uniprot+ \".a3m\"\n",
        "else:\n",
        "  print('MSA not found in folder !')\n",
        "\n",
        "### MSA of gene\n",
        "aln_subsection = msa_protocol(name_msa_file)\n",
        "\n",
        "### Protrans\n",
        "# calculate the ProTrans for WT protein\n",
        "lines_list = []\n",
        "for line in range(len(aln_subsection)):\n",
        "  temp = aln_subsection.matrix[line, :].tolist()\n",
        "\n",
        "  x = [x.upper() for x in temp]\n",
        "  lines_list.append(x)\n",
        "\n",
        "str1 = \" \"\n",
        "lines_string = [str1.join(first_line) for first_line in lines_list]\n",
        "\n",
        "sequences_WT = [re.sub(r\"[-.]\", \"X\", sequence) for sequence in lines_string]\n",
        "\n",
        "indices_to_excl = []\n",
        "seq_pooled = []\n",
        "\n",
        "BATCH_FILE_SIZE = 15\n",
        "test_features_WT = []\n",
        "for count in range(0, math.floor(len(sequences_WT) / BATCH_FILE_SIZE)):\n",
        "    i = sequences_WT[count*15:(count+1)*15][:]\n",
        "    ids = tokenizer.batch_encode_plus(i, add_special_tokens=True, padding='longest')\n",
        "    input_ids = torch.tensor(ids['input_ids']).to(device)\n",
        "    attention_mask = torch.tensor(ids['attention_mask']).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      embedding = model(input_ids=input_ids,attention_mask=attention_mask)\n",
        "      embedding = embedding.last_hidden_state.cpu().numpy()\n",
        "\n",
        "      for seq_num in range(len(embedding)):\n",
        "        seq_len = (attention_mask[seq_num] == 1).sum()\n",
        "        seq_emd = embedding[seq_num][:seq_len-1]\n",
        "        test_features_WT.append(seq_emd)\n",
        "    del attention_mask\n",
        "    gc.collect()\n",
        "\n",
        "# converting list to array\n",
        "arr_WT = np.array(test_features_WT)\n",
        "seq_temp = torch.tensor(arr_WT)\n",
        "arr_WT = m(seq_temp) # use when you want to reduce dimensions from 1024 to 20\n",
        "print(arr_WT.shape, arr_WT[0].shape)\n",
        "arr_WT =arr_WT.numpy()\n",
        "\n",
        "columns = range(0, arr_WT.shape[1])\n",
        "differences_WT = []\n",
        "densities_WT = []\n",
        "#density_threshold_WT = []\n",
        "for col in columns:\n",
        "    first_col = arr_WT[:, col]\n",
        "    gmm = GaussianMixture(n_components=1).fit(first_col)\n",
        "    densities_temp = gmm.score_samples(first_col)\n",
        "    densities_WT.append(densities_temp)\n",
        "    threshold_temp = np.percentile(densities_temp, 1)\n",
        "    differences_WT.append(densities_temp[0] - threshold_temp)\n",
        "print('Columns (input to gmm) shape:', first_col.shape )\n",
        "\n",
        "### Calculate differences of all mutations of gene\n",
        "\n",
        "points, positions_list, colors = [], [], []\n",
        "for k, mut in mut_gene.iterrows():\n",
        "  diction_test = {} # dictionary containing the difference of log-probabilities of mutation from the lof-prob of WT\n",
        "\n",
        "  mut_seq = mut['mut_sequence']# mutated sequence\n",
        "  position = int(mut['position'])-1\n",
        "  AA_orig = mut['AA_orig']\n",
        "  AA_targ = mut['AA_targ']\n",
        "\n",
        "  new_str = [str(x) for x in mut_seq]\n",
        "  new_str[position] = AA_targ\n",
        "\n",
        "  str1 = \" \"\n",
        "  lines_string = str1.join(new_str)\n",
        "  MUT_sequence = re.sub(r\"[-.]\", \"X\", lines_string)\n",
        "\n",
        "  ids = tokenizer.batch_encode_plus([MUT_sequence], add_special_tokens=True, padding='longest')\n",
        "  input_ids = torch.tensor(ids['input_ids']).to(device)\n",
        "  attention_mask = torch.tensor(ids['attention_mask']).to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    embedding = model(input_ids=input_ids,attention_mask=attention_mask)\n",
        "    embedding = embedding.last_hidden_state.cpu().numpy()\n",
        "    #print(embedding.shape)\n",
        "    seq_len = (attention_mask == 1).sum()\n",
        "    seq_emd = embedding[:, :seq_len-1, :]\n",
        "\n",
        "  seq_emd = torch.tensor(seq_emd)\n",
        "  seq_emd = m(seq_emd) # use when you want to reduce dimensions from 1024 to 20\n",
        "  seq_emd =seq_emd.numpy()\n",
        "\n",
        "  arr_WT[0] = seq_emd[0]\n",
        "  del embedding, ids, MUT_sequence, attention_mask\n",
        "  gc.collect()\n",
        "\n",
        "  columns = range(0, arr_WT.shape[1])\n",
        "  differences_MUT = []\n",
        "  densities_MUT = []\n",
        "  for col in columns:\n",
        "      first_col = arr_WT[:, col]\n",
        "      gmm = GaussianMixture(n_components=1).fit(first_col)\n",
        "      densities_temp = gmm.score_samples(first_col)\n",
        "      densities_MUT.append(densities_temp)\n",
        "      threshold_temp = np.percentile(densities_temp, 1)\n",
        "      differences_MUT.append(densities_temp[0] - threshold_temp)\n",
        "\n",
        "  dif_dif = [differences_WT[i] - differences_MUT[i] for i in range(len(differences_MUT))] # difference of WT and Mutated sequence log probabiities\n",
        "\n",
        "  points.extend([x for x in dif_dif if x>7 ])\n",
        "\n",
        "  #if position == 137:\n",
        "    #positions_list.extend([133, 134, 135, 136, 138, 139, 140, 142])\n",
        "    #colors.extend([\"yellow\", \"yellow\", \"yellow\",  \"yellow\", \"yellow\", \"red\", \"yellow\" , \"yellow\"])\n",
        "\n",
        "    #for i in range(len(positions_list)):\n",
        "    #    plt.scatter(positions_list[i], points[i], color=colors[i])\n",
        "    #plt.xlim([0, 392])\n",
        "  plt.plot(dif_dif, c='slategrey', alpha=0.5)\n",
        "  '''\n",
        "\n",
        "  elif position == 275:\n",
        "\n",
        "    positions_list.extend([268, 269, 270, 271, 272, 273, 274, 276, 277, 278, 279, 280])\n",
        "    colors.extend([\"yellow\", \"yellow\", \"orange\", \"red\", \"orange\", \"red\", \"yellow\" , \"red\", \"red\" , \"orange\", \"yellow\" , \"orange\" ])\n",
        "\n",
        "    for i in range(len(positions_list)):\n",
        "        plt.scatter(positions_list[i], points[i], color=colors[i])\n",
        "    plt.xlim([0, 392])\n",
        "    plt.plot(dif_dif, c='black', alpha=0.5)\n",
        "\n",
        "\n",
        "  elif position == 357:\n",
        "\n",
        "    positions_list.extend([352, 355, 356])\n",
        "    colors.extend([\"grey\", \"grey\", \"grey\"])\n",
        "\n",
        "    for i in range(len(positions_list)):\n",
        "        plt.scatter(positions_list[i], points[i], color=colors[i])\n",
        "    plt.xlim([0, 392])\n",
        "    plt.plot(dif_dif, c='silver', alpha=0.5)\n",
        "   '''\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "  ### Save dif_dif in a dictionary with keys: genename_mutation\n",
        "  gene_name_mutation = uniprot +'_' + AA_orig + str(mut['position']) + AA_targ\n",
        "\n",
        "  diction_test['uniprot_mut'] = gene_name_mutation\n",
        "  diction_test['Log dif'] = dif_dif"
      ],
      "metadata": {
        "id": "Ouur4CZR_MDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### BRAF"
      ],
      "metadata": {
        "id": "X0C_pDW_pgh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "braf = all_predictions_labels[all_predictions_labels['uniprot id'] == 'P15056']\n",
        "braf_labelled = labelled[labelled['uniprot id'] == 'P15056']\n",
        "\n",
        "correct =braf_labelled['correct_label'].sum()\n",
        "print(f'Correct labels for braf: { round(correct)} out of {len(braf_labelled)} with known significance. Accuracy: {round(correct/ len(braf_labelled),3)}')\n",
        "print('--------------------------')\n",
        "print('Inorrect labels for braf: ', len(braf_labelled[braf_labelled['correct_label'] == 0]))\n",
        "print('--------------------------')\n",
        "print(f'VUS labels for braf: {len(braf) - len(braf_labelled)}, VUS percentage in gene annotations {round(len(braf) - len(braf_labelled)/len(braf),3)}')"
      ],
      "metadata": {
        "id": "F6QhMURC7ju6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct, incorrect, vus_nb, count_mutations, incorrect_mutation, correct_mutation, predictions_clinvar_labels = d2d_performance_vs_clinvar_labels_correct(braf_predictions, braf_clinvar, False)\n",
        "predictions_clinvar_labels['pos'] = pd.to_numeric(predictions_clinvar_labels['position'],errors='coerce')\n",
        "test= predictions_clinvar_labels.sort_values(by='position', ascending=True)"
      ],
      "metadata": {
        "id": "nvQyFNJr7ju6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.scatter(test, x='pos', y='D2D_prediction',\n",
        "                 color =  test['lab_clinvar'],\n",
        "                 symbol = test['lab_clinvar'],\n",
        "                 symbol_sequence= ['circle-open', 'circle-open', 'circle','circle','circle', 'circle'],\n",
        "                 #color_discrete_sequence = ['#a4c639' ,'#ffa7b1' ,'#a4c639', '#ffa7b1', '#23712E'  ,'#D82626'], opacity = 0.85, width =850, height =400,  hover_data=['conc_mutation', 'D2D_prediction' ])\n",
        "                 color_discrete_sequence = ['#82AAE3' ,'#ffa7b1' ,'#82AAE3', '#ffa7b1', 'blue','#ed5564' ], opacity = 0.85, width =850, height =400,  hover_data=['conc_mutation', 'D2D_prediction' ])\n",
        "\n",
        "\n",
        "# Change the bar mode\n",
        "fig.update_layout(barmode='group', title=\"BRAF Gene \",\n",
        "    xaxis_title=\"Position\",\n",
        "    yaxis_title=\"D2D prediction\",\n",
        "    font_family=\"Arial\",\n",
        "    legend_title=\"Groundtruth\",\n",
        "    title_font_family=\"Arial\")\n",
        "\n",
        "fig.update_layout({\n",
        "'plot_bgcolor': 'rgba(255, 255, 255, 255)' ,\n",
        "'paper_bgcolor': 'rgba(255, 255, 255, 255)',\n",
        "})\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "CmxA566h7ju7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Weigthed Accuracy"
      ],
      "metadata": {
        "id": "PohhYOwdg774"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weighted_sum = (braf_labelled['overall_confidence'] * braf_labelled['correct_label']).sum()\n",
        "total_weight = braf_labelled['overall_confidence'].sum()\n",
        "weighted_average = weighted_sum / total_weight\n",
        "print(weighted_average)"
      ],
      "metadata": {
        "id": "hrRgu7rTg-HX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "high_confidence_predictions = braf[braf['overall_confidence'] >=0.65] # 0.5\n",
        "high_positions =  high_confidence_predictions['position'].tolist()\n",
        "high_positions = [int(x) for x in high_positions]\n",
        "\n",
        "low_confidence_predictions = braf[braf['overall_confidence'] < 0.5] #0.3\n",
        "low_positions =  low_confidence_predictions['position'].tolist()\n",
        "low_positions = [int(x) for x in low_positions]\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (10,3)\n",
        "plt.scatter(high_positions, high_confidence_predictions['overall_confidence'], label = 'high overall_confidence', c='b', alpha=0.7)\n",
        "plt.show()\n",
        "plt.rcParams[\"figure.figsize\"] = (10,3)\n",
        "plt.scatter(low_positions, low_confidence_predictions['overall_confidence'], label = 'low overall_confidence', c='b', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MbwZc81F7ju7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "high_confidence_predictions['pos'] = pd.to_numeric(high_confidence_predictions['position'],errors='coerce')\n",
        "test_high = high_confidence_predictions.sort_values(by='position', ascending=True)"
      ],
      "metadata": {
        "id": "X6FwHqOe7ju7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.scatter(test_high, x='pos', y='D2D_prediction',\n",
        "                 color =  test_high['lab_clinvar'],\n",
        "                 symbol = test_high['lab_clinvar'],\n",
        "                 symbol_sequence= ['circle-open', 'circle', 'circle','circle-open','circle', 'circle'],\n",
        "                 #color_discrete_sequence = ['#a4c639' ,'#a4c639' ,'#ffa7b1', '#23712E', '#D82626'  ,'#ffa7b1'], opacity = 0.85, width =850, height =400,  hover_data=['conc_mutation', 'D2D_prediction' ])\n",
        "                 color_discrete_sequence = ['#82AAE3' ,'#82AAE3' ,'blue', '#ffa7b1', '#ffa7b1','#ed5564' ], opacity = 0.85, width =850, height =400,  hover_data=['conc_mutation', 'D2D_prediction' ])\n",
        "\n",
        "\n",
        "# Change the bar mode\n",
        "fig.update_layout(barmode='group', title=\"BRAF Gene \",\n",
        "    xaxis_title=\"Position\",\n",
        "    yaxis_title=\"D2D prediction\",\n",
        "    font_family=\"Arial\",\n",
        "    legend_title=\"Groundtruth\",\n",
        "    title_font_family=\"Arial\")\n",
        "\n",
        "fig.update_layout({\n",
        "'plot_bgcolor': 'rgba(255, 255, 255, 255)' ,\n",
        "'paper_bgcolor': 'rgba(255, 255, 255, 255)',\n",
        "})\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "kYI169nU7ju7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Novel mutations"
      ],
      "metadata": {
        "id": "d9DeR2Ly7ju7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "braf_predictions_norm = normalise_confidence(braf_predictions)"
      ],
      "metadata": {
        "id": "b53fbwct7ju7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CPV - BRAF\n",
        "print('Prediction:',braf_predictions_norm[braf_predictions_norm['conc_mutation']== 'G469A']['D2D_prediction'].values[0], 'Confidence:',  round(braf_predictions_norm[braf_predictions_norm['conc_mutation']== 'G469A']['overall_confidence'].values[0],3))\n",
        "print('---------------')\n",
        "print('Prediction:',braf_predictions_norm[braf_predictions_norm['conc_mutation']== 'G469R']['D2D_prediction'].values[0], 'Confidence:',  round(braf_predictions_norm[braf_predictions_norm['conc_mutation']== 'G469R']['overall_confidence'].values[0],3))\n",
        "print('---------------')\n",
        "print('Prediction:', braf_predictions_norm[braf_predictions_norm['conc_mutation']== 'G469E']['D2D_prediction'].values[0], 'Confidence:',  round(braf_predictions_norm[braf_predictions_norm['conc_mutation']== 'G469E']['overall_confidence'].values[0],3))\n",
        "print('---------------')\n",
        "print('Prediction:', braf_predictions_norm[braf_predictions_norm['conc_mutation']==  'G469V']['D2D_prediction'].values[0], 'Confidence:',  round(braf_predictions_norm[braf_predictions_norm['conc_mutation']== 'G469V']['overall_confidence'].values[0],3))\n",
        "print('---------------')\n",
        "print('Prediction:', braf_predictions_norm[braf_predictions_norm['conc_mutation']==  'D594G']['D2D_prediction'].values[0], 'Confidence:',  round(braf_predictions_norm[braf_predictions_norm['conc_mutation']==  'D594G']['overall_confidence'].values[0],3))\n",
        "print('---------------')\n",
        "print('Prediction:',braf_predictions_norm[braf_predictions_norm['conc_mutation']==  'V600E']['D2D_prediction'].values[0], 'Confidence:',  round(braf_predictions_norm[braf_predictions_norm['conc_mutation']==  'V600E']['overall_confidence'].values[0],3))\n",
        "print('---------------')\n",
        "print('Prediction:', braf_predictions_norm[braf_predictions_norm['conc_mutation']== 'V600K']['D2D_prediction'].values[0], 'Confidence:',  round(braf_predictions_norm[braf_predictions_norm['conc_mutation']==  'V600K']['overall_confidence'].values[0],3))\n",
        "print('---------------')\n",
        "print('Prediction:', braf_predictions_norm[braf_predictions_norm['conc_mutation']==  'V600M']['D2D_prediction'].values[0], 'Confidence:', round(braf_predictions_norm[braf_predictions_norm['conc_mutation']==  'V600M']['overall_confidence'].values[0],3))\n",
        "print('---------------')\n",
        "print('Prediction:', braf_predictions_norm[braf_predictions_norm['conc_mutation']== 'V600R']['D2D_prediction'].values[0], 'Confidence:', round( braf_predictions_norm[braf_predictions_norm['conc_mutation']== 'V600R']['overall_confidence'].values[0],3))\n",
        "print('---------------')\n",
        "print('Prediction:', braf_predictions_norm[braf_predictions_norm['conc_mutation']== 'K601E']['D2D_prediction'].values[0], 'Confidence:', round( braf_predictions_norm[braf_predictions_norm['conc_mutation']==  'K601E']['overall_confidence'].values[0],3))"
      ],
      "metadata": {
        "id": "8Gm7L9is-IoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Novel F468S and N581Y https://www.sciencedirect.com/science/article/pii/S1556086420304664\n",
        "braf_predictions_norm[braf_predictions_norm['conc_mutation']== 'F468S']"
      ],
      "metadata": {
        "id": "R9gSdh9x-IoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "braf_predictions_norm[braf_predictions_norm['conc_mutation'] == 'N581Y']"
      ],
      "metadata": {
        "id": "yP3jCgYk-IoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### PTEN"
      ],
      "metadata": {
        "id": "cSlqwPSGCZrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pten = all_predictions_labels[all_predictions_labels['uniprot id'] == 'P60484']\n",
        "pten_labelled = labelled[labelled['uniprot id'] == 'P60484']\n",
        "\n",
        "correct =pten_labelled['correct_label'].sum()\n",
        "print(f'Correct labels \\for pten: { round(correct)} out of {len(pten_labelled)} with known significance. Accuracy: {round(correct/ len(pten_labelled),3)}')\n",
        "print('--------------------------')\n",
        "print('Inorrect labels for pten: ', len(pten_labelled[pten_labelled['correct_label'] == 0]))\n",
        "print('--------------------------')\n",
        "print(f'VUS labels for pten: {len(pten) - len(pten_labelled)}, VUS percentage in gene annotations {round((len(pten) - len(pten_labelled))/len(pten),3)}')"
      ],
      "metadata": {
        "id": "Q5D9HLu4CiKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct, incorrect, vus_nb, count_mutations, incorrect_mutation, correct_mutation, predictions_clinvar_labels = d2d_performance_vs_clinvar_labels_correct(pten_predictions, pten_clinvar, False)\n",
        "predictions_clinvar_labels['pos'] = pd.to_numeric(predictions_clinvar_labels['position'],errors='coerce')\n",
        "test= predictions_clinvar_labels.sort_values(by='position', ascending=True)"
      ],
      "metadata": {
        "id": "6xv-jSezCiKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.scatter(test, x='pos', y='D2D_prediction',\n",
        "                 color =  test['lab_clinvar'],\n",
        "                 symbol = test['lab_clinvar'],\n",
        "                 symbol_sequence= ['circle', 'circle-open','circle','circle-open', 'circle'],\n",
        "                 color_discrete_sequence = ['#ed5564' , '#ffa7b1', '#ffa7b1','#82AAE3', '#82AAE3' ], opacity = 0.85, width =850, height =400,  hover_data=['conc_mutation', 'D2D_prediction' ])\n",
        "                 #color_discrete_sequence = ['#a4c639' ,'#a4c639' ,'#ffa7b1', '#ffa7b1', '#23712E'  ,'#D82626'], opacity = 0.85, width =850, height =400,  hover_data=['conc_mutation', 'D2D_prediction' ])\n",
        "\n",
        "\n",
        "\n",
        "# Change the bar mode\n",
        "fig.update_layout(barmode='group', title=\"PTEN Gene \",\n",
        "    xaxis_title=\"Position\",\n",
        "    yaxis_title=\"D2D prediction\",\n",
        "    font_family=\"Arial\",\n",
        "    legend_title=\"Groundtruth\",\n",
        "    title_font_family=\"Arial\")\n",
        "\n",
        "fig.update_layout({\n",
        "'plot_bgcolor': 'rgba(255, 255, 255, 255)' ,\n",
        "'paper_bgcolor': 'rgba(255, 255, 255, 255)',\n",
        "})\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "tUSMrLI6iSYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.scatter(test, x='pos', y='D2D_prediction',\n",
        "                 color =  test['lab_clinvar'],\n",
        "                 symbol = test['lab_clinvar'],\n",
        "                 symbol_sequence= ['circle', 'circle-open', 'circle','circle-open','circle'],\n",
        "                 color_discrete_sequence = ['#D82626' ,'#ffa7b1' ,'#ffa7b1', '#a4c639', '#a4c639' ], opacity = 0.85, width =850, height =400,  hover_data=['conc_mutation', 'D2D_prediction' ])\n",
        "\n",
        "\n",
        "# Change the bar mode\n",
        "fig.update_layout(barmode='group', title=\"PTEN Gene \",\n",
        "    xaxis_title=\"Position\",\n",
        "    yaxis_title=\"D2D prediction\",\n",
        "    font_family=\"Arial\",\n",
        "    legend_title=\"Groundtruth\",\n",
        "    title_font_family=\"Arial\")\n",
        "\n",
        "fig.update_layout({\n",
        "'plot_bgcolor': 'rgba(255, 255, 255, 255)' ,\n",
        "'paper_bgcolor': 'rgba(255, 255, 255, 255)',\n",
        "})\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "fyuDvI6cCiKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Weigthed Accuracy"
      ],
      "metadata": {
        "id": "rxV2C6SPhw_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weighted_sum = (pten_labelled['overall_confidence'] * pten_labelled['correct_label']).sum()\n",
        "total_weight = pten_labelled['overall_confidence'].sum()\n",
        "weighted_average = weighted_sum / total_weight\n",
        "print(weighted_average)"
      ],
      "metadata": {
        "id": "DX6y0Qykhw_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "high_confidence_predictions = pten[pten['overall_confidence'] >=0.65]\n",
        "high_positions =  high_confidence_predictions['position'].tolist()\n",
        "high_positions = [int(x) for x in high_positions]\n",
        "\n",
        "low_confidence_predictions = pten[pten['overall_confidence'] < 0.3]\n",
        "low_positions =  low_confidence_predictions['position'].tolist()\n",
        "low_positions = [int(x) for x in low_positions]\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (10,3)\n",
        "plt.scatter(high_positions, high_confidence_predictions['overall_confidence'], label = 'high overall_confidence', c='b', alpha=0.7)\n",
        "plt.show()\n",
        "plt.rcParams[\"figure.figsize\"] = (10,3)\n",
        "plt.scatter(low_positions, low_confidence_predictions['overall_confidence'], label = 'low overall_confidence', c='b', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "G9zPctDBCiKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "high_confidence_predictions['pos'] = pd.to_numeric(high_confidence_predictions['position'],errors='coerce')\n",
        "test_high = high_confidence_predictions.sort_values(by='position', ascending=True)"
      ],
      "metadata": {
        "id": "oXEJ6tHkCiKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.scatter(test_high, x='pos', y='D2D_prediction',\n",
        "                 color =  test_high['lab_clinvar'],\n",
        "                 symbol = test_high['lab_clinvar'],\n",
        "                symbol_sequence= ['circle', 'circle-open','circle','circle-open', 'circle'],\n",
        "                 color_discrete_sequence = ['#ed5564' , '#ffa7b1', '#ffa7b1','#82AAE3', '#82AAE3' ], opacity = 0.85, width =850, height =400,  hover_data=['conc_mutation', 'D2D_prediction' ])\n",
        "\n",
        "\n",
        "# Change the bar mode\n",
        "fig.update_layout(barmode='group', title=\"PTEN Gene \",\n",
        "    xaxis_title=\"Position\",\n",
        "    yaxis_title=\"D2D prediction\",\n",
        "    font_family=\"Arial\",\n",
        "    legend_title=\"Groundtruth\",\n",
        "    title_font_family=\"Arial\")\n",
        "\n",
        "fig.update_layout({\n",
        "'plot_bgcolor': 'rgba(255, 255, 255, 255)' ,\n",
        "'paper_bgcolor': 'rgba(255, 255, 255, 255)',\n",
        "})\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "oIfhrtjUCiKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CHEK2"
      ],
      "metadata": {
        "id": "bKhmhEj2GAfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pten = all_predictions_labels[all_predictions_labels['uniprot id'] == 'O96017']\n",
        "pten_labelled = labelled[labelled['uniprot id'] == 'O96017']\n",
        "\n",
        "correct =pten_labelled['correct_label'].sum()\n",
        "print(f'Correct labels for CHEK2: { round(correct)} out of {len(pten_labelled)} with known significance. Accuracy: {round(correct/ len(pten_labelled),3)}')\n",
        "print('--------------------------')\n",
        "print('Inorrect labels for CHEK2: ', len(pten_labelled[pten_labelled['correct_label'] == 0]))\n",
        "print('--------------------------')\n",
        "print(f'VUS labels for CHEK2: {len(pten) - len(pten_labelled)}, VUS percentage in gene annotations {round((len(pten) - len(pten_labelled))/len(pten),3)}')"
      ],
      "metadata": {
        "id": "PFwOVgfyGGld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct, incorrect, vus_nb, count_mutations, incorrect_mutation, correct_mutation, predictions_clinvar_labels = d2d_performance_vs_clinvar_labels_correct(chek2_predictions, chek2_clinvar, False)\n",
        "predictions_clinvar_labels['pos'] = pd.to_numeric(predictions_clinvar_labels['position'],errors='coerce')\n",
        "test= predictions_clinvar_labels.sort_values(by='position', ascending=True)"
      ],
      "metadata": {
        "id": "mnu4gcW6GGle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Weigthed Accuracy"
      ],
      "metadata": {
        "id": "9U7ppIvjiCNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weighted_sum = (pten_labelled['overall_confidence'] * pten_labelled['correct_label']).sum()\n",
        "total_weight = pten_labelled['overall_confidence'].sum()\n",
        "weighted_average = weighted_sum / total_weight\n",
        "print(weighted_average)"
      ],
      "metadata": {
        "id": "3JxH2EtXiCNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.scatter(test, x='pos', y='D2D_prediction',\n",
        "                 color =  test['lab_clinvar'],\n",
        "                 symbol = test['lab_clinvar'],\n",
        "                 symbol_sequence= ['circle-open', 'circle','circle-open','circle'],\n",
        "                 color_discrete_sequence = ['#82AAE3' , '#ffa7b1','#ffa7b1', '#82AAE3' ], opacity = 0.85, width =850, height =400,  hover_data=['conc_mutation', 'D2D_prediction' ])\n",
        "\n",
        "\n",
        "# Change the bar mode\n",
        "fig.update_layout(barmode='group', title=\"CHEK2 Gene \",\n",
        "    xaxis_title=\"Position\",\n",
        "    yaxis_title=\"D2D prediction\",\n",
        "    font_family=\"Arial\",\n",
        "    legend_title=\"Groundtruth\",\n",
        "    title_font_family=\"Arial\")\n",
        "\n",
        "fig.update_layout({\n",
        "'plot_bgcolor': 'rgba(255, 255, 255, 255)' ,\n",
        "'paper_bgcolor': 'rgba(255, 255, 255, 255)',\n",
        "})\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "5EnZXxqoGGle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "high_confidence_predictions = pten[pten['overall_confidence'] >=0.65]\n",
        "high_positions =  high_confidence_predictions['position'].tolist()\n",
        "high_positions = [int(x) for x in high_positions]\n",
        "\n",
        "low_confidence_predictions = pten[pten['overall_confidence'] < 0.3]\n",
        "low_positions =  low_confidence_predictions['position'].tolist()\n",
        "low_positions = [int(x) for x in low_positions]\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (10,3)\n",
        "plt.scatter(high_positions, high_confidence_predictions['overall_confidence'], label = 'high overall_confidence', c='b', alpha=0.7)\n",
        "plt.show()\n",
        "plt.rcParams[\"figure.figsize\"] = (10,3)\n",
        "plt.scatter(low_positions, low_confidence_predictions['overall_confidence'], label = 'low overall_confidence', c='b', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "a_bdUHaZGGle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "high_confidence_predictions['pos'] = pd.to_numeric(high_confidence_predictions['position'],errors='coerce')\n",
        "test_high = high_confidence_predictions.sort_values(by='position', ascending=True)"
      ],
      "metadata": {
        "id": "LpiIYk9BGGle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.scatter(test_high, x='pos', y='D2D_prediction',\n",
        "                 color =  test_high['lab_clinvar'],\n",
        "                 symbol = test_high['lab_clinvar'],\n",
        "                 symbol_sequence= ['circle-open', 'circle','circle-open'],\n",
        "                 color_discrete_sequence = ['#82AAE3' , '#82AAE3','#ffa7b1' ], opacity = 0.85, width =850, height =400,  hover_data=['conc_mutation', 'D2D_prediction' ])\n",
        "\n",
        "\n",
        "# Change the bar mode\n",
        "fig.update_layout(barmode='group', title=\"CHEK2 Gene \",\n",
        "    xaxis_title=\"Position\",\n",
        "    yaxis_title=\"D2D prediction\",\n",
        "    font_family=\"Arial\",\n",
        "    legend_title=\"Groundtruth\",\n",
        "    title_font_family=\"Arial\")\n",
        "\n",
        "fig.update_layout({\n",
        "'plot_bgcolor': 'rgba(255, 255, 255, 255)' ,\n",
        "'paper_bgcolor': 'rgba(255, 255, 255, 255)',\n",
        "})\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "I7RuwcZLGGle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### AR"
      ],
      "metadata": {
        "id": "DjlxeFGCGBs9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tp53 = all_predictions_labels[all_predictions_labels['uniprot id'] == 'P10275']\n",
        "tp53_labelled = labelled[labelled['uniprot id'] == 'P10275']\n",
        "\n",
        "correct =tp53_labelled['correct_label'].sum()\n",
        "print(f'Correct labels for AR: { round(correct)} out of {len(tp53_labelled)} with known significance. Accuracy: {round(correct/ len(tp53_labelled),3)}')\n",
        "print('--------------------------')\n",
        "print('Inorrect labels for AR: ', len(tp53_labelled[tp53_labelled['correct_label'] == 0]))\n",
        "print('--------------------------')\n",
        "print(f'VUS labels for AR: {len(tp53) - len(tp53_labelled)}, VUS percentage in gene annotations {round(len(tp53) - len(tp53_labelled)/len(tp53),3)}')"
      ],
      "metadata": {
        "id": "KL7dwkrKHiBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct, incorrect, vus_nb, count_mutations, incorrect_mutation, correct_mutation, predictions_clinvar_labels = d2d_performance_vs_clinvar_labels_correct(ar_predictions, ar_clinvar, False)\n",
        "predictions_clinvar_labels['pos'] = pd.to_numeric(predictions_clinvar_labels['position'],errors='coerce')\n",
        "test= predictions_clinvar_labels.sort_values(by='position', ascending=True)"
      ],
      "metadata": {
        "id": "ERyT8h6eHiB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Weigthed Accuracy"
      ],
      "metadata": {
        "id": "iNR1LR5pigmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weighted_sum = (tp53_labelled['overall_confidence'] * tp53_labelled['correct_label']).sum()\n",
        "total_weight = tp53_labelled['overall_confidence'].sum()\n",
        "weighted_average = weighted_sum / total_weight\n",
        "print(weighted_average)"
      ],
      "metadata": {
        "id": "7b_SDCczigmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.scatter(test, x='pos', y='D2D_prediction',\n",
        "                 color =  test['lab_clinvar'],\n",
        "                 symbol = test['lab_clinvar'],\n",
        "                 symbol_sequence= ['circle','circle','circle', 'circle-open','circle', 'circle-open'],\n",
        "                 color_discrete_sequence = ['#ffa7b1' ,'#82AAE3' ,'#ed5564', '#ffa7b1', 'blue'  ,'#ffa7b1'], opacity = 0.85, width =850, height =400,  hover_data=['conc_mutation', 'D2D_prediction' ])\n",
        "\n",
        "# Change the bar mode\n",
        "fig.update_layout(barmode='group', title=\"AR Gene \",\n",
        "    xaxis_title=\"Position\",\n",
        "    yaxis_title=\"D2D prediction\",\n",
        "    font_family=\"Arial\",\n",
        "    legend_title=\"Groundtruth\",\n",
        "    title_font_family=\"Arial\")\n",
        "\n",
        "fig.update_layout({\n",
        "'plot_bgcolor': 'rgba(255, 255, 255, 255)' ,\n",
        "'paper_bgcolor': 'rgba(255, 255, 255, 255)',\n",
        "})\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "up2tPvQ5HiB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "high_confidence_predictions = tp53[tp53['overall_confidence'] >=0.65]\n",
        "high_positions =  high_confidence_predictions['position'].tolist()\n",
        "high_positions = [int(x) for x in high_positions]\n",
        "\n",
        "low_confidence_predictions = tp53[tp53['overall_confidence'] < 0.3]\n",
        "low_positions =  low_confidence_predictions['position'].tolist()\n",
        "low_positions = [int(x) for x in low_positions]\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (10,3)\n",
        "plt.scatter(high_positions, high_confidence_predictions['overall_confidence'], label = 'high overall_confidence', c='b', alpha=0.7)\n",
        "plt.show()\n",
        "plt.rcParams[\"figure.figsize\"] = (10,3)\n",
        "plt.scatter(low_positions, low_confidence_predictions['overall_confidence'], label = 'low overall_confidence', c='b', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BmYjpM0SHiB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "high_confidence_predictions['pos'] = pd.to_numeric(high_confidence_predictions['position'],errors='coerce')\n",
        "test_high = high_confidence_predictions.sort_values(by='position', ascending=True)"
      ],
      "metadata": {
        "id": "DQqY0nJQHiB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.scatter(test_high, x='pos', y='D2D_prediction',\n",
        "                 color =  test_high['lab_clinvar'],\n",
        "                 symbol = test_high['lab_clinvar'],\n",
        "                 symbol_sequence= ['circle','circle','circle', 'circle-open','circle', 'circle-open'],\n",
        "                 color_discrete_sequence = ['#82AAE3' ,'#ed5564' ,'blue', '#82AAE3', '#ffa7b1'  ,'#ffa7b1'], opacity = 0.85, width =850, height =400,  hover_data=['conc_mutation', 'D2D_prediction' ])\n",
        "\n",
        "\n",
        "# Change the bar mode\n",
        "fig.update_layout(barmode='group', title=\"AR Gene \",\n",
        "    xaxis_title=\"Position\",\n",
        "    yaxis_title=\"D2D prediction\",\n",
        "    font_family=\"Arial\",\n",
        "    legend_title=\"Groundtruth\",\n",
        "    title_font_family=\"Arial\")\n",
        "\n",
        "fig.update_layout({\n",
        "'plot_bgcolor': 'rgba(255, 255, 255, 255)' ,\n",
        "'paper_bgcolor': 'rgba(255, 255, 255, 255)',\n",
        "})\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "PVymcVQQHiB2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "TclLbcx3-a6k",
        "toKOCmDZ2oax",
        "Xie-HSRZ83bM",
        "XBRk7tRE-4ns",
        "ZFIqA9tK9NZN",
        "pf3OERpn-9Na",
        "eGGSoExoAR0G",
        "sF7m_Ir-_B2Y",
        "4pSBhzp97LEM",
        "8i2m2I4m_hQg",
        "jS-BjE7ukqFB",
        "h4h6YSjtkuJx",
        "7zfJvTjZy_sF",
        "YlDX6Lqv0NpK",
        "pRC2glz20Qfa",
        "X0C_pDW_pgh_",
        "p3bJsKwPH4jv",
        "Kn7EkO8L2yN0",
        "vL3HxV69jmiX",
        "C9WArGp2lQKe"
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}