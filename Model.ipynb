{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuClass": "premium"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "jTCjN5rAX7Wf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GH7nhNqAX1Tl"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import seaborn as sns\n",
        "from scipy.stats import wilcoxon\n",
        "from collections import OrderedDict\n",
        "import pickle\n",
        "import plotly.express as px\n",
        "from csv import DictWriter\n",
        "from matplotlib_venn import venn2, venn2_circles\n",
        "from sklearn.mixture import GaussianMixture\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "import math\n",
        "import imblearn\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import gc\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler, TensorDataset\n",
        "from sklearn.preprocessing import MinMaxScaler , StandardScaler\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
        "from numpy import asarray,savez_compressed\n",
        "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
        "!pip install -q SentencePiece transformers\n",
        "from transformers import AdamW, get_cosine_schedule_with_warmup, get_linear_schedule_with_warmup, T5EncoderModel, T5Tokenizer\n",
        "import torch.nn as nn\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import requests\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn import metrics\n",
        "#from torch.utils import data\n",
        "import re\n",
        "import os\n",
        "!pip install Biopython"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "EpMYyPwyX-cw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOjQc6HHvtJl"
      },
      "outputs": [],
      "source": [
        "class Classifier2L(nn.Module):\n",
        "    def __init__(self, hidden, hidden2, dropout=0):\n",
        "        super(Classifier2L, self).__init__()\n",
        "        self.hidden = hidden\n",
        "        self.hidden2 = hidden2\n",
        "        self.num_feature = 2200\n",
        "        self.dropout = dropout\n",
        "        self.batchnorm1 = nn.BatchNorm1d(self.hidden)\n",
        "        self.batchnorm2 = nn.BatchNorm1d(self.hidden2)\n",
        "\n",
        "        self.layer_1 = nn.Linear(self.num_feature,  self.hidden)\n",
        "        self.layer_2 = nn.Linear( self.hidden, self.hidden2)\n",
        "        self.layer_3 = nn.Linear( self.hidden2, 1)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer_1(x)\n",
        "        x = self.batchnorm1(x)\n",
        "        x= self.dropout(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.layer_2(x)\n",
        "        x = self.batchnorm2(x)\n",
        "        x = self.relu(x)\n",
        "        x= self.dropout(x)\n",
        "\n",
        "        x = self.layer_3(x)\n",
        "        #x = self.sigmoid(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "    def compute_l1_loss(self, w):\n",
        "        return torch.abs(w).sum()\n",
        "\n",
        "    def compute_l2_loss(self, w):\n",
        "        return torch.square(w).sum()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def NormalizeData(data):\n",
        "    return (data - np.min(data)) / (np.max(data) - np.min(data))"
      ],
      "metadata": {
        "id": "C-NfmcMjFw5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def notNaN(num):\n",
        "    return num == num"
      ],
      "metadata": {
        "id": "LSV3HOHowSeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JS2Nt8gZY4v"
      },
      "outputs": [],
      "source": [
        "def intersection(lst1, lst2):\n",
        "    return list(set(lst1) & set(lst2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikaQZE05iJQj"
      },
      "outputs": [],
      "source": [
        "# implementation of a single training epoch\n",
        "def train_epoch_cross(net, loader, loss_fn, optimizer, scheduler):\n",
        "\n",
        "    # set the network in training mode\n",
        "    net.train()\n",
        "\n",
        "    # keep track of the loss\n",
        "    loss_cum = 0\n",
        "    cnt = 0\n",
        "    num_correct = 0\n",
        "    targets = []\n",
        "    predictions = []\n",
        "\n",
        "    for i, data in enumerate(loader):\n",
        "\n",
        "        # sample data\n",
        "        x, y = data\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        # set all gradients equal to zero\n",
        "        net.zero_grad()\n",
        "\n",
        "        # feed the batch to the network and compute the outputs\n",
        "        y_pred = net(x)\n",
        "        #y_pred_sq = np.squeeze(y_pred) # add when using loss_fn: BCEloss()\n",
        "\n",
        "        pred = torch.round(y_pred.squeeze())  # rounds to the nearest integer\n",
        "\n",
        "        # compare predictions to true label\n",
        "        #correct_tensor = pred.eq(y.float().view_as(pred))\n",
        "        #correct = np.squeeze(correct_tensor.cpu().numpy())\n",
        "        #num_correct += np.sum(correct)\n",
        "        targets.extend(y.cpu().detach().numpy().tolist())\n",
        "        predictions.extend(torch.sigmoid(y_pred).cpu().detach().numpy().tolist())\n",
        "\n",
        "        #predictions_round = [round(p) for p in predictions]\n",
        "        #correct_tensor = predictions_round.eq(targets.float().view_as(predictions_round))\n",
        "\n",
        "        #loss = loss_fn(y_pred_sq, y.float())  #add when using loss_fn: BCEloss()\n",
        "        loss = loss_fn(y_pred, y.float())\n",
        "\n",
        "        # Specify L1 and L2 weights\n",
        "        l1_weight = 0\n",
        "        l2_weight = 0\n",
        "\n",
        "        # Compute L1 and L2 loss component\n",
        "        parameters = []\n",
        "        for parameter in net.parameters():\n",
        "            parameters.append(parameter.view(-1))\n",
        "        l1 = l1_weight * net.compute_l1_loss(torch.cat(parameters))\n",
        "        l2 = l2_weight * net.compute_l2_loss(torch.cat(parameters))\n",
        "\n",
        "        # Add L1 and L2 loss components\n",
        "        loss += l1\n",
        "        loss += l2\n",
        "\n",
        "        loss_cum += loss.data.cpu().numpy()\n",
        "        cnt += 1\n",
        "\n",
        "        # backpropagate the gradients w.r.t. computed loss\n",
        "        loss.backward()\n",
        "\n",
        "        # apply one step in the optimization\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        #break #for training one batch\n",
        "\n",
        "    # compute the average loss\n",
        "    #mytrain_acc = num_correct\n",
        "    loss_avg = loss_cum / cnt\n",
        "\n",
        "    #predictions = np.array(predictions) >= 0.5\n",
        "    predictions = [1 if p[0] > 0.5 else 0 for p in predictions]\n",
        "    mytrain_acc  = metrics.accuracy_score(targets, predictions)   *100\n",
        "    #mytrain_acc = (num_correct/ (len(y)*cnt)) *100\n",
        "    return loss_avg, mytrain_acc\n",
        "\n",
        "def loss_fn(outputs, targets):\n",
        "  return nn.BCEWithLogitsLoss()(outputs, targets.view(-1, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LymEfthBiFQI"
      },
      "outputs": [],
      "source": [
        "# implementation of a single testing epoch\n",
        "def test_epoch(net, loader, loss_fn):\n",
        "\n",
        "    # set the network in evaluation mode\n",
        "    net.eval()\n",
        "\n",
        "    # keep track of the loss\n",
        "    loss_cum = 0\n",
        "    cnt = 0\n",
        "    num_correct_val = 0\n",
        "    targets = []\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "      for i, data in enumerate(loader):\n",
        "\n",
        "          x, y = data\n",
        "          x = x.to(device)\n",
        "          y = y.to(device)\n",
        "\n",
        "          # feed the batch to the network and compute the outputs\n",
        "          y_pred = net(x.float())\n",
        "          #y_pred_sq = np.squeeze(y_pred) #add when using loss_fn: BCEloss()\n",
        "          pred = torch.round(y_pred.squeeze())  # rounds to the nearest integer\n",
        "\n",
        "          # compare predictions to true label\n",
        "          #correct_tensor = pred.eq(y.float().view_as(pred))\n",
        "          #correct = np.squeeze(correct_tensor.cpu().numpy())\n",
        "\n",
        "          targets.extend(y.cpu().detach().numpy().tolist())\n",
        "          predictions.extend(torch.sigmoid(y_pred).cpu().detach().numpy().tolist())\n",
        "\n",
        "          #num_correct_val += np.sum(correct)\n",
        "          # compare the outputs to the labels with the loss function\n",
        "          #loss = loss_fn(y_pred_sq, y.float())  #ad|d when using loss_fn: BCEloss()\n",
        "          loss = loss_fn(y_pred, y.float())\n",
        "\n",
        "          # Specify L1 and L2 weights\n",
        "          l1_weight = 0\n",
        "          l2_weight = 0\n",
        "\n",
        "          # Compute L1 and L2 loss component\n",
        "          parameters = []\n",
        "          for parameter in net.parameters():\n",
        "              parameters.append(parameter.view(-1))\n",
        "          l1 = l1_weight * net.compute_l1_loss(torch.cat(parameters))\n",
        "          l2 = l2_weight * net.compute_l2_loss(torch.cat(parameters))\n",
        "\n",
        "          # Add L1 and L2 loss components\n",
        "          loss += l1\n",
        "          loss += l2\n",
        "\n",
        "          loss_cum += loss.data.cpu().numpy()\n",
        "          cnt += 1\n",
        "\n",
        "    # compute the average loss\n",
        "    loss_avg = loss_cum / cnt\n",
        "    predictions = np.array(predictions) >= 0.5\n",
        "    mytest_acc  = (metrics.accuracy_score(targets, predictions)) *100\n",
        "    total = cnt *len(y)\n",
        "\n",
        "    return loss_avg, mytest_acc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_net_cross(net, train_loader, val_loader, loss_fn, optimizer, epochs , scheduler):\n",
        "\n",
        "    # transfer the network to the GPU\n",
        "    net = net.to(device)\n",
        "\n",
        "    train_loss = np.zeros((epochs))\n",
        "    test_loss = np.zeros((epochs))\n",
        "    train_acc = np.zeros((epochs))\n",
        "    train_acc_alt = np.zeros((epochs))\n",
        "\n",
        "    test_acc = np.zeros((epochs))\n",
        "    test_acc_alt = np.zeros((epochs))\n",
        "\n",
        "    print(\"Begin training.\")\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "\n",
        "        # training\n",
        "        train_loss[epoch], train_acc[epoch] = train_epoch_cross(net, train_loader, loss_fn, optimizer, scheduler)\n",
        "        # validation\n",
        "        test_loss[epoch], test_acc[epoch] = test_epoch(net, val_loader, loss_fn)\n",
        "\n",
        "        print('Epoch %5d - Train loss: %.6f - Train accuracy: %.6f - Test loss: %.6f - Test accuracy: %.6f'\n",
        "             % (epoch, train_loss[epoch], train_acc[epoch], test_loss[epoch], test_acc[epoch]))\n",
        "\n",
        "        #print('Epoch %5d - Train loss: %.6f - Train accuracy: %.6f'\n",
        "        #    % (epoch, train_loss[epoch], train_acc[epoch]))# for training one batch\n",
        "\n",
        "    return (train_loss, test_loss), (train_acc , test_acc)\n",
        "    #return train_loss, train_acc # for training one batch"
      ],
      "metadata": {
        "id": "mBxGCSGnZH8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYnulWBrjZsv"
      },
      "outputs": [],
      "source": [
        "def dataset_with_indices(cls):\n",
        "    \"\"\"\n",
        "    Modifies the given Dataset class to return a tuple data, target, index\n",
        "    instead of just data, target.\n",
        "    \"\"\"\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        data, target = cls.__getitem__(self, index)\n",
        "        return data, target, index\n",
        "\n",
        "    return type(cls.__name__, (cls,), {\n",
        "        '__getitem__': __getitem__,\n",
        "    })\n",
        "\n",
        "DWithInd = dataset_with_indices(torch.utils.data.TensorDataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7bxA5TKndA9"
      },
      "outputs": [],
      "source": [
        "def Average(lst):\n",
        "  return sum(lst) /len(lst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Geipw0E6bE7"
      },
      "outputs": [],
      "source": [
        "def get_class_distribution_binary(obj):\n",
        "    count_dict = {\n",
        "        'Neutral': 0,\n",
        "        'Deleterious': 0,\n",
        "    }\n",
        "\n",
        "    for i in obj:\n",
        "        if i == 0:\n",
        "            count_dict['Neutral'] += 1\n",
        "        elif i == 1:\n",
        "            count_dict['Deleterious'] += 1\n",
        "\n",
        "        else:\n",
        "            print(\"Check classes.\")\n",
        "\n",
        "    return count_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rv_Imf1z8OCK"
      },
      "outputs": [],
      "source": [
        "def multi_acc(y_pred, y_test):\n",
        "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
        "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)\n",
        "\n",
        "    correct_pred = (y_pred_tags == y_test).float()\n",
        "    acc = correct_pred.sum() / len(correct_pred)\n",
        "\n",
        "    acc = torch.round(acc * 100)\n",
        "\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BGSa9O-4ned"
      },
      "outputs": [],
      "source": [
        "class ClassifierDataset(Dataset):\n",
        "\n",
        "    def __init__(self, X_data, y_data):\n",
        "        self.X_data = X_data\n",
        "        self.y_data = y_data\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data[index], self.y_data[index]\n",
        "\n",
        "    def __len__ (self):\n",
        "        return len(self.X_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2QoDsxhODDa"
      },
      "outputs": [],
      "source": [
        "def unique(list1):\n",
        "\n",
        "    # initialize a null list\n",
        "    unique_list = []\n",
        "\n",
        "    # traverse for all elements\n",
        "    for x in list1:\n",
        "        # check if exists in unique_list or not\n",
        "        if x not in unique_list:\n",
        "            unique_list.append(x)\n",
        "\n",
        "    print(f'{len(unique_list)} unique transcripts')\n",
        "    return unique_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfQgl-GRcuKT"
      },
      "outputs": [],
      "source": [
        "def init_weights(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        #nn.init.normal_(m.weight, std=0.01)\n",
        "        nn.init.xavier_normal_(m.weight)\n",
        "\n",
        "    if type(m) == nn.LSTM:\n",
        "      for param in m._flat_weights_names:\n",
        "          if \"weight\" in param:\n",
        "              nn.init.xavier_uniform_(m._parameters[param])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import training set"
      ],
      "metadata": {
        "id": "r3msa3y3Yxpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import difference for each mutation + labels\n",
        "# File found in Datasets found in Zenodo repository\n",
        "dif_mut = pd.read_csv('log_probWT_MUT_Tier1_2_3_common_balanced+-2_2200AA_57maxpool.csv', header = None, names = ['mutation', 'log_difference', 'label'])\n",
        "\n",
        "# log_difference has been saved as string of list! Here I convert it back to list of floats\n",
        "fl_dif = []\n",
        "for x in dif_mut['log_difference']:\n",
        "  p = x[1:-1].split(',')\n",
        "  fl_dif.append([float(i) for i in p])\n",
        "\n",
        "dif_mut['fl_dif'] = fl_dif\n",
        "\n",
        "print('Deleterious mutations in dataset: ', len(dif_mut[dif_mut['label'] == 1]))\n",
        "print('Benign mutations in dataset: ', len(dif_mut[dif_mut['label'] == 0]))\n",
        "\n",
        "# pad to 2200 AA\n",
        "N= 2200\n",
        "fl_dif_pad =[]\n",
        "for i, mut in dif_mut.iterrows():\n",
        "  a = mut['fl_dif']\n",
        "  new_a = a + [0] * (N - len(a))\n",
        "  fl_dif_pad.append(new_a)\n",
        "dif_mut['fl_dif_pad'] = fl_dif_pad\n",
        "\n",
        "#dif_mut_shuffled = dif_mut.sample(frac=1)\n",
        "dif_mut_shuffled = dif_mut\n",
        "stacked_flat =[]\n",
        "for i, mut in dif_mut_shuffled.iterrows():\n",
        "  stacked_flat.append(torch.tensor(mut['fl_dif_pad']))\n",
        "\n",
        "stacked_gmm = torch.stack(stacked_flat)\n",
        "print(stacked_gmm.shape)"
      ],
      "metadata": {
        "id": "iC-IjQ-DYpCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvEHznl050zP"
      },
      "source": [
        "# with validation to find early stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twM3ebYU50zQ"
      },
      "outputs": [],
      "source": [
        "temp = dif_mut_shuffled.mutation.str.split(pat='_',expand=True)\n",
        "# seperate inputs and outputs\n",
        "X = stacked_gmm\n",
        "y = dif_mut_shuffled['label']\n",
        "\n",
        "# Split, shuffle and stratify sequences, mutations, proteins and label\n",
        "#X_train, X_test, y_train, y_test, mu_all_train, mu_all_test , prot_all_train, prot_all_test = train_test_split(X, y, temp[1],  temp[0], test_size=0.1, stratify=y, random_state=69)\n",
        "X_train, X_test, y_train, y_test, mu_all_train, mu_all_test , prot_all_train, prot_all_test = train_test_split(X, y, temp[1],  temp[0], test_size=0.0002, stratify=y, random_state=69) #balance_ccommo\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "X_test, y_test = np.array(X_test), np.array(y_test)\n",
        "\n",
        "#del stacked_gmm, X\n",
        "gc.collect()\n",
        "\n",
        "train_dataset = ClassifierDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long())\n",
        "val_dataset = ClassifierDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test).long())\n",
        "\n",
        "#fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(25,7))# Train\n",
        "#sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution_binary(y_train)]).melt(), x = \"variable\", y=\"value\", hue=\"variable\",  ax=axes[0]).set_title('Class Distribution in Train Set')# Validation\n",
        "#sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution_binary(y_test)]).melt(), x = \"variable\", y=\"value\", hue=\"variable\",  ax=axes[1]).set_title('Class Distribution in Val Set')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nN0ZRrbq50zR"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE=64\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, drop_last=True)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=2, drop_last=True)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Set fixed random number seed\n",
        "torch.manual_seed(42)\n",
        "TRAIN_BATCH_SIZE = 64\n",
        "epochs =200\n",
        "lr = 3e-5\n",
        "#h = 1024\n",
        "#h = 2048\n",
        "h = 4096\n",
        "#h= 8192\n",
        "#hidden2 =258\n",
        "#hidden2=1024\n",
        "hidden2=2048\n",
        "#hidden2=4096\n",
        "\n",
        "my_net = Classifier2L(h, hidden2, 0.3).to(device)\n",
        "#my_net = Classifier(h, 0.3).to(device)\n",
        "my_net.apply(init_weights)\n",
        "param_optimizer = list(my_net.named_parameters())\n",
        "no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "optimizer_parameters = [\n",
        "    {\n",
        "        \"params\": [\n",
        "            p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
        "        ],\n",
        "        \"weight_decay\": 0.001,\n",
        "    },\n",
        "    {\n",
        "        \"params\": [\n",
        "            p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
        "        ],\n",
        "        \"weight_decay\": 0.02,\n",
        "    },\n",
        "]\n",
        "\n",
        "num_train_steps = int(len(X_train) / TRAIN_BATCH_SIZE * epochs)\n",
        "optimizer = torch.optim.AdamW(optimizer_parameters, lr=lr)\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer, num_warmup_steps=1000, num_training_steps=num_train_steps\n",
        ")\n",
        "#loss_fn = nn.BCELoss()\n",
        "\n",
        "loss, acc = train_net_cross(my_net, train_loader, val_loader, loss_fn, optimizer, epochs, scheduler)\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
        "sns.set()\n",
        "# plot train/validation loss curves\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(loss[0])\n",
        "plt.plot(loss[1])\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title(f'Learning rate: {lr}, hidden : {h}')\n",
        "plt.legend(('Train', 'Validation'))\n",
        "#plt.title(f'Learning rate: {lr}, hidden : {h}, hidden2: {h2}')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(acc[0])\n",
        "plt.plot(acc[1])\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(('Train', 'Validation'))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RUN ONCE\n",
        "#torch.save(my_net.state_dict(), '/content/drive/MyDrive/my_colab/3rdYear/GMM/model')"
      ],
      "metadata": {
        "id": "DaRLBGLQzgVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__95gty4T3PW"
      },
      "source": [
        "# Cross-validation DRGN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import difference for each mutation + labels\n",
        "dif_mut = pd.read_csv('/content/drive/MyDrive/log_probWT_MUT_Tier1_2_3_common_balanced+-2_2200AA_57maxpool.csv', header = None, names = ['mutation', 'log_difference', 'label'])\n",
        "\n",
        "# exclude duplicates\n",
        "#dif_mut.drop_duplicates(subset = 'mutation', inplace =True)\n",
        "\n",
        "# log_difference has been saved as string of list! Here I convert it back to list of floats\n",
        "fl_dif = []\n",
        "for x in dif_mut['log_difference']:\n",
        "  p = x[1:-1].split(',')\n",
        "  fl_dif.append([float(i) for i in p])\n",
        "\n",
        "dif_mut['fl_dif'] = fl_dif\n",
        "\n",
        "print('Deleterious mutations in dataset: ', len(dif_mut[dif_mut['label'] == 1]))\n",
        "print('Benign mutations in dataset: ', len(dif_mut[dif_mut['label'] == 0]))\n",
        "\n",
        "\n",
        "# pad to 2200 AA\n",
        "N= 2200\n",
        "fl_dif_pad =[]\n",
        "for i, mut in dif_mut.iterrows():\n",
        "  a = mut['fl_dif']\n",
        "  new_a = a + [0] * (N - len(a))\n",
        "  fl_dif_pad.append(new_a)\n",
        "dif_mut['fl_dif_pad'] = fl_dif_pad\n",
        "dif_mut_shuffled = dif_mut.sample(frac=1)"
      ],
      "metadata": {
        "id": "F95WfO9KWY5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6hsvaZ2Rd-y"
      },
      "outputs": [],
      "source": [
        "dif_mut_drgn = pd.read_csv('/content/drive/MyDrive/log_probWT_MUT_DRGN_2200AA_57maxpool.csv', header = None, names = ['mutation', 'log_difference', 'label'])\n",
        "# exclude duplicates\n",
        "#dif_mut_drgn.drop_duplicates(subset = 'mutation', inplace =True)\n",
        "\n",
        "# log_difference has been saved as string of list! Here I convert it back to list of floats\n",
        "fl_dif = []\n",
        "for x in dif_mut_drgn['log_difference']:\n",
        "  p = x[1:-1].split(',')\n",
        "  fl_dif.append([float(i) for i in p])\n",
        "\n",
        "dif_mut_drgn['fl_dif'] = fl_dif\n",
        "\n",
        "print('Deleterious mutations in dataset: ', len(dif_mut_drgn[dif_mut_drgn['label'] == 1]))\n",
        "print('Benign mutations in dataset: ', len(dif_mut_drgn[dif_mut_drgn['label'] == 0]))\n",
        "\n",
        "# pad to 2200 AA\n",
        "N= 2200\n",
        "fl_dif_pad =[]\n",
        "for i, mut in dif_mut_drgn.iterrows():\n",
        "  a = mut['fl_dif']\n",
        "  new_a = a + [0] * (N - len(a))\n",
        "  fl_dif_pad.append(new_a)\n",
        "dif_mut_drgn['fl_dif_pad'] = fl_dif_pad\n",
        "\n",
        "stacked_flat_drgn =[]\n",
        "for i, mut in dif_mut_drgn.iterrows():\n",
        "  stacked_flat_drgn.append(torch.tensor(mut['fl_dif_pad']))\n",
        "\n",
        "dif_mut_drgn_shuffled = dif_mut_drgn.sample(frac=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLn06AuvUeJB"
      },
      "outputs": [],
      "source": [
        "# implementation of a single training epoch\n",
        "def train_epoch_cross(net, loader, loss_fn, optimizer, scheduler):\n",
        "\n",
        "    # set the network in training mode\n",
        "    net.train()\n",
        "\n",
        "    # keep track of the loss\n",
        "    loss_cum = 0\n",
        "    cnt = 0\n",
        "    num_correct = 0\n",
        "    targets = []\n",
        "    predictions = []\n",
        "\n",
        "    for i, data in enumerate(loader):\n",
        "\n",
        "        # sample data\n",
        "        x, y = data\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        # set all gradients equal to zero\n",
        "        net.zero_grad()\n",
        "\n",
        "        # feed the batch to the network and compute the outputs\n",
        "        y_pred = net(x)\n",
        "        #y_pred_sq = np.squeeze(y_pred) # add when using loss_fn: BCEloss()\n",
        "\n",
        "        pred = torch.round(y_pred.squeeze())  # rounds to the nearest integer\n",
        "\n",
        "        # compare predictions to true label\n",
        "        #correct_tensor = pred.eq(y.float().view_as(pred))\n",
        "        #correct = np.squeeze(correct_tensor.cpu().numpy())\n",
        "        #num_correct += np.sum(correct)\n",
        "        targets.extend(y.cpu().detach().numpy().tolist())\n",
        "        predictions.extend(torch.sigmoid(y_pred).cpu().detach().numpy().tolist())\n",
        "\n",
        "        #predictions_round = [round(p) for p in predictions]\n",
        "        #correct_tensor = predictions_round.eq(targets.float().view_as(predictions_round))\n",
        "\n",
        "        #loss = loss_fn(y_pred_sq, y.float())  #add when using loss_fn: BCEloss()\n",
        "        loss = loss_fn(y_pred, y.float())\n",
        "\n",
        "        # Specify L1 and L2 weights\n",
        "        l1_weight = 0\n",
        "        l2_weight = 0\n",
        "\n",
        "        # Compute L1 and L2 loss component\n",
        "        parameters = []\n",
        "        for parameter in net.parameters():\n",
        "            parameters.append(parameter.view(-1))\n",
        "        l1 = l1_weight * net.compute_l1_loss(torch.cat(parameters))\n",
        "        l2 = l2_weight * net.compute_l2_loss(torch.cat(parameters))\n",
        "\n",
        "        # Add L1 and L2 loss components\n",
        "        loss += l1\n",
        "        loss += l2\n",
        "\n",
        "        loss_cum += loss.data.cpu().numpy()\n",
        "        cnt += 1\n",
        "\n",
        "        # backpropagate the gradients w.r.t. computed loss\n",
        "        loss.backward()\n",
        "\n",
        "        # apply one step in the optimization\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        #break #for training one batch\n",
        "\n",
        "    # compute the average loss\n",
        "    #mytrain_acc = num_correct\n",
        "    loss_avg = loss_cum / cnt\n",
        "\n",
        "    #predictions = np.array(predictions) >= 0.5\n",
        "    predictions = [1 if p[0] > 0.5 else 0 for p in predictions]\n",
        "    mytrain_acc  = metrics.accuracy_score(targets, predictions)   *100\n",
        "    #mytrain_acc = (num_correct/ (len(y)*cnt)) *100\n",
        "    return loss_avg, mytrain_acc\n",
        "\n",
        "def loss_fn(outputs, targets):\n",
        "  return nn.BCEWithLogitsLoss()(outputs, targets.view(-1, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXkj-GQhUlxA"
      },
      "outputs": [],
      "source": [
        "def train_net_cross(net, train_loader, val_loader, loss_fn, optimizer, epochs , scheduler):\n",
        "\n",
        "    # transfer the network to the GPU\n",
        "    net = net.to(device)\n",
        "\n",
        "    train_loss = np.zeros((epochs))\n",
        "    test_loss = np.zeros((epochs))\n",
        "    train_acc = np.zeros((epochs))\n",
        "    train_acc_alt = np.zeros((epochs))\n",
        "\n",
        "    test_acc = np.zeros((epochs))\n",
        "    test_acc_alt = np.zeros((epochs))\n",
        "\n",
        "    print(\"Begin training.\")\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "\n",
        "        # training\n",
        "        train_loss[epoch], train_acc[epoch] = train_epoch_cross(net, train_loader, loss_fn, optimizer, scheduler)\n",
        "        #predictions, outputs = eval(net, train_loader)\n",
        "        #train_acc_alt[epoch] = metrics.accuracy_score(outputs, predictions)\n",
        "\n",
        "        # validation\n",
        "        test_loss[epoch], test_acc[epoch] = test_epoch(net, val_loader, loss_fn)\n",
        "        #predictions, outputs = eval(net, val_loader)\n",
        "        #test_acc_alt[epoch] = metrics.accuracy_score(outputs, predictions)\n",
        "\n",
        "        #print('Epoch %5d - Train loss: %.6f - Train accuracy: %.6f - Test loss: %.6f - Test accuracy: %.6f'\n",
        "        #     % (epoch, train_loss[epoch], train_acc[epoch], test_loss[epoch], test_acc[epoch]))\n",
        "\n",
        "        #print('Epoch %5d - Train loss: %.6f - Train accuracy: %.6f'\n",
        "        #    % (epoch, train_loss[epoch], train_acc[epoch]))# for training one batch\n",
        "\n",
        "    return (train_loss, test_loss), (train_acc , test_acc)\n",
        "    #return train_loss, train_acc # for training one batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVJrGC7mcTu7"
      },
      "outputs": [],
      "source": [
        "# Distribution of proteins in trianing / test se tof fold\n",
        "# Set fixed random number seed\n",
        "torch.manual_seed(42)\n",
        "TRAIN_BATCH_SIZE = 64\n",
        "epochs=200\n",
        "lr = [3e-5]\n",
        "#h = 1024\n",
        "#h = 2048\n",
        "h = 4096\n",
        "#hidden2 =258\n",
        "#hidden2=1024\n",
        "hidden2=2048\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "n_folds = 5\n",
        "\n",
        "accuracy, sensitivity, specificity, mcc, auc_dict = {}, {}, {}, {}, {}\n",
        "\n",
        "for fold in range(n_folds):\n",
        "  test = dif_mut_drgn_shuffled[fold*round(len(dif_mut_drgn_shuffled)/n_folds):(fold+1)*round(len(dif_mut_drgn_shuffled)/n_folds)]\n",
        "  temp = test.mutation.str.split(pat='_',expand=True)[0]\n",
        "\n",
        "\n",
        "  stacked_flat_drgn =[]\n",
        "  for i, mut in test.iterrows():\n",
        "    stacked_flat_drgn.append(torch.tensor(mut['fl_dif_pad']))\n",
        "\n",
        "  stacked_drgn = torch.stack(stacked_flat_drgn)\n",
        "  print(stacked_drgn.shape)\n",
        "\n",
        "  cond = dif_mut_shuffled['mutation'].isin(test['mutation'])\n",
        "  training = dif_mut_shuffled.drop(dif_mut_shuffled[cond].index, inplace = False)\n",
        "\n",
        "  #print('deleterious labels in Training for Fold ', fold, ': ', len(training[training['label']==1]))\n",
        "  #print('benign labels in Training for Fold ', fold, ': ',  len(training[training['label']==0]))\n",
        "\n",
        "  #print('deleterious labels in Test for Fold ', fold, ': ', len(test[test['label']==1]))\n",
        "  #print('benign labels in Test for Fold ', fold, ': ',  len(test[test['label']==0]))\n",
        "  #print('different genes in Fold ', fold, ': ',  len(temp.unique()))\n",
        "\n",
        "\n",
        "  # exclude test mutations from training data\n",
        "  stacked_flat =[]\n",
        "  for i, mut in training.iterrows():\n",
        "    stacked_flat.append(torch.tensor(mut['fl_dif_pad']))\n",
        "\n",
        "  stacked_gmm = torch.stack(stacked_flat)\n",
        "  print(stacked_gmm.shape)\n",
        "\n",
        "  training_temp = training.mutation.str.split(pat='_',expand=True)\n",
        "\n",
        "  # how many proteins co exist in training set / test set\n",
        "  prot_inters= intersection(training_temp[0].unique(), temp.unique())\n",
        "  print('Proteins in common between training set / test set: ', len(prot_inters))#, ': ', prot_inters)\n",
        "  '''\n",
        "  # how many deleterious / benign per protein are in training versus test set\n",
        "  for prot_int in prot_inters:\n",
        "    training_df = training[training['mutation'].str.contains(prot_int)]\n",
        "    del_training = len(training_df[training_df['label'] == 1])\n",
        "    ben_training = len(training_df[training_df['label'] == 0])\n",
        "\n",
        "    test_df =  test[test['mutation'].str.contains(prot_int)]\n",
        "    del_test = len(test_df[test_df['label'] == 1])\n",
        "    ben_test = len(test_df[test_df['label'] == 0])\n",
        "\n",
        "    # creating the dataset\n",
        "    data = {'Train del':del_training, 'Train ben':ben_training, 'Test del':del_test, 'Test ben':ben_test}\n",
        "    courses = list(data.keys())\n",
        "    values = list(data.values())\n",
        "\n",
        "    fig = plt.figure(figsize = (5, 3))\n",
        "\n",
        "    # creating the bar plot\n",
        "    plt.bar(courses, values, color ='maroon',\n",
        "            width = 0.4)\n",
        "\n",
        "    plt.xlabel(\"\")\n",
        "    plt.ylabel(\"No. of samples\")\n",
        "    plt.title(prot_int)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n",
        "\n",
        "  '''\n",
        "  # seperate inputs and outputs\n",
        "  X = stacked_gmm\n",
        "  y = training['label']\n",
        "\n",
        "  # Split, shuffle and stratify sequences, mutations, proteins and label\n",
        "  X_train, X_test, y_train, y_test, mu_all_train, mu_all_test , prot_all_train, prot_all_test = train_test_split(X, y, training_temp[1],  training_temp[0], test_size=0.0002, stratify=y, random_state=69)\n",
        "  X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "  X_test, y_test = np.array(X_test), np.array(y_test)\n",
        "\n",
        "  del stacked_gmm, X\n",
        "  gc.collect()\n",
        "\n",
        "  train_dataset = ClassifierDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long())\n",
        "  val_dataset = ClassifierDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test).long())\n",
        "\n",
        "  #fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(25,7))# Train\n",
        "  #sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution_binary(y_train)]).melt(), x = \"variable\", y=\"value\", hue=\"variable\",  ax=axes[0]).set_title('Class Distribution in Train Set')# Validation\n",
        "  #sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution_binary(y_test)]).melt(), x = \"variable\", y=\"value\", hue=\"variable\",  ax=axes[1]).set_title('Class Distribution in Val Set')\n",
        "\n",
        "  train_loader = DataLoader(dataset=train_dataset, batch_size=TRAIN_BATCH_SIZE, drop_last=True)\n",
        "  val_loader = DataLoader(dataset=val_dataset, batch_size=2, drop_last=True)\n",
        "\n",
        "  my_net = Classifier2L(h, hidden2, 0.3).to(device)\n",
        "  #my_net = my_net = Classifier(h, 0.3).to(device)\n",
        "  my_net.apply(init_weights)\n",
        "  param_optimizer = list(my_net.named_parameters())\n",
        "  no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "  optimizer_parameters = [\n",
        "      {\n",
        "          \"params\": [\n",
        "              p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
        "          ],\n",
        "          \"weight_decay\": 0.001,\n",
        "      },\n",
        "      {\n",
        "          \"params\": [\n",
        "              p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
        "          ],\n",
        "          \"weight_decay\": 0.02,\n",
        "      },\n",
        "  ]\n",
        "\n",
        "  num_train_steps = int(len(X_train) / TRAIN_BATCH_SIZE * epochs)\n",
        "  optimizer = torch.optim.AdamW(optimizer_parameters, lr=3e-5)\n",
        "  scheduler = get_linear_schedule_with_warmup(\n",
        "      optimizer, num_warmup_steps=1000, num_training_steps=num_train_steps\n",
        "  )\n",
        "\n",
        "  loss, acc = train_net_cross(my_net, train_loader, val_loader, loss_fn, optimizer, epochs, scheduler )\n",
        "\n",
        "\n",
        "  labels_drgn = test['label'].tolist()\n",
        "  X_drgn, y_drgn = np.array(stacked_drgn), np.array(labels_drgn)\n",
        "\n",
        "  drgn_dataset = ClassifierDataset(torch.from_numpy(X_drgn).float(), torch.from_numpy(y_drgn).long())\n",
        "  drgn_loader = DataLoader(dataset=drgn_dataset, batch_size=1 , drop_last=True)\n",
        "\n",
        "  y_pred_list = []\n",
        "  predictions_drgn= []\n",
        "  my_net.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for X_batch, _ in drgn_loader:\n",
        "          X_batch = X_batch.to(device)\n",
        "          y_test_pred = my_net(X_batch)\n",
        "          #print(y_test_pred)\n",
        "          predictions_drgn.extend(torch.sigmoid(y_test_pred).cpu().detach().numpy().tolist())\n",
        "          #print(predictions_drgn)\n",
        "\n",
        "  flat_list = []\n",
        "  for sublist in predictions_drgn:\n",
        "      for item in sublist:\n",
        "          flat_list.append(item)\n",
        "\n",
        "  predictions_drgn = [1 if i>=0.5 else 0 for i in flat_list]\n",
        "  confusion_matrix_df = pd.DataFrame(confusion_matrix(y_drgn, predictions_drgn))\n",
        "  tn, fp, fn, tp = confusion_matrix(y_drgn, predictions_drgn).ravel()\n",
        "  print(classification_report(y_drgn, predictions_drgn))\n",
        "  print(tp, tn, fp, fn)\n",
        "  TPR =tp / (tp + fn)\n",
        "  print('Sensitivity: %.2f'  % (TPR*100))\n",
        "\n",
        "  TNR = tn / (tn + fp)\n",
        "  print('Specificity: %.2f'  % (TNR*100))\n",
        "  print(matthews_corrcoef(y_drgn, predictions_drgn))\n",
        "\n",
        "  lw = 2\n",
        "  import matplotlib\n",
        "  matplotlib.rc_file_defaults()\n",
        "  fpr, tpr, _ = metrics.roc_curve(y_drgn[:len(predictions_drgn)],  flat_list)\n",
        "  auc = metrics.roc_auc_score(y_drgn[:len(predictions_drgn)], flat_list)\n",
        "  plt.plot(fpr,tpr,color=\"navy\",label=\"DRGN, auc=\"+str(round(auc, 3)))\n",
        "  plt.plot([0, 1], [0, 1], color=\"darkorange\", lw=lw, linestyle=\"--\")\n",
        "  plt.legend(loc=4)\n",
        "  plt.xlabel(\"False Positive Rate\")\n",
        "  plt.ylabel(\"True Positive Rate\")\n",
        "  plt.title(\"Receiver operating characteristic DRGN set\")\n",
        "  plt.rcParams[\"figure.figsize\"] = (10,10)\n",
        "  plt.show()\n",
        "\n",
        "  accuracy[fold]=((tp+tn)/(tp +tn+ fp+ fn))*100\n",
        "  sensitivity[fold]=TPR*100\n",
        "  specificity[fold]=TNR*100\n",
        "  mcc[fold]= matthews_corrcoef(y_drgn, predictions_drgn)*100\n",
        "  auc_dict[fold] =round(auc, 3)*100\n",
        "\n",
        "  # find the accuracy per protein\n",
        "  test['Groundtruth'] = y_drgn\n",
        "  test['prediction'] = predictions_drgn\n",
        "\n",
        "  training_df = pd.DataFrame(list(zip(prot_all_train.tolist(), y_train.tolist())),\n",
        "               columns =['uniprot', 'label'])\n",
        "  for prot_int in prot_inters:\n",
        "\n",
        "    print('----------')\n",
        "\n",
        "    df = training_df[training_df['uniprot']==prot_int]\n",
        "    del_training = len(df[df['label'] == 1])\n",
        "    ben_training = len(df[df['label'] == 0])\n",
        "    print(f'Protein {prot_int} has {del_training} deleterious and {ben_training} benign samples in training set of {fold} Fold ')\n",
        "    test_accu = test[test['mutation'].str.contains(prot_int)]\n",
        "    del_test_accu = len(test_accu[test_accu['label'] == 1])\n",
        "    ben_test_accu = len(test_accu[test_accu['label'] == 0])\n",
        "    print(f'Protein {prot_int} has {del_test_accu} deleterious and {ben_test_accu} benign samples in test set of {fold} Fold ')\n",
        "\n",
        "    print('Samples for Protein: ', len(test_accu))\n",
        "    #print(classification_report(test_accu['Groundtruth'], test_accu['prediction']))\n",
        "    precision, recall, fscore, support = precision_recall_fscore_support(test_accu['Groundtruth'], test_accu['prediction'], average='micro')#, pos_label=1)\n",
        "    print('Precision: {}'.format(precision))\n",
        "    print('Recall: {}'.format(recall))\n",
        "    print('F-measure: {}'.format(fscore))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds=[accuracy,  sensitivity,  specificity,  mcc, auc_dict]\n",
        "test = pd.DataFrame(columns = ['metric', 'fold', 'value'])\n",
        "fold_list, value_list = [],[]\n",
        "for i, m in enumerate(ds):\n",
        "  for key, value in m.items():\n",
        "    fold_list.append(key)\n",
        "    value_list.append(value)\n",
        "\n",
        "test['metric'] = ['accuracy']* len(accuracy) + ['sensitivity']* len(accuracy)+  ['specificity']* len(accuracy)+  ['mcc']* len(accuracy)+ ['AUC']* len(accuracy)\n",
        "test['fold'] = fold_list\n",
        "test['value'] = value_list\n",
        "\n",
        "fig = px.violin(test, y=\"metric\", x=\"value\", color=\"metric\", box=True, points=\"all\", width=800, height=400, title=\"10 folds\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "Gdcxp58KlRy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(style=\"darkgrid\")\n",
        "sns.violinplot(data=test, x=\"value\", y=\"metric\", palette=\"Blues\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kOa7UeuSlVRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of proteins in trianing / test se tof fold\n",
        "# Set fixed random number seed\n",
        "torch.manual_seed(42)\n",
        "TRAIN_BATCH_SIZE = 64\n",
        "epochs=200\n",
        "lr = [3e-5]\n",
        "#h = 1024\n",
        "#h = 2048\n",
        "h = 4096\n",
        "#hidden2 =258\n",
        "#hidden2=1024\n",
        "hidden2=2048\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "n_folds = 10\n",
        "\n",
        "accuracy, sensitivity, specificity, mcc, auc_dict = {}, {}, {}, {}, {}\n",
        "\n",
        "for fold in range(n_folds):\n",
        "  test = dif_mut_drgn_shuffled[fold*round(len(dif_mut_drgn_shuffled)/n_folds):(fold+1)*round(len(dif_mut_drgn_shuffled)/n_folds)]\n",
        "  temp = test.mutation.str.split(pat='_',expand=True)[0]\n",
        "\n",
        "\n",
        "  stacked_flat_drgn =[]\n",
        "  for i, mut in test.iterrows():\n",
        "    stacked_flat_drgn.append(torch.tensor(mut['fl_dif_pad']))\n",
        "\n",
        "  stacked_drgn = torch.stack(stacked_flat_drgn)\n",
        "  print(stacked_drgn.shape)\n",
        "\n",
        "  cond = dif_mut_shuffled['mutation'].isin(test['mutation'])\n",
        "  training = dif_mut_shuffled.drop(dif_mut_shuffled[cond].index, inplace = False)\n",
        "\n",
        "  #print('deleterious labels in Training for Fold ', fold, ': ', len(training[training['label']==1]))\n",
        "  #print('benign labels in Training for Fold ', fold, ': ',  len(training[training['label']==0]))\n",
        "\n",
        "  #print('deleterious labels in Test for Fold ', fold, ': ', len(test[test['label']==1]))\n",
        "  #print('benign labels in Test for Fold ', fold, ': ',  len(test[test['label']==0]))\n",
        "  #print('different genes in Fold ', fold, ': ',  len(temp.unique()))\n",
        "\n",
        "\n",
        "  # exclude test mutations from training data\n",
        "  stacked_flat =[]\n",
        "  for i, mut in training.iterrows():\n",
        "    stacked_flat.append(torch.tensor(mut['fl_dif_pad']))\n",
        "\n",
        "  stacked_gmm = torch.stack(stacked_flat)\n",
        "  print(stacked_gmm.shape)\n",
        "\n",
        "  training_temp = training.mutation.str.split(pat='_',expand=True)\n",
        "\n",
        "  # how many proteins co exist in training set / test set\n",
        "  prot_inters= intersection(training_temp[0].unique(), temp.unique())\n",
        "  print('Proteins in common between training set / test set: ', len(prot_inters))#, ': ', prot_inters)\n",
        "  '''\n",
        "  # how many deleterious / benign per protein are in training versus test set\n",
        "  for prot_int in prot_inters:\n",
        "    training_df = training[training['mutation'].str.contains(prot_int)]\n",
        "    del_training = len(training_df[training_df['label'] == 1])\n",
        "    ben_training = len(training_df[training_df['label'] == 0])\n",
        "\n",
        "    test_df =  test[test['mutation'].str.contains(prot_int)]\n",
        "    del_test = len(test_df[test_df['label'] == 1])\n",
        "    ben_test = len(test_df[test_df['label'] == 0])\n",
        "\n",
        "    # creating the dataset\n",
        "    data = {'Train del':del_training, 'Train ben':ben_training, 'Test del':del_test, 'Test ben':ben_test}\n",
        "    courses = list(data.keys())\n",
        "    values = list(data.values())\n",
        "\n",
        "    fig = plt.figure(figsize = (5, 3))\n",
        "\n",
        "    # creating the bar plot\n",
        "    plt.bar(courses, values, color ='maroon',\n",
        "            width = 0.4)\n",
        "\n",
        "    plt.xlabel(\"\")\n",
        "    plt.ylabel(\"No. of samples\")\n",
        "    plt.title(prot_int)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n",
        "\n",
        "  '''\n",
        "  # seperate inputs and outputs\n",
        "  X = stacked_gmm\n",
        "  y = training['label']\n",
        "\n",
        "  # Split, shuffle and stratify sequences, mutations, proteins and label\n",
        "  X_train, X_test, y_train, y_test, mu_all_train, mu_all_test , prot_all_train, prot_all_test = train_test_split(X, y, training_temp[1],  training_temp[0], test_size=0.0002, stratify=y, random_state=69)\n",
        "  X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "  X_test, y_test = np.array(X_test), np.array(y_test)\n",
        "\n",
        "  del stacked_gmm, X\n",
        "  gc.collect()\n",
        "\n",
        "  train_dataset = ClassifierDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long())\n",
        "  val_dataset = ClassifierDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test).long())\n",
        "\n",
        "  #fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(25,7))# Train\n",
        "  #sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution_binary(y_train)]).melt(), x = \"variable\", y=\"value\", hue=\"variable\",  ax=axes[0]).set_title('Class Distribution in Train Set')# Validation\n",
        "  #sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution_binary(y_test)]).melt(), x = \"variable\", y=\"value\", hue=\"variable\",  ax=axes[1]).set_title('Class Distribution in Val Set')\n",
        "\n",
        "  train_loader = DataLoader(dataset=train_dataset, batch_size=TRAIN_BATCH_SIZE, drop_last=True)\n",
        "  val_loader = DataLoader(dataset=val_dataset, batch_size=2, drop_last=True)\n",
        "\n",
        "  my_net = Classifier2L(h, hidden2, 0.3).to(device)\n",
        "  #my_net = my_net = Classifier(h, 0.3).to(device)\n",
        "  my_net.apply(init_weights)\n",
        "  param_optimizer = list(my_net.named_parameters())\n",
        "  no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "  optimizer_parameters = [\n",
        "      {\n",
        "          \"params\": [\n",
        "              p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
        "          ],\n",
        "          \"weight_decay\": 0.001,\n",
        "      },\n",
        "      {\n",
        "          \"params\": [\n",
        "              p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
        "          ],\n",
        "          \"weight_decay\": 0.02,\n",
        "      },\n",
        "  ]\n",
        "\n",
        "  num_train_steps = int(len(X_train) / TRAIN_BATCH_SIZE * epochs)\n",
        "  optimizer = torch.optim.AdamW(optimizer_parameters, lr=3e-5)\n",
        "  scheduler = get_linear_schedule_with_warmup(\n",
        "      optimizer, num_warmup_steps=1000, num_training_steps=num_train_steps\n",
        "  )\n",
        "\n",
        "  loss, acc = train_net_cross(my_net, train_loader, val_loader, loss_fn, optimizer, epochs, scheduler )\n",
        "\n",
        "\n",
        "  labels_drgn = test['label'].tolist()\n",
        "  X_drgn, y_drgn = np.array(stacked_drgn), np.array(labels_drgn)\n",
        "\n",
        "  drgn_dataset = ClassifierDataset(torch.from_numpy(X_drgn).float(), torch.from_numpy(y_drgn).long())\n",
        "  drgn_loader = DataLoader(dataset=drgn_dataset, batch_size=1 , drop_last=True)\n",
        "\n",
        "\n",
        "  y_pred_list = []\n",
        "  predictions_drgn= []\n",
        "  my_net.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for X_batch, _ in drgn_loader:\n",
        "          X_batch = X_batch.to(device)\n",
        "          y_test_pred = my_net(X_batch)\n",
        "          #print(y_test_pred)\n",
        "          predictions_drgn.extend(torch.sigmoid(y_test_pred).cpu().detach().numpy().tolist())\n",
        "          #print(predictions_drgn)\n",
        "\n",
        "  flat_list = []\n",
        "  for sublist in predictions_drgn:\n",
        "      for item in sublist:\n",
        "          flat_list.append(item)\n",
        "\n",
        "  predictions_drgn = [1 if i>=0.5 else 0 for i in flat_list]\n",
        "  confusion_matrix_df = pd.DataFrame(confusion_matrix(y_drgn, predictions_drgn))\n",
        "  tn, fp, fn, tp = confusion_matrix(y_drgn, predictions_drgn).ravel()\n",
        "  print(classification_report(y_drgn, predictions_drgn))\n",
        "  print(tp, tn, fp, fn)\n",
        "  TPR =tp / (tp + fn)\n",
        "  print('Sensitivity: %.2f'  % (TPR*100))\n",
        "\n",
        "  TNR = tn / (tn + fp)\n",
        "  print('Specificity: %.2f'  % (TNR*100))\n",
        "  print(matthews_corrcoef(y_drgn, predictions_drgn))\n",
        "\n",
        "  lw = 2\n",
        "  import matplotlib\n",
        "  matplotlib.rc_file_defaults()\n",
        "  fpr, tpr, _ = metrics.roc_curve(y_drgn[:len(predictions_drgn)],  flat_list)\n",
        "  auc = metrics.roc_auc_score(y_drgn[:len(predictions_drgn)], flat_list)\n",
        "  plt.plot(fpr,tpr,color=\"navy\",label=\"DRGN, auc=\"+str(round(auc, 3)))\n",
        "  plt.plot([0, 1], [0, 1], color=\"darkorange\", lw=lw, linestyle=\"--\")\n",
        "  plt.legend(loc=4)\n",
        "  plt.xlabel(\"False Positive Rate\")\n",
        "  plt.ylabel(\"True Positive Rate\")\n",
        "  plt.title(\"Receiver operating characteristic DRGN set\")\n",
        "  plt.rcParams[\"figure.figsize\"] = (10,10)\n",
        "  plt.show()\n",
        "\n",
        "  accuracy[fold]=((tp+tn)/(tp +tn+ fp+ fn))*100\n",
        "  sensitivity[fold]=TPR*100\n",
        "  specificity[fold]=TNR*100\n",
        "  mcc[fold]= matthews_corrcoef(y_drgn, predictions_drgn)*100\n",
        "  auc_dict[fold] =round(auc, 3)*100\n",
        "\n",
        "  # find the accuracy per protein\n",
        "  test['Groundtruth'] = y_drgn\n",
        "  test['prediction'] = predictions_drgn\n",
        "\n",
        "  training_df = pd.DataFrame(list(zip(prot_all_train.tolist(), y_train.tolist())),\n",
        "               columns =['uniprot', 'label'])\n",
        "  for prot_int in prot_inters:\n",
        "\n",
        "    print('----------')\n",
        "\n",
        "    df = training_df[training_df['uniprot']==prot_int]\n",
        "    del_training = len(df[df['label'] == 1])\n",
        "    ben_training = len(df[df['label'] == 0])\n",
        "    print(f'Protein {prot_int} has {del_training} deleterious and {ben_training} benign samples in training set of {fold} Fold ')\n",
        "    test_accu = test[test['mutation'].str.contains(prot_int)]\n",
        "    del_test_accu = len(test_accu[test_accu['label'] == 1])\n",
        "    ben_test_accu = len(test_accu[test_accu['label'] == 0])\n",
        "    print(f'Protein {prot_int} has {del_test_accu} deleterious and {ben_test_accu} benign samples in test set of {fold} Fold ')\n",
        "\n",
        "    print('Samples for Protein: ', len(test_accu))\n",
        "    #print(classification_report(test_accu['Groundtruth'], test_accu['prediction']))\n",
        "    precision, recall, fscore, support = precision_recall_fscore_support(test_accu['Groundtruth'], test_accu['prediction'], average='micro')#, pos_label=1)\n",
        "    print('Precision: {}'.format(precision))\n",
        "    print('Recall: {}'.format(recall))\n",
        "    print('F-measure: {}'.format(fscore))"
      ],
      "metadata": {
        "id": "xbp8BWy7OBlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds=[accuracy,  sensitivity,  specificity,  mcc, auc_dict]\n",
        "test = pd.DataFrame(columns = ['metric', 'fold', 'value'])\n",
        "fold_list, value_list = [],[]\n",
        "for i, m in enumerate(ds):\n",
        "  for key, value in m.items():\n",
        "    fold_list.append(key)\n",
        "    value_list.append(value)\n",
        "\n",
        "test['metric'] = ['accuracy']* len(accuracy) + ['sensitivity']* len(accuracy)+  ['specificity']* len(accuracy)+  ['mcc']* len(accuracy)+ ['AUC']* len(accuracy)\n",
        "test['fold'] = fold_list\n",
        "test['value'] = value_list\n",
        "\n",
        "fig = px.violin(test, y=\"metric\", x=\"value\", color=\"metric\", box=True, points=\"all\", width=800, height=400, title=\"10 folds\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "-mtXs1WIkwwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(style=\"darkgrid\")\n",
        "sns.violinplot(data=test, x=\"value\", y=\"metric\", palette=\"Blues\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-vqwt1YMlyGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPlLsc-ZzNrG"
      },
      "outputs": [],
      "source": [
        "# Distribution of proteins in trianing / test se tof fold\n",
        "# Set fixed random number seed\n",
        "torch.manual_seed(42)\n",
        "TRAIN_BATCH_SIZE = 64\n",
        "epochs=200\n",
        "lr = [3e-5]\n",
        "#h = 1024\n",
        "#h = 2048\n",
        "h = 4096\n",
        "#hidden2 =258\n",
        "#hidden2=1024\n",
        "hidden2=2048\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "n_folds = 20\n",
        "\n",
        "accuracy, sensitivity, specificity, mcc, auc_dict = {}, {}, {}, {}, {}\n",
        "\n",
        "for fold in range(n_folds):\n",
        "  test = dif_mut_drgn_shuffled[fold*round(len(dif_mut_drgn_shuffled)/n_folds):(fold+1)*round(len(dif_mut_drgn_shuffled)/n_folds)]\n",
        "  temp = test.mutation.str.split(pat='_',expand=True)[0]\n",
        "\n",
        "\n",
        "  stacked_flat_drgn =[]\n",
        "  for i, mut in test.iterrows():\n",
        "    stacked_flat_drgn.append(torch.tensor(mut['fl_dif_pad']))\n",
        "\n",
        "  stacked_drgn = torch.stack(stacked_flat_drgn)\n",
        "  print(stacked_drgn.shape)\n",
        "\n",
        "  cond = dif_mut_shuffled['mutation'].isin(test['mutation'])\n",
        "  training = dif_mut_shuffled.drop(dif_mut_shuffled[cond].index, inplace = False)\n",
        "\n",
        "  #print('deleterious labels in Training for Fold ', fold, ': ', len(training[training['label']==1]))\n",
        "  #print('benign labels in Training for Fold ', fold, ': ',  len(training[training['label']==0]))\n",
        "\n",
        "  #print('deleterious labels in Test for Fold ', fold, ': ', len(test[test['label']==1]))\n",
        "  #print('benign labels in Test for Fold ', fold, ': ',  len(test[test['label']==0]))\n",
        "  #print('different genes in Fold ', fold, ': ',  len(temp.unique()))\n",
        "\n",
        "\n",
        "  # exclude test mutations from training data\n",
        "  stacked_flat =[]\n",
        "  for i, mut in training.iterrows():\n",
        "    stacked_flat.append(torch.tensor(mut['fl_dif_pad']))\n",
        "\n",
        "  stacked_gmm = torch.stack(stacked_flat)\n",
        "  print(stacked_gmm.shape)\n",
        "\n",
        "  training_temp = training.mutation.str.split(pat='_',expand=True)\n",
        "\n",
        "  # how many proteins co exist in training set / test set\n",
        "  prot_inters= intersection(training_temp[0].unique(), temp.unique())\n",
        "  print('Proteins in common between training set / test set: ', len(prot_inters))#, ': ', prot_inters)\n",
        "  '''\n",
        "  # how many deleterious / benign per protein are in training versus test set\n",
        "  for prot_int in prot_inters:\n",
        "    training_df = training[training['mutation'].str.contains(prot_int)]\n",
        "    del_training = len(training_df[training_df['label'] == 1])\n",
        "    ben_training = len(training_df[training_df['label'] == 0])\n",
        "\n",
        "    test_df =  test[test['mutation'].str.contains(prot_int)]\n",
        "    del_test = len(test_df[test_df['label'] == 1])\n",
        "    ben_test = len(test_df[test_df['label'] == 0])\n",
        "\n",
        "    # creating the dataset\n",
        "    data = {'Train del':del_training, 'Train ben':ben_training, 'Test del':del_test, 'Test ben':ben_test}\n",
        "    courses = list(data.keys())\n",
        "    values = list(data.values())\n",
        "\n",
        "    fig = plt.figure(figsize = (5, 3))\n",
        "\n",
        "    # creating the bar plot\n",
        "    plt.bar(courses, values, color ='maroon',\n",
        "            width = 0.4)\n",
        "\n",
        "    plt.xlabel(\"\")\n",
        "    plt.ylabel(\"No. of samples\")\n",
        "    plt.title(prot_int)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n",
        "\n",
        "  '''\n",
        "  # seperate inputs and outputs\n",
        "  X = stacked_gmm\n",
        "  y = training['label']\n",
        "\n",
        "  # Split, shuffle and stratify sequences, mutations, proteins and label\n",
        "  X_train, X_test, y_train, y_test, mu_all_train, mu_all_test , prot_all_train, prot_all_test = train_test_split(X, y, training_temp[1],  training_temp[0], test_size=0.0002, stratify=y, random_state=69)\n",
        "  X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "  X_test, y_test = np.array(X_test), np.array(y_test)\n",
        "\n",
        "  del stacked_gmm, X\n",
        "  gc.collect()\n",
        "\n",
        "  train_dataset = ClassifierDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long())\n",
        "  val_dataset = ClassifierDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test).long())\n",
        "\n",
        "  #fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(25,7))# Train\n",
        "  #sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution_binary(y_train)]).melt(), x = \"variable\", y=\"value\", hue=\"variable\",  ax=axes[0]).set_title('Class Distribution in Train Set')# Validation\n",
        "  #sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution_binary(y_test)]).melt(), x = \"variable\", y=\"value\", hue=\"variable\",  ax=axes[1]).set_title('Class Distribution in Val Set')\n",
        "\n",
        "  train_loader = DataLoader(dataset=train_dataset, batch_size=TRAIN_BATCH_SIZE, drop_last=True)\n",
        "  val_loader = DataLoader(dataset=val_dataset, batch_size=2, drop_last=True)\n",
        "\n",
        "  my_net = Classifier2L(h, hidden2, 0.3).to(device)\n",
        "  #my_net = my_net = Classifier(h, 0.3).to(device)\n",
        "  my_net.apply(init_weights)\n",
        "  param_optimizer = list(my_net.named_parameters())\n",
        "  no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "  optimizer_parameters = [\n",
        "      {\n",
        "          \"params\": [\n",
        "              p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
        "          ],\n",
        "          \"weight_decay\": 0.001,\n",
        "      },\n",
        "      {\n",
        "          \"params\": [\n",
        "              p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
        "          ],\n",
        "          \"weight_decay\": 0.02,\n",
        "      },\n",
        "  ]\n",
        "\n",
        "  num_train_steps = int(len(X_train) / TRAIN_BATCH_SIZE * epochs)\n",
        "  optimizer = torch.optim.AdamW(optimizer_parameters, lr=3e-5)\n",
        "  scheduler = get_linear_schedule_with_warmup(\n",
        "      optimizer, num_warmup_steps=1000, num_training_steps=num_train_steps\n",
        "  )\n",
        "\n",
        "  loss, acc = train_net_cross(my_net, train_loader, val_loader, loss_fn, optimizer, epochs, scheduler )\n",
        "\n",
        "\n",
        "  labels_drgn = test['label'].tolist()\n",
        "  X_drgn, y_drgn = np.array(stacked_drgn), np.array(labels_drgn)\n",
        "\n",
        "  drgn_dataset = ClassifierDataset(torch.from_numpy(X_drgn).float(), torch.from_numpy(y_drgn).long())\n",
        "  drgn_loader = DataLoader(dataset=drgn_dataset, batch_size=1 , drop_last=True)\n",
        "\n",
        "\n",
        "  y_pred_list = []\n",
        "  predictions_drgn= []\n",
        "  my_net.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for X_batch, _ in drgn_loader:\n",
        "          X_batch = X_batch.to(device)\n",
        "          y_test_pred = my_net(X_batch)\n",
        "          #print(y_test_pred)\n",
        "          predictions_drgn.extend(torch.sigmoid(y_test_pred).cpu().detach().numpy().tolist())\n",
        "          #print(predictions_drgn)\n",
        "\n",
        "  flat_list = []\n",
        "  for sublist in predictions_drgn:\n",
        "      for item in sublist:\n",
        "          flat_list.append(item)\n",
        "\n",
        "  predictions_drgn = [1 if i>=0.5 else 0 for i in flat_list]\n",
        "  confusion_matrix_df = pd.DataFrame(confusion_matrix(y_drgn, predictions_drgn))\n",
        "  tn, fp, fn, tp = confusion_matrix(y_drgn, predictions_drgn).ravel()\n",
        "  print(classification_report(y_drgn, predictions_drgn))\n",
        "  print(tp, tn, fp, fn)\n",
        "  TPR =tp / (tp + fn)\n",
        "  print('Sensitivity: %.2f'  % (TPR*100))\n",
        "\n",
        "  TNR = tn / (tn + fp)\n",
        "  print('Specificity: %.2f'  % (TNR*100))\n",
        "  print(matthews_corrcoef(y_drgn, predictions_drgn))\n",
        "\n",
        "  lw = 2\n",
        "  import matplotlib\n",
        "  matplotlib.rc_file_defaults()\n",
        "  fpr, tpr, _ = metrics.roc_curve(y_drgn[:len(predictions_drgn)],  flat_list)\n",
        "  auc = metrics.roc_auc_score(y_drgn[:len(predictions_drgn)], flat_list)\n",
        "  plt.plot(fpr,tpr,color=\"navy\",label=\"DRGN, auc=\"+str(round(auc, 3)))\n",
        "  plt.plot([0, 1], [0, 1], color=\"darkorange\", lw=lw, linestyle=\"--\")\n",
        "  plt.legend(loc=4)\n",
        "  plt.xlabel(\"False Positive Rate\")\n",
        "  plt.ylabel(\"True Positive Rate\")\n",
        "  plt.title(\"Receiver operating characteristic DRGN set\")\n",
        "  plt.rcParams[\"figure.figsize\"] = (10,10)\n",
        "  plt.show()\n",
        "\n",
        "  accuracy[fold]=((tp+tn)/(tp +tn+ fp+ fn))*100\n",
        "  sensitivity[fold]=TPR*100\n",
        "  specificity[fold]=TNR*100\n",
        "  mcc[fold]= matthews_corrcoef(y_drgn, predictions_drgn)*100\n",
        "  auc_dict[fold] =round(auc, 3)*100\n",
        "\n",
        "  # find the accuracy per protein\n",
        "  test['Groundtruth'] = y_drgn\n",
        "  test['prediction'] = predictions_drgn\n",
        "\n",
        "  training_df = pd.DataFrame(list(zip(prot_all_train.tolist(), y_train.tolist())),\n",
        "               columns =['uniprot', 'label'])\n",
        "  for prot_int in prot_inters:\n",
        "\n",
        "    print('----------')\n",
        "\n",
        "    df = training_df[training_df['uniprot']==prot_int]\n",
        "    del_training = len(df[df['label'] == 1])\n",
        "    ben_training = len(df[df['label'] == 0])\n",
        "    print(f'Protein {prot_int} has {del_training} deleterious and {ben_training} benign samples in training set of {fold} Fold ')\n",
        "    test_accu = test[test['mutation'].str.contains(prot_int)]\n",
        "    del_test_accu = len(test_accu[test_accu['label'] == 1])\n",
        "    ben_test_accu = len(test_accu[test_accu['label'] == 0])\n",
        "    print(f'Protein {prot_int} has {del_test_accu} deleterious and {ben_test_accu} benign samples in test set of {fold} Fold ')\n",
        "\n",
        "    print('Samples for Protein: ', len(test_accu))\n",
        "    #print(classification_report(test_accu['Groundtruth'], test_accu['prediction']))\n",
        "    precision, recall, fscore, support = precision_recall_fscore_support(test_accu['Groundtruth'], test_accu['prediction'], average='micro')#, pos_label=1)\n",
        "    print('Precision: {}'.format(precision))\n",
        "    print('Recall: {}'.format(recall))\n",
        "    print('F-measure: {}'.format(fscore))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds=[accuracy,  sensitivity,  specificity,  mcc, auc_dict]\n",
        "test = pd.DataFrame(columns = ['metric', 'fold', 'value'])\n",
        "fold_list, value_list = [],[]\n",
        "for i, m in enumerate(ds):\n",
        "  for key, value in m.items():\n",
        "    fold_list.append(key)\n",
        "    value_list.append(value)\n",
        "\n",
        "test['metric'] = ['accuracy']* len(accuracy) + ['sensitivity']* len(accuracy)+  ['specificity']* len(accuracy)+  ['mcc']* len(accuracy)+ ['AUC']* len(accuracy)\n",
        "test['fold'] = fold_list\n",
        "test['value'] = value_list\n",
        "\n",
        "fig = px.violin(test, y=\"metric\", x=\"value\", color=\"metric\", box=True, points=\"all\", width=800, height=400, title=\"20 folds\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "TIizdpOa9OIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(style=\"darkgrid\")\n",
        "sns.violinplot(data=test, x=\"value\", y=\"metric\", palette=\"Blues\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bFMX9cOk9Pq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzZwH64reMOA"
      },
      "source": [
        "# Cross-validation DRGN with results of all predictors"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# implementation of a single training epoch\n",
        "def train_epoch_cross(net, loader, loss_fn, optimizer, scheduler):\n",
        "\n",
        "    # set the network in training mode\n",
        "    net.train()\n",
        "\n",
        "    # keep track of the loss\n",
        "    loss_cum = 0\n",
        "    cnt = 0\n",
        "    num_correct = 0\n",
        "    targets = []\n",
        "    predictions = []\n",
        "\n",
        "    for i, data in enumerate(loader):\n",
        "\n",
        "        # sample data\n",
        "        x, y = data\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        # set all gradients equal to zero\n",
        "        net.zero_grad()\n",
        "\n",
        "        # feed the batch to the network and compute the outputs\n",
        "        y_pred = net(x)\n",
        "        #y_pred_sq = np.squeeze(y_pred) # add when using loss_fn: BCEloss()\n",
        "\n",
        "        pred = torch.round(y_pred.squeeze())  # rounds to the nearest integer\n",
        "\n",
        "        # compare predictions to true label\n",
        "        #correct_tensor = pred.eq(y.float().view_as(pred))\n",
        "        #correct = np.squeeze(correct_tensor.cpu().numpy())\n",
        "        #num_correct += np.sum(correct)\n",
        "        targets.extend(y.cpu().detach().numpy().tolist())\n",
        "        predictions.extend(torch.sigmoid(y_pred).cpu().detach().numpy().tolist())\n",
        "\n",
        "        #predictions_round = [round(p) for p in predictions]\n",
        "        #correct_tensor = predictions_round.eq(targets.float().view_as(predictions_round))\n",
        "\n",
        "        #loss = loss_fn(y_pred_sq, y.float())  #add when using loss_fn: BCEloss()\n",
        "        loss = loss_fn(y_pred, y.float())\n",
        "\n",
        "        # Specify L1 and L2 weights\n",
        "        l1_weight = 0\n",
        "        l2_weight = 0\n",
        "\n",
        "        # Compute L1 and L2 loss component\n",
        "        parameters = []\n",
        "        for parameter in net.parameters():\n",
        "            parameters.append(parameter.view(-1))\n",
        "        l1 = l1_weight * net.compute_l1_loss(torch.cat(parameters))\n",
        "        l2 = l2_weight * net.compute_l2_loss(torch.cat(parameters))\n",
        "\n",
        "        # Add L1 and L2 loss components\n",
        "        loss += l1\n",
        "        loss += l2\n",
        "\n",
        "        loss_cum += loss.data.cpu().numpy()\n",
        "        cnt += 1\n",
        "\n",
        "        # backpropagate the gradients w.r.t. computed loss\n",
        "        loss.backward()\n",
        "\n",
        "        # apply one step in the optimization\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        #break #for training one batch\n",
        "\n",
        "    # compute the average loss\n",
        "    #mytrain_acc = num_correct\n",
        "    loss_avg = loss_cum / cnt\n",
        "\n",
        "    #predictions = np.array(predictions) >= 0.5\n",
        "    predictions = [1 if p[0] > 0.5 else 0 for p in predictions]\n",
        "    mytrain_acc  = metrics.accuracy_score(targets, predictions)   *100\n",
        "    #mytrain_acc = (num_correct/ (len(y)*cnt)) *100\n",
        "    return loss_avg, mytrain_acc\n",
        "\n",
        "def loss_fn(outputs, targets):\n",
        "  return nn.BCEWithLogitsLoss()(outputs, targets.view(-1, 1))"
      ],
      "metadata": {
        "id": "VS-TmWqFwLpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_net_cross(net, train_loader, val_loader, loss_fn, optimizer, epochs , scheduler):\n",
        "\n",
        "    # transfer the network to the GPU\n",
        "    net = net.to(device)\n",
        "\n",
        "    train_loss = np.zeros((epochs))\n",
        "    test_loss = np.zeros((epochs))\n",
        "    train_acc = np.zeros((epochs))\n",
        "    train_acc_alt = np.zeros((epochs))\n",
        "\n",
        "    test_acc = np.zeros((epochs))\n",
        "    test_acc_alt = np.zeros((epochs))\n",
        "\n",
        "    print(\"Begin training.\")\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "\n",
        "        # training\n",
        "        train_loss[epoch], train_acc[epoch] = train_epoch_cross(net, train_loader, loss_fn, optimizer, scheduler)\n",
        "        #predictions, outputs = eval(net, train_loader)\n",
        "        #train_acc_alt[epoch] = metrics.accuracy_score(outputs, predictions)\n",
        "\n",
        "        # validation\n",
        "        test_loss[epoch], test_acc[epoch] = test_epoch(net, val_loader, loss_fn)\n",
        "        #predictions, outputs = eval(net, val_loader)\n",
        "        #test_acc_alt[epoch] = metrics.accuracy_score(outputs, predictions)\n",
        "\n",
        "        #print('Epoch %5d - Train loss: %.6f - Train accuracy: %.6f - Test loss: %.6f - Test accuracy: %.6f'\n",
        "        #     % (epoch, train_loss[epoch], train_acc[epoch], test_loss[epoch], test_acc[epoch]))\n",
        "\n",
        "        #print('Epoch %5d - Train loss: %.6f - Train accuracy: %.6f'\n",
        "        #    % (epoch, train_loss[epoch], train_acc[epoch]))# for training one batch\n",
        "\n",
        "    return (train_loss, test_loss), (train_acc , test_acc)\n",
        "    #return train_loss, train_acc # for training one batch"
      ],
      "metadata": {
        "id": "4zjkE37NwJiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train / test only ones with overlapping values for all predictors"
      ],
      "metadata": {
        "id": "tC62GA7wwhzk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import training data"
      ],
      "metadata": {
        "id": "wDmskXHbeeLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import difference for each mutation + labels\n",
        "dif_mut = pd.read_csv('/content/drive/MyDrive/log_probWT_MUT_Tier1_2_3_common_balanced+-2_2200AA_57maxpool.csv', header = None, names = ['mutation', 'log_difference', 'label'])\n",
        "\n",
        "# exclude duplicates\n",
        "#dif_mut.drop_duplicates(subset = 'mutation', inplace =True)\n",
        "\n",
        "# log_difference has been saved as string of list! Here I convert it back to list of floats\n",
        "fl_dif = []\n",
        "for x in dif_mut['log_difference']:\n",
        "  p = x[1:-1].split(',')\n",
        "  fl_dif.append([float(i) for i in p])\n",
        "\n",
        "dif_mut['fl_dif'] = fl_dif\n",
        "\n",
        "print('Deleterious mutations in dataset: ', len(dif_mut[dif_mut['label'] == 1]))\n",
        "print('Benign mutations in dataset: ', len(dif_mut[dif_mut['label'] == 0]))\n",
        "\n",
        "\n",
        "# pad to 2200 AA\n",
        "N= 2200\n",
        "fl_dif_pad =[]\n",
        "for i, mut in dif_mut.iterrows():\n",
        "  a = mut['fl_dif']\n",
        "  new_a = a + [0] * (N - len(a))\n",
        "  fl_dif_pad.append(new_a)\n",
        "dif_mut['fl_dif_pad'] = fl_dif_pad\n",
        "dif_mut_shuffled = dif_mut.sample(frac=1)"
      ],
      "metadata": {
        "id": "5afI0dwueMOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import results of all predictors for DRGN and save them in dictionary"
      ],
      "metadata": {
        "id": "Ed-wMvM_ejCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV file into a Pandas DataFrame\n",
        "df = pd.read_csv('/content/drive/MyDrive/my_colab/3rdYear/GMM/DRGN_mutations_012023_DEOGEN_etc.csv')\n",
        "# squeeze proteins and mutaitons in one column\n",
        "df['mutation'] = df['uniprot'] + '_' + df['AA_orig'] + df['position'].astype(str) + df['AA_targ']\n",
        "df = df.drop(columns=['label'])\n",
        "# Create a dictionary with the specified columns as key and values\n",
        "results_all = {}\n",
        "for key, val1, val2, val3, val4, val5 in zip(df['mutation'], df['DEOGEN2'], df['EVE'], df['FATHMM'], df['SIFT'], df['PolyPhen2']):\n",
        "    #if key in my_dict: # should be the case since I dont have duplicates\n",
        "    #    my_dict[key].append([val1, val2, val3, val4, val5])\n",
        "    #else:\n",
        "    results_all[key] = [val1, val2, val3, val4, val5]\n",
        "\n",
        "## keep only the values that have prediction for all predictors\n",
        "df = df[~df.isnull().any(axis=1)]"
      ],
      "metadata": {
        "id": "ocZQTRUqeoqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import testing data (DRGN) representations"
      ],
      "metadata": {
        "id": "Bfz5DvUregas"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zt4FpWcweMOB"
      },
      "outputs": [],
      "source": [
        "dif_mut_drgn = pd.read_csv('/content/drive/MyDrive/log_probWT_MUT_DRGN_2200AA_57maxpool.csv', header = None, names = ['mutation', 'log_difference', 'label'])\n",
        "# exclude duplicates\n",
        "#dif_mut_drgn.drop_duplicates(subset = 'mutation', inplace =True)\n",
        "\n",
        "dif_mut_drgn_nonan = pd.merge(df, dif_mut_drgn, how='inner', on=['mutation']) # Ti einai auto?? Giati den grafeis sxolia ????? Ok katalaba: Exairw ta DRGN samples pou den exw timi gia olous tous predictors\n",
        "print(len(dif_mut_drgn_nonan))\n",
        "\n",
        "# log_difference has been saved as string of list! Here I convert it back to list of floats\n",
        "fl_dif = []\n",
        "for x in dif_mut_drgn_nonan['log_difference']:\n",
        "  p = x[1:-1].split(',')\n",
        "  fl_dif.append([float(i) for i in p])\n",
        "\n",
        "dif_mut_drgn_nonan['fl_dif'] = fl_dif\n",
        "\n",
        "print('Deleterious mutations in dataset: ', len(dif_mut_drgn_nonan[dif_mut_drgn_nonan['label'] == 1]))\n",
        "print('Benign mutations in dataset: ', len(dif_mut_drgn_nonan[dif_mut_drgn_nonan['label'] == 0]))\n",
        "\n",
        "# pad to 2200 AA\n",
        "N= 2200\n",
        "fl_dif_pad =[]\n",
        "for i, mut in dif_mut_drgn_nonan.iterrows():\n",
        "  a = mut['fl_dif']\n",
        "  new_a = a + [0] * (N - len(a))\n",
        "  fl_dif_pad.append(new_a)\n",
        "dif_mut_drgn_nonan['fl_dif_pad'] = fl_dif_pad\n",
        "\n",
        "stacked_flat_drgn =[]\n",
        "for i, mut in dif_mut_drgn_nonan.iterrows():\n",
        "  stacked_flat_drgn.append(torch.tensor(mut['fl_dif_pad']))\n",
        "\n",
        "dif_mut_drgn_shuffled = dif_mut_drgn_nonan.sample(frac=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train / test only ones with overlapping values for all predictors\n"
      ],
      "metadata": {
        "id": "BftVTCBzkzKP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzBfyizUeMOB"
      },
      "outputs": [],
      "source": [
        "# Distribution of proteins in trianing / test se tof fold\n",
        "# Set fixed random number seed\n",
        "torch.manual_seed(42)\n",
        "TRAIN_BATCH_SIZE = 64\n",
        "epochs=200\n",
        "lr = [3e-5]\n",
        "h = 4096\n",
        "hidden2=2048\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "n_folds = 5\n",
        "\n",
        "sensitivity_D2D, specificity_D2D, mcc_D2D, auc_D2D = {}, {}, {}, {}\n",
        "sensitivity_DEOGEN2, specificity_DEOGEN2, mcc_DEOGEN2, auc_DEOGEN2 = {}, {}, {}, {}\n",
        "sensitivity_EVE, specificity_EVE, mcc_EVE, auc_EVE = {}, {}, {}, {}\n",
        "sensitivity_FATHMM, specificity_FATHMM, mcc_FATHMM, auc_FATHMM = {}, {}, {}, {}\n",
        "sensitivity_SIFT, specificity_SIFT, mcc_SIFT, auc_SIFT = {}, {}, {}, {}\n",
        "sensitivity_PolyPhen2, specificity_PolyPhen2, mcc_PolyPhen2, auc_PolyPhen2 = {}, {}, {}, {}\n",
        "\n",
        "for fold in range(n_folds):\n",
        "  print(f'Starting {fold} fold')\n",
        "  test = dif_mut_drgn_shuffled[fold*round(len(dif_mut_drgn_shuffled)/n_folds):(fold+1)*round(len(dif_mut_drgn_shuffled)/n_folds)]\n",
        "  temp = test.mutation.str.split(pat='_',expand=True)[0]\n",
        "\n",
        "  stacked_flat_drgn =[]\n",
        "  for i, mut in test.iterrows():\n",
        "    stacked_flat_drgn.append(torch.tensor(mut['fl_dif_pad']))\n",
        "\n",
        "  stacked_drgn = torch.stack(stacked_flat_drgn)\n",
        "  print('Test set dimensions of fold: ', stacked_drgn.shape)\n",
        "\n",
        "  cond = dif_mut_shuffled['mutation'].isin(test['mutation'])\n",
        "  training = dif_mut_shuffled.drop(dif_mut_shuffled[cond].index, inplace = False)\n",
        "\n",
        "  # exclude test mutations from training data\n",
        "  stacked_flat =[]\n",
        "  for i, mut in training.iterrows():\n",
        "    stacked_flat.append(torch.tensor(mut['fl_dif_pad']))\n",
        "\n",
        "  stacked_gmm = torch.stack(stacked_flat)\n",
        "  print('Training set dimensions of fold: ', stacked_gmm.shape)\n",
        "\n",
        "  training_temp = training.mutation.str.split(pat='_',expand=True)\n",
        "\n",
        "  # seperate inputs and outputs\n",
        "  X = stacked_gmm\n",
        "  y = training['label']\n",
        "\n",
        "  # Split, shuffle and stratify sequences, mutations, proteins and label\n",
        "  X_train, X_test, y_train, y_test, mu_all_train, mu_all_test , prot_all_train, prot_all_test = train_test_split(X, y, training_temp[1],  training_temp[0], test_size=0.0002, stratify=y, random_state=69)\n",
        "  X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "  X_test, y_test = np.array(X_test), np.array(y_test)\n",
        "\n",
        "  del stacked_gmm, X\n",
        "  gc.collect()\n",
        "\n",
        "  train_dataset = ClassifierDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long())\n",
        "  val_dataset = ClassifierDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test).long())\n",
        "\n",
        "  train_loader = DataLoader(dataset=train_dataset, batch_size=TRAIN_BATCH_SIZE, drop_last=True)\n",
        "  val_loader = DataLoader(dataset=val_dataset, batch_size=2, drop_last=True)\n",
        "\n",
        "  my_net = Classifier2L(h, hidden2, 0.3).to(device)\n",
        "  my_net.apply(init_weights)\n",
        "  param_optimizer = list(my_net.named_parameters())\n",
        "  no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "  optimizer_parameters = [\n",
        "      {\n",
        "          \"params\": [\n",
        "              p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
        "          ],\n",
        "          \"weight_decay\": 0.001,\n",
        "      },\n",
        "      {\n",
        "          \"params\": [\n",
        "              p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
        "          ],\n",
        "          \"weight_decay\": 0.02,\n",
        "      },\n",
        "  ]\n",
        "\n",
        "  num_train_steps = int(len(X_train) / TRAIN_BATCH_SIZE * epochs)\n",
        "  optimizer = torch.optim.AdamW(optimizer_parameters, lr=3e-5)\n",
        "  scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=1000, num_training_steps=num_train_steps)\n",
        "\n",
        "  loss, acc = train_net_cross(my_net, train_loader, val_loader, loss_fn, optimizer, epochs, scheduler )\n",
        "  labels_drgn = test['label'].tolist()\n",
        "  X_drgn, y_drgn = np.array(stacked_drgn), np.array(labels_drgn)  # Actual test\n",
        "\n",
        "  drgn_dataset = ClassifierDataset(torch.from_numpy(X_drgn).float(), torch.from_numpy(y_drgn).long())\n",
        "  drgn_loader = DataLoader(dataset=drgn_dataset, batch_size=1 , drop_last=True)\n",
        "\n",
        "  y_pred_list = []\n",
        "  predictions_drgn= []\n",
        "  my_net.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for X_batch, _ in drgn_loader:\n",
        "          X_batch = X_batch.to(device)\n",
        "          y_test_pred = my_net(X_batch)\n",
        "          predictions_drgn.extend(torch.sigmoid(y_test_pred).cpu().detach().numpy().tolist())\n",
        "\n",
        "  flat_list = []\n",
        "  for sublist in predictions_drgn:\n",
        "      for item in sublist:\n",
        "          flat_list.append(item)\n",
        "\n",
        "  predictions_drgn_D2D = [1 if i>=0.5 else 0 for i in flat_list]\n",
        "  confusion_matrix_df = pd.DataFrame(confusion_matrix(y_drgn, predictions_drgn_D2D))\n",
        "  auc = metrics.roc_auc_score(y_drgn[:len(predictions_drgn_D2D)], flat_list)\n",
        "  tn, fp, fn, tp = confusion_matrix(y_drgn, predictions_drgn_D2D).ravel()\n",
        "  TPR =tp / (tp + fn)\n",
        "  TNR = tn / (tn + fp)\n",
        "\n",
        "  #accuracy_D2D[fold]=((tp+tn)/(tp +tn+ fp+ fn))*100\n",
        "  sensitivity_D2D[fold]=TPR*100\n",
        "  specificity_D2D[fold]=TNR*100\n",
        "  mcc_D2D[fold]= matthews_corrcoef(y_drgn, predictions_drgn_D2D)*100\n",
        "  auc_D2D[fold] =round(auc, 3)*100\n",
        "\n",
        "\n",
        "  # DEOGEN2 results for fold\n",
        "  DEOGEN2_drgn = []\n",
        "  for mut_tet in test['mutation'].values:\n",
        "    DEOGEN2_drgn.append(results_all[mut_tet][0])\n",
        "\n",
        "  ## use when NA --> errors\n",
        "  DEOGEN2_drgn_Na = []\n",
        "  for j,i in enumerate(DEOGEN2_drgn):\n",
        "    if notNaN(i): # if not NaN\n",
        "      DEOGEN2_drgn_Na.append(i)\n",
        "    else:\n",
        "      DEOGEN2_drgn_Na.append(1- y_drgn[j])\n",
        "  predictions_drgn_DEOGEN2 = [1 if i>0.5 else 0 for i in DEOGEN2_drgn_Na]\n",
        "\n",
        "  confusion_matrix_df = pd.DataFrame(confusion_matrix(y_drgn, predictions_drgn_DEOGEN2))\n",
        "  auc = metrics.roc_auc_score(y_drgn[:len(predictions_drgn_DEOGEN2)], DEOGEN2_drgn_Na )\n",
        "  tn, fp, fn, tp = confusion_matrix(y_drgn, predictions_drgn_DEOGEN2).ravel()\n",
        "\n",
        "  ## use when NA --> omit\n",
        "  #y_drgn_DEOGEN2 = [x for x, y in zip(y_drgn, DEOGEN2_drgn) if not pd.isna(y)]\n",
        "  #predictions_drgn_DEOGEN2 = [x for x in DEOGEN2_drgn if not pd.isna(x)]\n",
        "  #predictions_drgn_DEOGEN2 = [1 if i>0.5 else 0 for i in predictions_drgn_DEOGEN2]\n",
        "  #confusion_matrix_df = pd.DataFrame(confusion_matrix(y_drgn_DEOGEN2, predictions_drgn_DEOGEN2))\n",
        "  #auc = metrics.roc_auc_score(y_drgn_DEOGEN2[:len(predictions_drgn_DEOGEN2)], predictions_drgn_DEOGEN2 )\n",
        "  #tn, fp, fn, tp = confusion_matrix(y_drgn_DEOGEN2, predictions_drgn_DEOGEN2).ravel()\n",
        "\n",
        "  TPR =tp / (tp + fn)\n",
        "  TNR = tn / (tn + fp)\n",
        "\n",
        "  #accuracy_DEOGEN2[fold]=((tp+tn)/(tp +tn+ fp+ fn))*100\n",
        "  sensitivity_DEOGEN2[fold]=TPR*100\n",
        "  specificity_DEOGEN2[fold]=TNR*100\n",
        "  mcc_DEOGEN2[fold]= matthews_corrcoef(y_drgn, predictions_drgn_DEOGEN2)*100 # y_drgn_DEOGEN2 when omit\n",
        "  auc_DEOGEN2[fold] =round(auc, 3)*100\n",
        "\n",
        "\n",
        "  # EVE results for fold\n",
        "  EVE_drgn = []\n",
        "  for mut_tet in test['mutation'].values:\n",
        "    EVE_drgn.append(results_all[mut_tet][1])\n",
        "\n",
        "  # use when NA --> errors\n",
        "  #EVE_drgn_Na = []\n",
        "  #for j,i in enumerate(EVE_drgn):\n",
        "  #  if notNaN(i): # if not NaN\n",
        "  #    if i>=0.63:\n",
        "  #      temp.append(1)\n",
        "  #    elif i<0.38:\n",
        "   #     temp.append(0)\n",
        "   # else:\n",
        "   #   EVE_drgn_Na.append(1- y_drgn[j])\n",
        "  #predictions_drgn_EVE = [1 if i>=0.5 else 0 for i in EVE_drgn_Na ]\n",
        "  temp=[]\n",
        "  for i in EVE_drgn:\n",
        "    if i<=0.62 and i>=0.5:\n",
        "      temp.append(i-0.13)\n",
        "    elif i>=0.38 and i<0.5:\n",
        "      temp.append(i+0.17)\n",
        "    else:\n",
        "      temp.append(i)\n",
        "  predictions_drgn_EVE = [1 if i>0.5 else 0 for i in temp]\n",
        "  confusion_matrix_df = pd.DataFrame(confusion_matrix(y_drgn, predictions_drgn_EVE))\n",
        "  auc = metrics.roc_auc_score(y_drgn[:len(predictions_drgn_EVE)], temp) # EVE_drgn_Na\n",
        "  tn, fp, fn, tp = confusion_matrix(y_drgn, predictions_drgn_EVE).ravel()\n",
        "\n",
        "  # use when NA --> omit\n",
        "  #y_drgn_EVE = [x for x, y in zip(y_drgn, EVE_drgn) if not pd.isna(y)]\n",
        "  #predictions_drgn_EVE = [x for x in EVE_drgn if not pd.isna(x)]\n",
        "  #temp = []\n",
        "  #for j,i in enumerate(predictions_drgn_EVE):\n",
        "  #  if i>=0.63:\n",
        "  #    temp.append(1)\n",
        "  #  elif i<0.38:\n",
        "  #    temp.append(0)\n",
        "  #  else:\n",
        "  #    temp.append(1- y_drgn[j])\n",
        "  #predictions_drgn_EVE = temp\n",
        "  #confusion_matrix_df = pd.DataFrame(confusion_matrix(y_drgn_EVE, predictions_drgn_EVE))\n",
        "  #auc = metrics.roc_auc_score(y_drgn_EVE[:len(predictions_drgn_EVE)], predictions_drgn_EVE) # EVE_drgn_Na\n",
        "  #tn, fp, fn, tp = confusion_matrix(y_drgn_EVE, predictions_drgn_EVE).ravel()\n",
        "\n",
        "  TPR =tp / (tp + fn)\n",
        "  TNR = tn / (tn + fp)\n",
        "\n",
        "  #accuracy_EVE[fold]=((tp+tn)/(tp +tn+ fp+ fn))*100\n",
        "  sensitivity_EVE[fold]=TPR*100\n",
        "  specificity_EVE[fold]=TNR*100\n",
        "  mcc_EVE[fold]= matthews_corrcoef(y_drgn, predictions_drgn_EVE)*100 # y_drgn_EVE when omit\n",
        "  auc_EVE[fold] =round(auc, 3)*100\n",
        "\n",
        "  # FATHMM results for fold\n",
        "  FATHMM_drgn = []\n",
        "  for mut_tet in test['mutation'].values:\n",
        "    FATHMM_drgn.append(results_all[mut_tet][2])\n",
        "  # use when NA --> errors\n",
        "  #FATHMM_drgn_Na = []\n",
        "  #for j,i in enumerate(FATHMM_drgn):\n",
        "  #  if notNaN(i): # if not NaN\n",
        "  #    FATHMM_drgn_Na.append(i)\n",
        "  #  else:\n",
        "  #    FATHMM_drgn_Na.append(1- y_drgn[j])\n",
        "  #predictions_drgn_FATHMM = [1 if i<-0.75 else 0 for i in FATHMM_drgn_Na ]\n",
        "\n",
        "  # use when NA --> omit\n",
        "  y_drgn_FATHMM = [x for x, y in zip(y_drgn, FATHMM_drgn) if not pd.isna(y)]\n",
        "  predictions_drgn_FATHMM = [x for x in FATHMM_drgn if not pd.isna(x)]\n",
        "  predictions_drgn_FATHMM = [1 if i<-0.75 else 0 for i in predictions_drgn_FATHMM]\n",
        "\n",
        "  confusion_matrix_df = pd.DataFrame(confusion_matrix(y_drgn_FATHMM, predictions_drgn_FATHMM))\n",
        "  auc = metrics.roc_auc_score(y_drgn_FATHMM[:len(predictions_drgn_FATHMM)], predictions_drgn_FATHMM ) # FATHMM_drgn_Na\n",
        "  tn, fp, fn, tp = confusion_matrix(y_drgn_FATHMM, predictions_drgn_FATHMM).ravel()\n",
        "  TPR =tp / (tp + fn)\n",
        "  TNR = tn / (tn + fp)\n",
        "\n",
        "  #accuracy_FATHMM[fold]=((tp+tn)/(tp +tn+ fp+ fn))*100\n",
        "  sensitivity_FATHMM[fold]=TPR*100\n",
        "  specificity_FATHMM[fold]=TNR*100\n",
        "  mcc_FATHMM[fold]= matthews_corrcoef(y_drgn_FATHMM, predictions_drgn_FATHMM)*100\n",
        "  auc_FATHMM[fold] =round(auc, 3)*100\n",
        "\n",
        "\n",
        "  # SIFT results for fold\n",
        "  SIFT_drgn = []\n",
        "  for mut_tet in test['mutation'].values:\n",
        "    SIFT_drgn.append(results_all[mut_tet][3])\n",
        "\n",
        "  # use when NA --> errors\n",
        "  #SIFT_drgn_Na = []\n",
        "  #for j,i in enumerate(SIFT_drgn):\n",
        "  #  if notNaN(i): # if not NaN\n",
        "  #    SIFT_drgn_Na.append(i)\n",
        "  #  else:\n",
        "  #    SIFT_drgn_Na.append(1- y_drgn[j])\n",
        "  #predictions_drgn_SIFT = [1 if i<=0.05 else 0 for i in SIFT_drgn_Na ]\n",
        "\n",
        "  # use when NA --> omit\n",
        "  y_drgn_SIFT = [x for x, y in zip(y_drgn, SIFT_drgn) if not pd.isna(y)]\n",
        "  predictions_drgn_SIFT = [x for x in SIFT_drgn if not pd.isna(x)]\n",
        "  predictions_drgn_SIFT = [1 if i<=0.05 else 0 for i in predictions_drgn_SIFT]\n",
        "\n",
        "  confusion_matrix_df = pd.DataFrame(confusion_matrix(y_drgn_SIFT, predictions_drgn_SIFT))\n",
        "  auc = metrics.roc_auc_score(y_drgn_SIFT[:len(predictions_drgn_SIFT)], predictions_drgn_SIFT ) #SIFT_drgn_Na\n",
        "  tn, fp, fn, tp = confusion_matrix(y_drgn_SIFT, predictions_drgn_SIFT).ravel()\n",
        "  TPR =tp / (tp + fn)\n",
        "  TNR = tn / (tn + fp)\n",
        "\n",
        "  #accuracy_SIFT[fold]=((tp+tn)/(tp +tn+ fp+ fn))*100\n",
        "  sensitivity_SIFT[fold]=TPR*100\n",
        "  specificity_SIFT[fold]=TNR*100\n",
        "  mcc_SIFT[fold]= matthews_corrcoef(y_drgn_SIFT, predictions_drgn_SIFT)*100\n",
        "  auc_SIFT[fold] =round(auc, 3)*100\n",
        "\n",
        "\n",
        "  # PolyPhen2 results for fold\n",
        "  PolyPhen2_drgn = []\n",
        "  for mut_tet in test['mutation'].values:\n",
        "    PolyPhen2_drgn.append(results_all[mut_tet][4])\n",
        "\n",
        "  # use when NA --> errors\n",
        "  #PolyPhen2_drgn_Na = []\n",
        "  #for j,i in enumerate(PolyPhen2_drgn):\n",
        "  #  if notNaN(i): # if not NaN\n",
        "  #    PolyPhen2_drgn_Na.append(i)\n",
        "  #  else:\n",
        "  #    PolyPhen2_drgn_Na.append(1- y_drgn[j])\n",
        "  #predictions_drgn_PolyPhen2 = [1 if i>=0.49 else 0 for i in PolyPhen2_drgn_Na]\n",
        "\n",
        "  # use when NA --> omit\n",
        "  y_drgn_PolyPhen2 = [x for x, y in zip(y_drgn, PolyPhen2_drgn) if not pd.isna(y)]\n",
        "  predictions_drgn_PolyPhen2 = [x for x in PolyPhen2_drgn if not pd.isna(x)]\n",
        "  predictions_drgn_PolyPhen2 = [1 if i>=0.49 else 0 for i in predictions_drgn_PolyPhen2]\n",
        "  confusion_matrix_df = pd.DataFrame(confusion_matrix(y_drgn_PolyPhen2, predictions_drgn_PolyPhen2))\n",
        "  auc = metrics.roc_auc_score(y_drgn[:len(predictions_drgn_PolyPhen2)],predictions_drgn_PolyPhen2 ) # PolyPhen2_drgn_Na\n",
        "  tn, fp, fn, tp = confusion_matrix(y_drgn_PolyPhen2, predictions_drgn_PolyPhen2).ravel()\n",
        "  TPR =tp / (tp + fn)\n",
        "  TNR = tn / (tn + fp)\n",
        "\n",
        "  #accuracy_PolyPhen2[fold]=((tp+tn)/(tp +tn+ fp+ fn))*100\n",
        "  sensitivity_PolyPhen2[fold]=TPR*100\n",
        "  specificity_PolyPhen2[fold]=TNR*100\n",
        "  mcc_PolyPhen2[fold]= matthews_corrcoef(y_drgn_PolyPhen2, predictions_drgn_PolyPhen2)*100\n",
        "  auc_PolyPhen2[fold] =round(auc, 3)*100"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds=[sensitivity_D2D,  specificity_D2D,  mcc_D2D, auc_D2D] # list of dictionaries\n",
        "test = pd.DataFrame(columns = ['metric', 'fold', 'value'])\n",
        "fold_list, value_list = [],[]\n",
        "for i, m in enumerate(ds):\n",
        "  for key, value in m.items():\n",
        "    fold_list.append(key)\n",
        "    value_list.append(value)\n",
        "\n",
        "test['metric'] = ['sensitivity']* len(sensitivity_D2D) + ['specificity']* len(sensitivity_D2D)+  ['mcc']* len(sensitivity_D2D)+  ['auc']* len(sensitivity_D2D)\n",
        "test['fold'] = fold_list\n",
        "test['value'] = value_list\n",
        "test['predictor'] = ['D2D']* len(sensitivity_D2D) * len(ds)\n",
        "\n",
        "ds=[sensitivity_DEOGEN2,  specificity_DEOGEN2,  mcc_DEOGEN2, auc_DEOGEN2] # list of dictionaries\n",
        "df2 = pd.DataFrame(columns = ['metric', 'fold', 'value'])\n",
        "fold_list, value_list = [],[]\n",
        "for i, m in enumerate(ds):\n",
        "  for key, value in m.items():\n",
        "    fold_list.append(key)\n",
        "    value_list.append(value)\n",
        "\n",
        "df2['metric'] = ['sensitivity']* len(sensitivity_DEOGEN2) + ['specificity']* len(sensitivity_DEOGEN2)+  ['mcc']* len(sensitivity_DEOGEN2)+  ['auc']* len(sensitivity_DEOGEN2)\n",
        "df2['fold'] = fold_list\n",
        "df2['value'] = value_list\n",
        "df2['predictor'] = ['DEOGEN2']* len(sensitivity_D2D) * len(ds)\n",
        "test = test.append(df2, ignore_index=True)\n",
        "\n",
        "ds=[sensitivity_EVE,  specificity_EVE,  mcc_EVE, auc_EVE] # list of dictionaries\n",
        "df2 = pd.DataFrame(columns = ['metric', 'fold', 'value'])\n",
        "fold_list, value_list = [],[]\n",
        "for i, m in enumerate(ds):\n",
        "  for key, value in m.items():\n",
        "    fold_list.append(key)\n",
        "    value_list.append(value)\n",
        "\n",
        "df2['metric'] = ['sensitivity']* len(sensitivity_EVE) + ['specificity']* len(sensitivity_EVE)+  ['mcc']* len(sensitivity_EVE)+  ['auc']* len(sensitivity_EVE)\n",
        "df2['fold'] = fold_list\n",
        "df2['value'] = value_list\n",
        "df2['predictor'] = ['EVE']* len(sensitivity_D2D) * len(ds)\n",
        "test = test.append(df2, ignore_index=True)\n",
        "\n",
        "ds=[sensitivity_FATHMM,  specificity_FATHMM,  mcc_FATHMM, auc_FATHMM] # list of dictionaries\n",
        "df2 = pd.DataFrame(columns = ['metric', 'fold', 'value'])\n",
        "fold_list, value_list = [],[]\n",
        "for i, m in enumerate(ds):\n",
        "  for key, value in m.items():\n",
        "    fold_list.append(key)\n",
        "    value_list.append(value)\n",
        "\n",
        "df2['metric'] = ['sensitivity']* len(sensitivity_FATHMM) + ['specificity']* len(sensitivity_FATHMM)+  ['mcc']* len(sensitivity_FATHMM)+  ['auc']* len(sensitivity_FATHMM)\n",
        "df2['fold'] = fold_list\n",
        "df2['value'] = value_list\n",
        "df2['predictor'] = ['FATHMM']* len(sensitivity_D2D) * len(ds)\n",
        "test = test.append(df2, ignore_index=True)\n",
        "\n",
        "ds=[sensitivity_SIFT,  specificity_SIFT,  mcc_SIFT, auc_SIFT] # list of dictionaries\n",
        "df2 = pd.DataFrame(columns = ['metric', 'fold', 'value'])\n",
        "fold_list, value_list = [],[]\n",
        "for i, m in enumerate(ds):\n",
        "  for key, value in m.items():\n",
        "    fold_list.append(key)\n",
        "    value_list.append(value)\n",
        "\n",
        "df2['metric'] = ['sensitivity']* len(sensitivity_SIFT) + ['specificity']* len(sensitivity_SIFT)+  ['mcc']* len(sensitivity_SIFT)+  ['auc']* len(sensitivity_SIFT)\n",
        "df2['fold'] = fold_list\n",
        "df2['value'] = value_list\n",
        "df2['predictor'] = ['SIFT']* len(sensitivity_D2D) * len(ds)\n",
        "test = test.append(df2, ignore_index=True)\n",
        "\n",
        "ds=[sensitivity_PolyPhen2,  specificity_PolyPhen2,  mcc_PolyPhen2, auc_PolyPhen2] # list of dictionaries\n",
        "df2 = pd.DataFrame(columns = ['metric', 'fold', 'value'])\n",
        "fold_list, value_list = [],[]\n",
        "for i, m in enumerate(ds):\n",
        "  for key, value in m.items():\n",
        "    fold_list.append(key)\n",
        "    value_list.append(value)\n",
        "\n",
        "df2['metric'] = ['sensitivity']* len(sensitivity_PolyPhen2) + ['specificity']* len(sensitivity_PolyPhen2)+  ['mcc']* len(sensitivity_PolyPhen2)+  ['auc']* len(sensitivity_PolyPhen2)\n",
        "df2['fold'] = fold_list\n",
        "df2['value'] = value_list\n",
        "df2['predictor'] = ['PolyPhen2']* len(sensitivity_D2D) * len(ds)\n",
        "test = test.append(df2, ignore_index=True)\n",
        "\n",
        "#fig = px.violin(test, y=\"metric\", x=\"value\", color=\"metric\", box=True, points=\"all\", width=800, height=400, title=\"5 folds D2D\")\n",
        "#fig.update_xaxes(range=[-60, 100])\n",
        "#fig.show()\n",
        "test_notmcc = test[test['metric'] != 'mcc']"
      ],
      "metadata": {
        "id": "7F3ahGi0can_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.box(test_notmcc, x=\"metric\", y=\"value\", color=\"predictor\", color_discrete_map = {'D2D': '#0E6A7B', 'EVE': '#ffc907', 'FATHMM': '#56B4E9','PolyPhen2': '#82ad27','DEOGEN2': '#695647', 'SIFT':'#4234a4'}, width=1600, height=500) #2292a7\n",
        "#fig.update_traces(quartilemethod=\"exclusive\") # or \"inclusive\", or \"linear\" by default\n",
        "fig.update_layout({\n",
        "'plot_bgcolor': 'rgba(255, 255, 255, 255)' ,\n",
        "'paper_bgcolor': 'rgba(255, 255, 255, 255)',\n",
        "})\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "L5VHAIHobJfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.box(test_notmcc, x=\"metric\", y=\"value\", color=\"predictor\", width=1600, height=500)\n",
        "fig.update_traces(quartilemethod=\"exclusive\") # or \"inclusive\", or \"linear\" by default\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "bK8XlxfUgE1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_mcc = test[test['metric'] == 'mcc']\n",
        "fig = px.box(test_mcc, x=\"metric\", y=\"value\", color=\"predictor\", color_discrete_map = {'D2D': '#0E6A7B', 'EVE': '#ffc907', 'FATHMM': '#56B4E9','PolyPhen2': '#82ad27','DEOGEN2': '#695647', 'SIFT':'#4234a4'}, width=600, height=500) # #2292a7\n",
        "fig.update_traces(quartilemethod=\"exclusive\") # or \"inclusive\", or \"linear\" by default\n",
        "fig.update_layout({\n",
        "'plot_bgcolor': 'rgba(255, 255, 255, 255)' ,\n",
        "'paper_bgcolor': 'rgba(255, 255, 255, 255)',\n",
        "})\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "8D0E2b3KgQLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## When missing values considered errors"
      ],
      "metadata": {
        "id": "WCx8MfUsw5Sx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import training data"
      ],
      "metadata": {
        "id": "djVtUbCMyYTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import difference for each mutation + labels\n",
        "dif_mut = pd.read_csv('/content/drive/MyDrive/log_probWT_MUT_Tier1_2_3_common_balanced+-2_2200AA_57maxpool.csv', header = None, names = ['mutation', 'log_difference', 'label'])\n",
        "\n",
        "# exclude duplicates\n",
        "#dif_mut.drop_duplicates(subset = 'mutation', inplace =True)\n",
        "\n",
        "# log_difference has been saved as string of list! Here I convert it back to list of floats\n",
        "fl_dif = []\n",
        "for x in dif_mut['log_difference']:\n",
        "  p = x[1:-1].split(',')\n",
        "  fl_dif.append([float(i) for i in p])\n",
        "\n",
        "dif_mut['fl_dif'] = fl_dif\n",
        "\n",
        "print('Deleterious mutations in dataset: ', len(dif_mut[dif_mut['label'] == 1]))\n",
        "print('Benign mutations in dataset: ', len(dif_mut[dif_mut['label'] == 0]))\n",
        "\n",
        "\n",
        "# pad to 2200 AA\n",
        "N= 2200\n",
        "fl_dif_pad =[]\n",
        "for i, mut in dif_mut.iterrows():\n",
        "  a = mut['fl_dif']\n",
        "  new_a = a + [0] * (N - len(a))\n",
        "  fl_dif_pad.append(new_a)\n",
        "dif_mut['fl_dif_pad'] = fl_dif_pad\n",
        "dif_mut_shuffled = dif_mut.sample(frac=1)"
      ],
      "metadata": {
        "id": "km-EOrkxyYTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import results of all predictors for DRGN and save them in dictionary"
      ],
      "metadata": {
        "id": "Lhisi21fx9aM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV file into a Pandas DataFrame\n",
        "df = pd.read_csv('/content/drive/MyDrive/my_colab/3rdYear/GMM/DRGN_mutations_012023_DEOGEN_etc.csv')\n",
        "# squeeze proteins and mutaitons in one column\n",
        "df['mutation'] = df['uniprot'] + '_' + df['AA_orig'] + df['position'].astype(str) + df['AA_targ']\n",
        "df = df.drop(columns=['label'])\n",
        "# Create a dictionary with the specified columns as key and values\n",
        "results_all = {}\n",
        "for key, val1, val2, val3, val4, val5 in zip(df['mutation'], df['DEOGEN2'], df['EVE'], df['FATHMM'], df['SIFT'], df['PolyPhen2']):\n",
        "    #if key in my_dict: # should be the case since I dont have duplicates\n",
        "    #    my_dict[key].append([val1, val2, val3, val4, val5])\n",
        "    #else:\n",
        "    results_all[key] = [val1, val2, val3, val4, val5]\n",
        "\n",
        "## keep only the values that have prediction for all predictors\n",
        "#df = df[~df.isnull().any(axis=1)]"
      ],
      "metadata": {
        "id": "tIQ7mekNx9aS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import testing data (DRGN) representations"
      ],
      "metadata": {
        "id": "W1P3K5b9x9aS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTzlCA5Mx9aS"
      },
      "outputs": [],
      "source": [
        "dif_mut_drgn = pd.read_csv('/content/drive/MyDrive/log_probWT_MUT_DRGN_2200AA_57maxpool.csv', header = None, names = ['mutation', 'log_difference', 'label'])\n",
        "# exclude duplicates\n",
        "#dif_mut_drgn.drop_duplicates(subset = 'mutation', inplace =True)\n",
        "\n",
        "dif_mut_drgn_nonan = pd.merge(df, dif_mut_drgn, how='inner', on=['mutation']) # Ti einai auto?? Giati den grafeis sxolia ????? Ok katalaba: Exairw ta DRGN samples pou den exw timi gia olous tous predictors\n",
        "print(len(dif_mut_drgn_nonan))\n",
        "\n",
        "# log_difference has been saved as string of list! Here I convert it back to list of floats\n",
        "fl_dif = []\n",
        "for x in dif_mut_drgn_nonan['log_difference']:\n",
        "  p = x[1:-1].split(',')\n",
        "  fl_dif.append([float(i) for i in p])\n",
        "\n",
        "dif_mut_drgn_nonan['fl_dif'] = fl_dif\n",
        "\n",
        "print('Deleterious mutations in dataset: ', len(dif_mut_drgn_nonan[dif_mut_drgn_nonan['label'] == 1]))\n",
        "print('Benign mutations in dataset: ', len(dif_mut_drgn_nonan[dif_mut_drgn_nonan['label'] == 0]))\n",
        "\n",
        "# pad to 2200 AA\n",
        "N= 2200\n",
        "fl_dif_pad =[]\n",
        "for i, mut in dif_mut_drgn_nonan.iterrows():\n",
        "  a = mut['fl_dif']\n",
        "  new_a = a + [0] * (N - len(a))\n",
        "  fl_dif_pad.append(new_a)\n",
        "dif_mut_drgn_nonan['fl_dif_pad'] = fl_dif_pad\n",
        "\n",
        "stacked_flat_drgn =[]\n",
        "for i, mut in dif_mut_drgn_nonan.iterrows():\n",
        "  stacked_flat_drgn.append(torch.tensor(mut['fl_dif_pad']))\n",
        "\n",
        "dif_mut_drgn_shuffled = dif_mut_drgn_nonan.sample(frac=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train /test"
      ],
      "metadata": {
        "id": "Alrfpj2tx9aT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of proteins in trianing / test se tof fold\n",
        "# Set fixed random number seed\n",
        "torch.manual_seed(42)\n",
        "TRAIN_BATCH_SIZE = 64\n",
        "epochs=200\n",
        "lr = [3e-5]\n",
        "h = 4096\n",
        "hidden2=2048\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "n_folds = 5\n",
        "\n",
        "sensitivity_D2D, specificity_D2D, mcc_D2D, auc_D2D = {}, {}, {}, {}\n",
        "sensitivity_DEOGEN2, specificity_DEOGEN2, mcc_DEOGEN2, auc_DEOGEN2 = {}, {}, {}, {}\n",
        "sensitivity_EVE, specificity_EVE, mcc_EVE, auc_EVE = {}, {}, {}, {}\n",
        "sensitivity_FATHMM, specificity_FATHMM, mcc_FATHMM, auc_FATHMM = {}, {}, {}, {}\n",
        "sensitivity_SIFT, specificity_SIFT, mcc_SIFT, auc_SIFT = {}, {}, {}, {}\n",
        "sensitivity_PolyPhen2, specificity_PolyPhen2, mcc_PolyPhen2, auc_PolyPhen2 = {}, {}, {}, {}\n",
        "\n",
        "for fold in range(n_folds):\n",
        "  print(f'Starting {fold} fold')\n",
        "  test = dif_mut_drgn_shuffled[fold*round(len(dif_mut_drgn_shuffled)/n_folds):(fold+1)*round(len(dif_mut_drgn_shuffled)/n_folds)]\n",
        "  temp = test.mutation.str.split(pat='_',expand=True)[0]\n",
        "\n",
        "  stacked_flat_drgn =[]\n",
        "  for i, mut in test.iterrows():\n",
        "    stacked_flat_drgn.append(torch.tensor(mut['fl_dif_pad']))\n",
        "\n",
        "  stacked_drgn = torch.stack(stacked_flat_drgn)\n",
        "  print('Test set dimensions of fold: ', stacked_drgn.shape)\n",
        "\n",
        "  cond = dif_mut_shuffled['mutation'].isin(test['mutation'])\n",
        "  training = dif_mut_shuffled.drop(dif_mut_shuffled[cond].index, inplace = False)\n",
        "\n",
        "  # exclude test mutations from training data\n",
        "  stacked_flat =[]\n",
        "  for i, mut in training.iterrows():\n",
        "    stacked_flat.append(torch.tensor(mut['fl_dif_pad']))\n",
        "\n",
        "  stacked_gmm = torch.stack(stacked_flat)\n",
        "  print('Training set dimensions of fold: ', stacked_gmm.shape)\n",
        "\n",
        "  training_temp = training.mutation.str.split(pat='_',expand=True)\n",
        "\n",
        "  # seperate inputs and outputs\n",
        "  X = stacked_gmm\n",
        "  y = training['label']\n",
        "\n",
        "  # Split, shuffle and stratify sequences, mutations, proteins and label\n",
        "  X_train, X_test, y_train, y_test, mu_all_train, mu_all_test , prot_all_train, prot_all_test = train_test_split(X, y, training_temp[1],  training_temp[0], test_size=0.0002, stratify=y, random_state=69)\n",
        "  X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "  X_test, y_test = np.array(X_test), np.array(y_test)\n",
        "\n",
        "  del stacked_gmm, X\n",
        "  gc.collect()\n",
        "\n",
        "  train_dataset = ClassifierDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long())\n",
        "  val_dataset = ClassifierDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test).long())\n",
        "\n",
        "  train_loader = DataLoader(dataset=train_dataset, batch_size=TRAIN_BATCH_SIZE, drop_last=True)\n",
        "  val_loader = DataLoader(dataset=val_dataset, batch_size=2, drop_last=True)\n",
        "\n",
        "  my_net = Classifier2L(h, hidden2, 0.3).to(device)\n",
        "  my_net.apply(init_weights)\n",
        "  param_optimizer = list(my_net.named_parameters())\n",
        "  no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "  optimizer_parameters = [\n",
        "      {\n",
        "          \"params\": [\n",
        "              p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
        "          ],\n",
        "          \"weight_decay\": 0.001,\n",
        "      },\n",
        "      {\n",
        "          \"params\": [\n",
        "              p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
        "          ],\n",
        "          \"weight_decay\": 0.02,\n",
        "      },\n",
        "  ]\n",
        "\n",
        "  num_train_steps = int(len(X_train) / TRAIN_BATCH_SIZE * epochs)\n",
        "  optimizer = torch.optim.AdamW(optimizer_parameters, lr=3e-5)\n",
        "  scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=1000, num_training_steps=num_train_steps)\n",
        "\n",
        "  loss, acc = train_net_cross(my_net, train_loader, val_loader, loss_fn, optimizer, epochs, scheduler )\n",
        "  labels_drgn = test['label'].tolist()\n",
        "  X_drgn, y_drgn = np.array(stacked_drgn), np.array(labels_drgn)  # Actual test\n",
        "\n",
        "  drgn_dataset = ClassifierDataset(torch.from_numpy(X_drgn).float(), torch.from_numpy(y_drgn).long())\n",
        "  drgn_loader = DataLoader(dataset=drgn_dataset, batch_size=1 , drop_last=True)\n",
        "\n",
        "  y_pred_list = []\n",
        "  predictions_drgn= []\n",
        "  my_net.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for X_batch, _ in drgn_loader:\n",
        "          X_batch = X_batch.to(device)\n",
        "          y_test_pred = my_net(X_batch)\n",
        "          predictions_drgn.extend(torch.sigmoid(y_test_pred).cpu().detach().numpy().tolist())\n",
        "\n",
        "  flat_list = []\n",
        "  for sublist in predictions_drgn:\n",
        "      for item in sublist:\n",
        "          flat_list.append(item)\n",
        "\n",
        "  predictions_drgn_D2D = [1 if i>=0.5 else 0 for i in flat_list]\n",
        "  confusion_matrix_df = pd.DataFrame(confusion_matrix(y_drgn, predictions_drgn_D2D))\n",
        "  auc = metrics.roc_auc_score(y_drgn[:len(predictions_drgn_D2D)], flat_list)\n",
        "  tn, fp, fn, tp = confusion_matrix(y_drgn, predictions_drgn_D2D).ravel()\n",
        "  TPR =tp / (tp + fn)\n",
        "  TNR = tn / (tn + fp)\n",
        "\n",
        "  #accuracy_D2D[fold]=((tp+tn)/(tp +tn+ fp+ fn))*100\n",
        "  sensitivity_D2D[fold]=TPR*100\n",
        "  specificity_D2D[fold]=TNR*100\n",
        "  mcc_D2D[fold]= matthews_corrcoef(y_drgn, predictions_drgn_D2D)*100\n",
        "  auc_D2D[fold] =round(auc, 3)*100\n",
        "\n",
        "\n",
        "  # DEOGEN2 results for fold\n",
        "  DEOGEN2_drgn = []\n",
        "  for mut_tet in test['mutation'].values:\n",
        "    DEOGEN2_drgn.append(results_all[mut_tet][0])\n",
        "\n",
        "  ## use when NA --> errors\n",
        "  DEOGEN2_drgn_Na = []\n",
        "  for j,i in enumerate(DEOGEN2_drgn):\n",
        "    if notNaN(i): # if not NaN\n",
        "      DEOGEN2_drgn_Na.append(i)\n",
        "    else:\n",
        "      DEOGEN2_drgn_Na.append(1- y_drgn[j])\n",
        "  predictions_drgn_DEOGEN2 = [1 if i>0.5 else 0 for i in DEOGEN2_drgn_Na]\n",
        "\n",
        "  confusion_matrix_df = pd.DataFrame(confusion_matrix(y_drgn, predictions_drgn_DEOGEN2))\n",
        "  auc = metrics.roc_auc_score(y_drgn[:len(predictions_drgn_DEOGEN2)], DEOGEN2_drgn_Na )\n",
        "  tn, fp, fn, tp = confusion_matrix(y_drgn, predictions_drgn_DEOGEN2).ravel()\n",
        "\n",
        "  ## use when NA --> omit\n",
        "  #y_drgn_DEOGEN2 = [x for x, y in zip(y_drgn, DEOGEN2_drgn) if not pd.isna(y)]\n",
        "  #predictions_drgn_DEOGEN2 = [x for x in DEOGEN2_drgn if not pd.isna(x)]\n",
        "  #predictions_drgn_DEOGEN2 = [1 if i>0.5 else 0 for i in predictions_drgn_DEOGEN2]\n",
        "  #confusion_matrix_df = pd.DataFrame(confusion_matrix(y_drgn_DEOGEN2, predictions_drgn_DEOGEN2))\n",
        "  #auc = metrics.roc_auc_score(y_drgn_DEOGEN2[:len(predictions_drgn_DEOGEN2)], predictions_drgn_DEOGEN2 )\n",
        "  #tn, fp, fn, tp = confusion_matrix(y_drgn_DEOGEN2, predictions_drgn_DEOGEN2).ravel()\n",
        "\n",
        "  TPR =tp / (tp + fn)\n",
        "  TNR = tn / (tn + fp)\n",
        "\n",
        "  #accuracy_DEOGEN2[fold]=((tp+tn)/(tp +tn+ fp+ fn))*100\n",
        "  sensitivity_DEOGEN2[fold]=TPR*100\n",
        "  specificity_DEOGEN2[fold]=TNR*100\n",
        "  mcc_DEOGEN2[fold]= matthews_corrcoef(y_drgn, predictions_drgn_DEOGEN2)*100 # y_drgn_DEOGEN2 when omit\n",
        "  auc_DEOGEN2[fold] =round(auc, 3)*100\n",
        "\n",
        "\n",
        "  # EVE results for fold\n",
        "  EVE_drgn = []\n",
        "  for mut_tet in test['mutation'].values:\n",
        "    EVE_drgn.append(results_all[mut_tet][1])\n",
        "\n",
        "\n",
        "  # use when NA --> errors\n",
        "  EVE_drgn_Na = []\n",
        "  for j,i in enumerate(EVE_drgn):\n",
        "    if notNaN(i): # if not NaN\n",
        "      EVE_drgn_Na.append(i)\n",
        "    else:\n",
        "      EVE_drgn_Na.append(1- y_drgn[j])\n",
        "  predictions_drgn_EVE = [1 if i>0.5 else 0 for i in EVE_drgn_Na]\n",
        "\n",
        "  confusion_matrix_df = pd.DataFrame(confusion_matrix(y_drgn, predictions_drgn_EVE))\n",
        "  auc = metrics.roc_auc_score(y_drgn[:len(predictions_drgn_EVE)], EVE_drgn_Na) # EVE_drgn_Na\n",
        "  tn, fp, fn, tp = confusion_matrix(y_drgn, predictions_drgn_EVE).ravel()\n",
        "\n",
        "  # use when NA --> omit\n",
        "  #y_drgn_EVE = [x for x, y in zip(y_drgn, EVE_drgn) if not pd.isna(y)]\n",
        "  #predictions_drgn_EVE = [x for x in EVE_drgn if not pd.isna(x)]\n",
        "  #temp = []\n",
        "  #for j,i in enumerate(predictions_drgn_EVE):\n",
        "  #  if i>=0.63:\n",
        "  #    temp.append(1)\n",
        "  #  elif i<0.38:\n",
        "  #    temp.append(0)\n",
        "  #  else:\n",
        "  #    temp.append(1- y_drgn[j])\n",
        "  #predictions_drgn_EVE = temp\n",
        "  #confusion_matrix_df = pd.DataFrame(confusion_matrix(y_drgn_EVE, predictions_drgn_EVE))\n",
        "  #auc = metrics.roc_auc_score(y_drgn_EVE[:len(predictions_drgn_EVE)], predictions_drgn_EVE) # EVE_drgn_Na\n",
        "  #tn, fp, fn, tp = confusion_matrix(y_drgn_EVE, predictions_drgn_EVE).ravel()\n",
        "\n",
        "  TPR =tp / (tp + fn)\n",
        "  TNR = tn / (tn + fp)\n",
        "\n",
        "  #accuracy_EVE[fold]=((tp+tn)/(tp +tn+ fp+ fn))*100\n",
        "  sensitivity_EVE[fold]=TPR*100\n",
        "  specificity_EVE[fold]=TNR*100\n",
        "  mcc_EVE[fold]= matthews_corrcoef(y_drgn, predictions_drgn_EVE)*100 # y_drgn_EVE when omit\n",
        "  auc_EVE[fold] =round(auc, 3)*100\n",
        "\n",
        "  # FATHMM results for fold\n",
        "  FATHMM_drgn = []\n",
        "  for mut_tet in test['mutation'].values:\n",
        "    FATHMM_drgn.append(results_all[mut_tet][2])\n",
        "\n",
        "  # use when NA --> errors\n",
        "  FATHMM_drgn_Na = []\n",
        "  for j,i in enumerate(FATHMM_drgn):\n",
        "    if notNaN(i): # if not NaN\n",
        "      FATHMM_drgn_Na.append(i)\n",
        "    else:\n",
        "      FATHMM_drgn_Na.append(1- y_drgn[j])\n",
        "  predictions_drgn_FATHMM = [1 if i<-0.75 else 0 for i in FATHMM_drgn_Na ]\n",
        "\n",
        "  # use when NA --> omit\n",
        "  #y_drgn_FATHMM = [x for x, y in zip(y_drgn, FATHMM_drgn) if not pd.isna(y)]\n",
        "  #predictions_drgn_FATHMM = [x for x in FATHMM_drgn if not pd.isna(x)]\n",
        "  #predictions_drgn_FATHMM = [1 if i<-0.75 else 0 for i in predictions_drgn_FATHMM]\n",
        "\n",
        "  confusion_matrix_df = pd.DataFrame(confusion_matrix(y_drgn, predictions_drgn_FATHMM))\n",
        "  auc = metrics.roc_auc_score(y_drgn[:len(predictions_drgn_FATHMM)], FATHMM_drgn_Na ) # FATHMM_drgn_Na when omit\n",
        "  tn, fp, fn, tp = confusion_matrix(y_drgn, predictions_drgn_FATHMM).ravel()\n",
        "  TPR =tp / (tp + fn)\n",
        "  TNR = tn / (tn + fp)\n",
        "\n",
        "  #accuracy_FATHMM[fold]=((tp+tn)/(tp +tn+ fp+ fn))*100\n",
        "  sensitivity_FATHMM[fold]=TPR*100\n",
        "  specificity_FATHMM[fold]=TNR*100\n",
        "  mcc_FATHMM[fold]= matthews_corrcoef(y_drgn, predictions_drgn_FATHMM)*100\n",
        "  auc_FATHMM[fold] =round(auc, 3)*100\n",
        "\n",
        "\n",
        "  # SIFT results for fold\n",
        "  SIFT_drgn = []\n",
        "  for mut_tet in test['mutation'].values:\n",
        "    SIFT_drgn.append(results_all[mut_tet][3])\n",
        "\n",
        "  # use when NA --> errors\n",
        "  SIFT_drgn_Na = []\n",
        "  for j,i in enumerate(SIFT_drgn):\n",
        "    if notNaN(i): # if not NaN\n",
        "      SIFT_drgn_Na.append(i)\n",
        "    else:\n",
        "      SIFT_drgn_Na.append(1- y_drgn[j])\n",
        "  predictions_drgn_SIFT = [1 if i<=0.05 else 0 for i in SIFT_drgn_Na ]\n",
        "\n",
        "  # use when NA --> omit\n",
        "  #y_drgn_SIFT = [x for x, y in zip(y_drgn, SIFT_drgn) if not pd.isna(y)]\n",
        "  #predictions_drgn_SIFT = [x for x in SIFT_drgn if not pd.isna(x)]\n",
        "  #predictions_drgn_SIFT = [1 if i<=0.05 else 0 for i in predictions_drgn_SIFT]\n",
        "\n",
        "  confusion_matrix_df = pd.DataFrame(confusion_matrix(y_drgn, predictions_drgn_SIFT))\n",
        "  auc = metrics.roc_auc_score(y_drgn[:len(predictions_drgn_SIFT)], SIFT_drgn_Na ) #SIFT_drgn_Na\n",
        "  tn, fp, fn, tp = confusion_matrix(y_drgn, predictions_drgn_SIFT).ravel()\n",
        "  TPR =tp / (tp + fn)\n",
        "  TNR = tn / (tn + fp)\n",
        "\n",
        "  #accuracy_SIFT[fold]=((tp+tn)/(tp +tn+ fp+ fn))*100\n",
        "  sensitivity_SIFT[fold]=TPR*100\n",
        "  specificity_SIFT[fold]=TNR*100\n",
        "  mcc_SIFT[fold]= matthews_corrcoef(y_drgn, predictions_drgn_SIFT)*100\n",
        "  auc_SIFT[fold] =round(auc, 3)*100\n",
        "\n",
        "\n",
        "  # PolyPhen2 results for fold\n",
        "  PolyPhen2_drgn = []\n",
        "  for mut_tet in test['mutation'].values:\n",
        "    PolyPhen2_drgn.append(results_all[mut_tet][4])\n",
        "\n",
        "  # use when NA --> errors\n",
        "  PolyPhen2_drgn_Na = []\n",
        "  for j,i in enumerate(PolyPhen2_drgn):\n",
        "    if notNaN(i): # if not NaN\n",
        "      PolyPhen2_drgn_Na.append(i)\n",
        "    else:\n",
        "      PolyPhen2_drgn_Na.append(1- y_drgn[j])\n",
        "  predictions_drgn_PolyPhen2 = [1 if i>=0.49 else 0 for i in PolyPhen2_drgn_Na]\n",
        "\n",
        "  # use when NA --> omit\n",
        "  #y_drgn_PolyPhen2 = [x for x, y in zip(y_drgn, PolyPhen2_drgn) if not pd.isna(y)]\n",
        "  #predictions_drgn_PolyPhen2 = [x for x in PolyPhen2_drgn if not pd.isna(x)]\n",
        "  #predictions_drgn_PolyPhen2 = [1 if i>=0.49 else 0 for i in predictions_drgn_PolyPhen2]\n",
        "\n",
        "  confusion_matrix_df = pd.DataFrame(confusion_matrix(y_drgn, predictions_drgn_PolyPhen2))\n",
        "  auc = metrics.roc_auc_score(y_drgn[:len(predictions_drgn_PolyPhen2)],PolyPhen2_drgn_Na ) # PolyPhen2_drgn_Na\n",
        "  tn, fp, fn, tp = confusion_matrix(y_drgn, predictions_drgn_PolyPhen2).ravel()\n",
        "  TPR =tp / (tp + fn)\n",
        "  TNR = tn / (tn + fp)\n",
        "\n",
        "  #accuracy_PolyPhen2[fold]=((tp+tn)/(tp +tn+ fp+ fn))*100\n",
        "  sensitivity_PolyPhen2[fold]=TPR*100\n",
        "  specificity_PolyPhen2[fold]=TNR*100\n",
        "  mcc_PolyPhen2[fold]= matthews_corrcoef(y_drgn, predictions_drgn_PolyPhen2)*100\n",
        "  auc_PolyPhen2[fold] =round(auc, 3)*100"
      ],
      "metadata": {
        "id": "eTmFbPagx9aT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds=[sensitivity_D2D,  specificity_D2D,  mcc_D2D, auc_D2D] # list of dictionaries\n",
        "test = pd.DataFrame(columns = ['metric', 'fold', 'value'])\n",
        "fold_list, value_list = [],[]\n",
        "for i, m in enumerate(ds):\n",
        "  for key, value in m.items():\n",
        "    fold_list.append(key)\n",
        "    value_list.append(value)\n",
        "\n",
        "test['metric'] = ['sensitivity']* len(sensitivity_D2D) + ['specificity']* len(sensitivity_D2D)+  ['mcc']* len(sensitivity_D2D)+  ['auc']* len(sensitivity_D2D)\n",
        "test['fold'] = fold_list\n",
        "test['value'] = value_list\n",
        "test['predictor'] = ['D2D']* len(sensitivity_D2D) * len(ds)\n",
        "\n",
        "ds=[sensitivity_DEOGEN2,  specificity_DEOGEN2,  mcc_DEOGEN2, auc_DEOGEN2] # list of dictionaries\n",
        "df2 = pd.DataFrame(columns = ['metric', 'fold', 'value'])\n",
        "fold_list, value_list = [],[]\n",
        "for i, m in enumerate(ds):\n",
        "  for key, value in m.items():\n",
        "    fold_list.append(key)\n",
        "    value_list.append(value)\n",
        "\n",
        "df2['metric'] = ['sensitivity']* len(sensitivity_DEOGEN2) + ['specificity']* len(sensitivity_DEOGEN2)+  ['mcc']* len(sensitivity_DEOGEN2)+  ['auc']* len(sensitivity_DEOGEN2)\n",
        "df2['fold'] = fold_list\n",
        "df2['value'] = value_list\n",
        "df2['predictor'] = ['DEOGEN2']* len(sensitivity_D2D) * len(ds)\n",
        "test = test.append(df2, ignore_index=True)\n",
        "\n",
        "ds=[sensitivity_EVE,  specificity_EVE,  mcc_EVE, auc_EVE] # list of dictionaries\n",
        "df2 = pd.DataFrame(columns = ['metric', 'fold', 'value'])\n",
        "fold_list, value_list = [],[]\n",
        "for i, m in enumerate(ds):\n",
        "  for key, value in m.items():\n",
        "    fold_list.append(key)\n",
        "    value_list.append(value)\n",
        "\n",
        "df2['metric'] = ['sensitivity']* len(sensitivity_EVE) + ['specificity']* len(sensitivity_EVE)+  ['mcc']* len(sensitivity_EVE)+  ['auc']* len(sensitivity_EVE)\n",
        "df2['fold'] = fold_list\n",
        "df2['value'] = value_list\n",
        "df2['predictor'] = ['EVE']* len(sensitivity_D2D) * len(ds)\n",
        "test = test.append(df2, ignore_index=True)\n",
        "\n",
        "ds=[sensitivity_FATHMM,  specificity_FATHMM,  mcc_FATHMM, auc_FATHMM] # list of dictionaries\n",
        "df2 = pd.DataFrame(columns = ['metric', 'fold', 'value'])\n",
        "fold_list, value_list = [],[]\n",
        "for i, m in enumerate(ds):\n",
        "  for key, value in m.items():\n",
        "    fold_list.append(key)\n",
        "    value_list.append(value)\n",
        "\n",
        "df2['metric'] = ['sensitivity']* len(sensitivity_FATHMM) + ['specificity']* len(sensitivity_FATHMM)+  ['mcc']* len(sensitivity_FATHMM)+  ['auc']* len(sensitivity_FATHMM)\n",
        "df2['fold'] = fold_list\n",
        "df2['value'] = value_list\n",
        "df2['predictor'] = ['FATHMM']* len(sensitivity_D2D) * len(ds)\n",
        "test = test.append(df2, ignore_index=True)\n",
        "\n",
        "ds=[sensitivity_SIFT,  specificity_SIFT,  mcc_SIFT, auc_SIFT] # list of dictionaries\n",
        "df2 = pd.DataFrame(columns = ['metric', 'fold', 'value'])\n",
        "fold_list, value_list = [],[]\n",
        "for i, m in enumerate(ds):\n",
        "  for key, value in m.items():\n",
        "    fold_list.append(key)\n",
        "    value_list.append(value)\n",
        "\n",
        "df2['metric'] = ['sensitivity']* len(sensitivity_SIFT) + ['specificity']* len(sensitivity_SIFT)+  ['mcc']* len(sensitivity_SIFT)+  ['auc']* len(sensitivity_SIFT)\n",
        "df2['fold'] = fold_list\n",
        "df2['value'] = value_list\n",
        "df2['predictor'] = ['SIFT']* len(sensitivity_D2D) * len(ds)\n",
        "test = test.append(df2, ignore_index=True)\n",
        "\n",
        "ds=[sensitivity_PolyPhen2,  specificity_PolyPhen2,  mcc_PolyPhen2, auc_PolyPhen2] # list of dictionaries\n",
        "df2 = pd.DataFrame(columns = ['metric', 'fold', 'value'])\n",
        "fold_list, value_list = [],[]\n",
        "for i, m in enumerate(ds):\n",
        "  for key, value in m.items():\n",
        "    fold_list.append(key)\n",
        "    value_list.append(value)\n",
        "\n",
        "df2['metric'] = ['sensitivity']* len(sensitivity_PolyPhen2) + ['specificity']* len(sensitivity_PolyPhen2)+  ['mcc']* len(sensitivity_PolyPhen2)+  ['auc']* len(sensitivity_PolyPhen2)\n",
        "df2['fold'] = fold_list\n",
        "df2['value'] = value_list\n",
        "df2['predictor'] = ['PolyPhen2']* len(sensitivity_D2D) * len(ds)\n",
        "test = test.append(df2, ignore_index=True)\n",
        "\n",
        "#fig = px.violin(test, y=\"metric\", x=\"value\", color=\"metric\", box=True, points=\"all\", width=800, height=400, title=\"5 folds D2D\")\n",
        "#fig.update_xaxes(range=[-60, 100])\n",
        "#fig.show()\n",
        "test_notmcc = test[test['metric'] != 'mcc']"
      ],
      "metadata": {
        "id": "eult4EvueMOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.box(test_notmcc, x=\"metric\", y=\"value\", color=\"predictor\", color_discrete_map = {'D2D': '#6DA4AF', 'EVE': '#F9E393', 'FATHMM': '#9BC9E2','PolyPhen2': '#9DAF79','DEOGEN2': '#907F71', 'SIFT':'#635C92'}, width=1600, height=500)\n",
        "#fig.update_traces(quartilemethod=\"exclusive\") # or \"inclusive\", or \"linear\" by default\n",
        "fig.update_layout({\n",
        "'plot_bgcolor': 'rgba(255, 255, 255, 255)' ,\n",
        "'paper_bgcolor': 'rgba(255, 255, 255, 255)',\n",
        "})\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "aRU-qPICF8j4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.box(test_notmcc, x=\"metric\", y=\"value\", color=\"predictor\", width=1600, height=500)\n",
        "fig.update_traces(quartilemethod=\"exclusive\") # or \"inclusive\", or \"linear\" by default\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "c666tLaQVVI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_mcc = test[test['metric'] == 'mcc']\n",
        "fig = px.box(test_mcc, x=\"metric\", y=\"value\", color=\"predictor\", color_discrete_map = {'D2D': '#6DA4AF', 'EVE': '#F9E393', 'FATHMM': '#9BC9E2','PolyPhen2': '#9DAF79','DEOGEN2': '#907F71', 'SIFT':'#635C92'}, width=600, height=500) #2292a7 #ffc907 #56B4E9 #82ad27 #695647 #4234a4\n",
        "fig.update_traces(quartilemethod=\"exclusive\") # or \"inclusive\", or \"linear\" by default\n",
        "fig.update_layout({\n",
        "'plot_bgcolor': 'rgba(255, 255, 255, 255)' ,\n",
        "'paper_bgcolor': 'rgba(255, 255, 255, 255)',\n",
        "})\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "iWroopS6Gz_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_mcc = test[test['metric'] == 'mcc']\n",
        "fig = px.box(test_mcc, x=\"metric\", y=\"value\", color=\"predictor\", width=600, height=500)\n",
        "fig.update_traces(quartilemethod=\"exclusive\") # or \"inclusive\", or \"linear\" by default\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "hXTjPSke7hJ6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}